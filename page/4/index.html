<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Attention Is A Talent</title><meta name="author" content="Poy One"><meta name="copyright" content="Poy One"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Attention Is A Talent">
<meta property="og:url" content="https://poyone.github.io/page/4/index.html">
<meta property="og:site_name" content="Attention Is A Talent">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://npm.elemecdn.com/poyone1222/eris/eris11.webp">
<meta property="article:author" content="Poy One">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://npm.elemecdn.com/poyone1222/eris/eris11.webp"><link rel="shortcut icon" href="https://npm.elemecdn.com/poyone1222/eris/eris11.webp"><link rel="canonical" href="https://poyone.github.io/page/4/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"ä½ å·²åˆ‡æ¢ä¸ºç¹ä½“","cht_to_chs":"ä½ å·²åˆ‡æ¢ä¸ºç®€ä½“","day_to_night":"ä½ å·²åˆ‡æ¢ä¸ºæ·±è‰²æ¨¡å¼","night_to_day":"ä½ å·²åˆ‡æ¢ä¸ºæµ…è‰²æ¨¡å¼","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Attention Is A Talent',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-12-15 22:44:59'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card@1.0.0/lib/categorybar.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/eris11.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> å…³äº</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Attention Is A Talent</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> å…³äº</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Attention Is A Talent</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/posts/64185.html" title="HF Course 02 APIæ¦‚è¦"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris40.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HF Course 02 APIæ¦‚è¦"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/64185.html" title="HF Course 02 APIæ¦‚è¦">HF Course 02 APIæ¦‚è¦</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-12-06T10:52:16.501Z" title="å‘è¡¨äº 2022-12-06 18:52:16">2022-12-06</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-12T04:03:09.516Z" title="æ›´æ–°äº 2022-12-12 12:03:09">2022-12-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Universe/">Universe</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Huggingface/">Huggingface</a></span></div><div class="content">outputsNote that the outputs of ğŸ¤— Transformers models behave like namedtuples or dictionaries. You can access the elements by attributes (like we did) or by key (outputs[&quot;last_hidden_state&quot;]), or even by index if you know exactly where the thing you are looking for is (outputs[0]).

HFçš„è¾“å…¥è¿”å› å¤§å¤šä»¥æ˜¯å…ƒç»„æˆ–å­—å…¸å½¢å¼å‡ºï¼Œå¤„ç†çš„æ—¶å€™è¦æ³¨æ„ã€‚

ä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»ï¼Œå¤šåˆ†ç±»ä¸­æ¯ä¸ªç±»åˆ«åˆ†åˆ«ä½œäºŒåˆ†ç±»ï¼Œæ˜¯å¦å±äºè¿™ä¸ªç±»åˆ«è¿›è¡Œè¾“å‡º
[[0.2,0.8]ã€[0.4,0.6]ã€[0.7,0.3]]  &#x3D; [[1]ã€[1]ã€[0]]
Config12345678910111213141516171819from transformers import BertConfig, BertModel# Building the configconfig = BertConfig()# Building the model from the configmodel = BertModel(config)config&#x27;&#x27;&#x27;BertConfig &#123;  [...]  &quot;hidden_size&quot;: 768,  &quot;intermediate_size&quot;: 3072,  &quot;max_position_embeddings&quot;: 512,  &quot;num_attention_heads&quot;: 12,  &quot;num_hidden_layers&quot;: 12,  [...]&#125;&#x27;&#x27;&#x27;



ç¯å¢ƒå˜é‡The weights have been downloaded and cached (so future calls to the from_pretrained() method wonâ€™t re-download them) in the cache folder, which defaults to ~&#x2F;.cache&#x2F;huggingface&#x2F;transformers. You can customize your cache folder by setting the HF_HOME environment variable.

é…ç½®ä½ å½“å‰çš„ç¯å¢ƒå˜é‡ os.environ[&#39;HF_HOME&#39;]= &#39;~/.cache/huggingface/transformers&#39; 

Saving12345678model.save_pretrained(&quot;directory_on_my_computer&quot;)&#x27;&#x27;&#x27;This saves two files to your disk:ls directory_on_my_computerconfig.json pytorch_model.bin&#x27;&#x27;&#x27;


If you take a look at the config.json file, youâ€™ll recognize the attributes necessary to build the model architecture. This file also contains some metadata, such as where the checkpoint originated and what ğŸ¤— Transformers version you were using when you last saved the checkpoint

The pytorch_model.bin file is known as the state dictionary; it contains all your modelâ€™s weights. The two files go hand in hand; the configuration is necessary to know your modelâ€™s architecture, while the model weights are your modelâ€™s parameters.


Tokenizerencodeé€šè¿‡tokenizer.tokenize(sequence)æŸ¥çœ‹åˆ†è¯åçš„ç»“æœ
12345678910from transformers import AutoTokenizertokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-cased&quot;)sequence = &quot;Using a Transformer network is simple&quot;tokens = tokenizer.tokenize(sequence)print(tokens)&#x27;&#x27;&#x27;[&#x27;Using&#x27;, &#x27;a&#x27;, &#x27;transform&#x27;, &#x27;##er&#x27;, &#x27;network&#x27;, &#x27;is&#x27;, &#x27;simple&#x27;]&#x27;&#x27;&#x27;



ids = tokenizer.convert_tokens_to_ids(tokens)
è¿˜å¯ä»¥åè¿‡æ¥å¾—åˆ°tokenï¼Œä¹Ÿå°±æ˜¯è·Ÿä¸Šé¢çš„ tokenize(seq) ä¸€æ ·çš„æ•ˆæœ
123ids = tokenizer.convert_tokens_to_ids(tokens)print(ids)



decode12345decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])print(decoded_string)&#x27;&#x27;&#x27;&#x27;Using a Transformer network is simple&#x27;&#x27;&#x27;&#x27;



paddingæŸ¥çœ‹tokenizer.pad_token_id padçš„id
123456789# Will pad the sequences up to the maximum sequence lengthmodel_inputs = tokenizer(sequences, padding=&quot;longest&quot;)# Will pad the sequences up to the model max length# (512 for BERT or DistilBERT)model_inputs = tokenizer(sequences, padding=&quot;max_length&quot;)# Will pad the sequences up to the specified max lengthmodel_inputs = tokenizer(sequences, padding=&quot;max_length&quot;, max_length=8)


ç›´æ¥max_lengthæ˜¯åˆ°æ¨¡å‹çš„æœ€å¤§é•¿åº¦ï¼Œlongestæ˜¯åˆ°æ‰¹æ¬¡é‡Œå¥å­çš„æœ€å¤§é•¿åº¦

1234567891011sequence1_ids = [[200, 200, 200]]sequence2_ids = [[200, 200]]batched_ids = [    [200, 200, 200],    [200, 200, tokenizer.pad_token_id],]&#x27;&#x27;&#x27;tensor([[ 1.5694, -1.3895]], grad_fn=&lt;AddmmBackward&gt;)tensor([[ 0.5803, -0.4125]], grad_fn=&lt;AddmmBackward&gt;)tensor([[ 1.5694, -1.3895],        [ 1.3373, -1.2163]], grad_fn=&lt;AddmmBackward&gt;)&#x27;&#x27;&#x27;



This is because the key feature of Transformer models is attention layers that contextualize each token. These will take into account the padding tokens since they attend to all of the tokens of a sequence. To get the same result when passing individual sentences of different lengths through the model or when passing a batch with the same sentences and padding applied, we need to tell those attention layers to ignore the padding tokens. This is done by using an attention mask.

è¿™é‡Œä¸¤æ¡å•ç‹¬çš„æ•°æ®çš„ç»“æœè·Ÿç»„åˆèµ·æ¥çš„æ˜¯ä¸åŒçš„ï¼Œæ˜¯å› ä¸ºpadçš„ä½ç½®ä¹Ÿåˆ†æ•£äº†æ¨¡å‹çš„æ³¨æ„åŠ›ï¼Œè¿™ä¸æ˜¯æˆ‘ä»¬å¸Œæœ›æ¨¡å‹å­¦ä¹ çš„åœ°æ–¹

ATTENTION MASK123456789101112131415batched_ids = [    [200, 200, 200],    [200, 200, tokenizer.pad_token_id],]attention_mask = [    [1, 1, 1],    [1, 1, 0],]outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))print(outputs.logits)&#x27;&#x27;&#x27;tensor([[ 1.5694, -1.3895],        [ 0.5803, -0.4125]], grad_fn=&lt;AddmmBackward&gt;)&#x27;&#x27;&#x27;



é•¿å¥å­å¤„ç†Models have different supported sequence lengths, and some specialize in handling very long sequences. Longformer is one example, and another is LED. If youâ€™re working on a task that requires very long sequences, we recommend you take a look at those models.
ä¸€èˆ¬æ˜¯åœ¨tokenizeré‡Œè®¾ç½®truncation max_lenï¼Œè¿™é‡Œæ²¡è®²ï¼Œå¯ä»¥å»çœ‹çœ‹æ¨¡å‹ã€‚
</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/16149.html" title="HF Course 01 åŸºç¡€æ¦‚å¿µ"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris40.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HF Course 01 åŸºç¡€æ¦‚å¿µ"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/16149.html" title="HF Course 01 åŸºç¡€æ¦‚å¿µ">HF Course 01 åŸºç¡€æ¦‚å¿µ</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-12-06T10:52:16.495Z" title="å‘è¡¨äº 2022-12-06 18:52:16">2022-12-06</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-12T04:03:00.563Z" title="æ›´æ–°äº 2022-12-12 12:03:00">2022-12-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Universe/">Universe</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Huggingface/">Huggingface</a></span></div><div class="content">Some of the currently available pipelines are:

feature-extraction (get the vector representation of a text)
fill-mask
ner (named entity recognition)
question-answering
sentiment-analysis
summarization
text-generation
translation
zero-shot-classification

pipeline12345678from transformers import pipelinegenerator = pipeline(&quot;text-generation&quot;, model=&quot;distilgpt2&quot;)generator(    &quot;In this course, we will teach you how to&quot;,    max_length=30,    num_return_sequences=2,)





modelæ¨¡å‹å‘å±•æ—¶é—´å²

June 2018: GPT, the first pretrained Transformer model, used for fine-tuning on various NLP tasks and obtained state-of-the-art results

October 2018: BERT, another large pretrained model, this one designed to produce better summaries of sentences (more on this in the next chapter!)

February 2019: GPT-2, an improved (and bigger) version of GPT that was not immediately publicly released due to ethical concerns

October 2019: DistilBERT, a distilled version of BERT that is 60% faster, 40% lighter in memory, and still retains 97% of BERTâ€™s performance

October 2019: BART and T5, two large pretrained models using the same architecture as the original Transformer model (the first to do so)

May 2020, GPT-3, an even bigger version of GPT-2 that is able to perform well on a variety of tasks without the need for fine-tuning (called zero-shot learning)

GPT-like (also called auto-regressive Transformer models)

BERT-like (also called auto-encoding Transformer models)

BART&#x2F;T5-like (also called sequence-to-sequence Transformer models)


encoder-decoderç‰¹æ”»ç±»ç¼–ç å™¨çš„ä¸»è¦ç”¨å¤„

Encoder-only models: Good for tasks that require understanding of the input, such as sentence classification and named entity recognition.
ALBERT
BERT
DistilBERT
ELECTRA
RoBERTa


Decoder-only models: Good for generative tasks such as text generation
CTRL
GPT
GPT-2
Transformer XL.


Encoder-decoder models or sequence-to-sequence models: Good for generative tasks that require an input, such as translation or summarization.
BART
mBART
Marian
T5



cross-attentionå±‚ä½¿å¾—decoderèƒ½æŸ¥çœ‹æ•´ä¸ªå¥æ„ï¼Œä»¥è°ƒæ•´é¡ºåºç¿»è¯‘è¾“å‡º
Note that the first attention layer in a decoder block pays attention to all (past) inputs to the decoder, but the second attention layer uses the output of the encoder. It can thus access the whole input sentence to best predict the current word. This is very useful as different languages can have grammatical rules that put the words in different orders, or some context provided later in the sentence may be helpful to determine the best translation of a given word.
æ¶æ„å’Œæ£€æŸ¥ç‚¹

Architecture: This is the skeleton of the model â€” the definition of each layer and each operation that happens within the model.
Checkpoints: These are the weights that will be loaded in a given architecture.
Model: This is an umbrella term that isnâ€™t as precise as â€œarchitectureâ€ or â€œcheckpointâ€: it can mean both. This course will specify architecture or checkpoint when it matters to reduce ambiguity.

For example, BERT is an architecture while bert-base-cased, a set of weights trained by the Google team for the first release of BERT, is a checkpoint. However, one can say â€œthe BERT modelâ€ and â€œthe bert-base-cased model.â€
å³ä½¿ä½¿ç”¨å¹²å‡€çš„è¯åº“ï¼Œä¹Ÿå¯èƒ½äº§ç”Ÿæ€§åˆ«æ­§è§†ï¼Œç§æ—æ­§è§†
When asked to fill in the missing word in these two sentences, the model gives only one gender-free answer (waiter&#x2F;waitress). The others are work occupations usually associated with one specific gender â€” and yes, prostitute ended up in the top 5 possibilities the model associates with â€œwomanâ€ and â€œwork.â€ This happens even though BERT is one of the rare Transformer models not built by scraping data from all over the internet, but rather using apparently neutral data (itâ€™s trained on the English Wikipedia and BookCorpus datasets).
When you use these tools, you therefore need to keep in the back of your mind that the original model you are using could very easily generate sexist, racist, or homophobic content. Fine-tuning the model on your data wonâ€™t make this intrinsic bias disappear.
</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/35234.html" title="huggingface proxy"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris26.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="huggingface proxy"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/35234.html" title="huggingface proxy">huggingface proxy</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-12-04T06:10:13.101Z" title="å‘è¡¨äº 2022-12-04 14:10:13">2022-12-04</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-06T10:55:07.386Z" title="æ›´æ–°äº 2022-12-06 18:55:07">2022-12-06</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/HuggingFace/">HuggingFace</a><span class="article-meta-link">â€¢</span><a class="article-meta__tags" href="/tags/Proxy/">Proxy</a></span></div><div class="content">huggingfaceåœ¨æœ‰ä»£ç†çš„æƒ…å†µä¸‹
1234567from transformers import AutoModelForSeq2SeqLM, AutoTokenizerprx = &#123;&#x27;https&#x27;: &#x27;http://127.0.0.1:7890&#x27;&#125;model_name = &quot;Helsinki-NLP/opus-mt-zh-en&quot;save_path = r&#x27;D:\00mydataset\huggingface model&#x27;tokenizer = AutoTokenizer.from_pretrained(model_name, proxies=prx, cache_dir=save_path)

ç›´æ¥è®¾ç½®ä»£ç†å°±å¯ä»¥æ¥åˆ°huggingfaceäº†
vscodeåœ¨settingé‡Œé¢çš„proxyçš„ç¬¬ä¸€æ è®¾ç½®http://127.0.0.1:7890 åé¢çš„7890å°±æ˜¯ä½ çš„ç«¯å£å·ï¼Œåœ¨ä½ çš„ä»£ç†å¤„å¯ä»¥æŸ¥çœ‹
pippip æˆ‘æ ¹æ®è¿™ç¯‡æ–‡ç« åœ¨ç»ˆç«¯ç›´æ¥è®¾ç½® set http_proxy=&#39;http://127.0.0.1:7890&#39; è¿™å°±å¥½äº†
123456789# åœ¨pipç›®å½•åˆ›å»ºå¹¶ç¼–è¾‘pip.iniï¼ˆé…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶ï¼‰cd C:\Users\(ä½ çš„ç”¨æˆ·å)   mkdir pip                # åˆ›å»ºpipæ–‡ä»¶å¤¹cd pip                     # è¿›å…¥pipè·¯å¾„ç›®å½•ä¸‹cd.&gt;pip.ini              # åˆ›å»ºpip.iniæ–‡ä»¶# ç„¶åæ‰“å¼€C:\Users(ç”¨æˆ·å)\pip\pip.iniï¼Œæ·»åŠ å¦‚ä¸‹å†…å®¹ï¼š[global]proxy=http://10.20.217.2:8080

</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/10656.html" title="å¥æ„ç›¸ä¼¼åº¦ PipeLineæ€»ç»“"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris41.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="å¥æ„ç›¸ä¼¼åº¦ PipeLineæ€»ç»“"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/10656.html" title="å¥æ„ç›¸ä¼¼åº¦ PipeLineæ€»ç»“">å¥æ„ç›¸ä¼¼åº¦ PipeLineæ€»ç»“</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-27T02:47:31.323Z" title="å‘è¡¨äº 2022-11-27 10:47:31">2022-11-27</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-04T16:48:36.782Z" title="æ›´æ–°äº 2022-12-05 00:48:36">2022-12-05</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%8F%A5%E6%84%8F%E7%9B%B8%E4%BC%BC%E5%BA%A6/">å¥æ„ç›¸ä¼¼åº¦</a><span class="article-meta-link">â€¢</span><a class="article-meta__tags" href="/tags/Pipeline/">Pipeline</a></span></div><div class="content">ä¸»è¦è¿›è¡Œè®­ç»ƒæ¡†æ¶ä¼˜åŒ–

ç«¯åˆ°ç«¯ ML å®æ–½ï¼ˆè®­ç»ƒã€éªŒè¯ã€é¢„æµ‹ã€è¯„ä¼°ï¼‰
è½»æ¾é€‚åº”æ‚¨è‡ªå·±çš„æ•°æ®é›†
ä¿ƒè¿›å…¶ä»–åŸºäº BERT çš„æ¨¡å‹ï¼ˆBERTã€ALBERTã€â€¦ï¼‰çš„å¿«é€Ÿå®éªŒ
ä½¿ç”¨æœ‰é™çš„è®¡ç®—èµ„æºè¿›è¡Œå¿«é€Ÿè®­ç»ƒï¼ˆæ··åˆç²¾åº¦ã€æ¢¯åº¦ç´¯ç§¯â€¦â€¦ï¼‰
å¤š GPU æ‰§è¡Œ
åˆ†ç±»å†³ç­–çš„é˜ˆå€¼é€‰æ‹©ï¼ˆä¸ä¸€å®šæ˜¯ 0.5ï¼‰
å†»ç»“ BERT å±‚ï¼Œåªæ›´æ–°åˆ†ç±»å±‚æƒé‡æˆ–æ›´æ–°æ‰€æœ‰æƒé‡
ç§å­è®¾ç½®ï¼Œå¯å¤ç°ç»“æœ

PipeLineå¯¼åŒ…12345678910111213import torchimport torch.nn as nnimport osimport copyimport torch.optim as optimimport randomimport numpy as npimport pandas as pdfrom torch.utils.data import DataLoader, Datasetfrom torch.cuda.amp import autocast, GradScalerfrom tqdm.auto import tqdmfrom transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmupfrom datasets import load_dataset, load_metric

Dataset123456789101112131415161718192021222324252627282930313233343536class CustomDataset(Dataset):    def __init__(self, data, maxlen, with_labels=True, bert_model=&#x27;albert-base-v2&#x27;):        self.data = data  # pandas dataframe        #Initialize the tokenizer        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)          self.maxlen = maxlen        self.with_labels = with_labels     def __len__(self):        return len(self.data)    def __getitem__(self, index):        #æ ¹æ®ç´¢å¼•ç´¢å–DataFrameä¸­å¥å­1ä½™å¥å­2        sent1 = str(self.data.loc[index, &#x27;sentence1&#x27;])        sent2 = str(self.data.loc[index, &#x27;sentence2&#x27;])        # å¯¹å¥å­å¯¹åˆ†è¯ï¼Œå¾—åˆ°input_idsã€attention_maskå’Œtoken_type_ids        encoded_pair = self.tokenizer(sent1, sent2,                                       padding=&#x27;max_length&#x27;,  # å¡«å……åˆ°æœ€å¤§é•¿åº¦                                      truncation=True,  # æ ¹æ®æœ€å¤§é•¿åº¦è¿›è¡Œæˆªæ–­                                      max_length=self.maxlen,                                        return_tensors=&#x27;pt&#x27;)  # è¿”å›torch.Tensorå¼ é‡                token_ids = encoded_pair[&#x27;input_ids&#x27;].squeeze(0)  # tensor token ids        attn_masks = encoded_pair[&#x27;attention_mask&#x27;].squeeze(0)  # padded valueså¯¹åº”ä¸º &quot;0&quot; ï¼Œå…¶ä»–tokenä¸º1        token_type_ids = encoded_pair[&#x27;token_type_ids&#x27;].squeeze(0)  #ç¬¬ä¸€ä¸ªå¥å­çš„å€¼ä¸º0ï¼Œç¬¬äºŒä¸ªå¥å­çš„å€¼ä¸º1 # åªæœ‰ä¸€å¥å…¨ä¸º0        if self.with_labels:  # True if the dataset has labels            label = self.data.loc[index, &#x27;label&#x27;]            return token_ids, attn_masks, token_type_ids, label          else:            return token_ids, attn_masks, token_type_ids

å»ºè®®ï¼Œè¿›è¡Œæµ‹è¯•
12sample = next(iter(DataLoader(tr_dataset, batch_size=2)))sample

12tr_model = SentencePairClassifier(freeze_bert=True)tr_model(sample[0], sample[1], sample[2])

å°±æ˜¯æ–¹ä¾¿æœ€åçš„ç»´åº¦è½¬æ¢ï¼Œsqueezeã€flattenã€viewï¼›ç”šè‡³å¯ä»¥ç”¨reshapeæ–¹æ³•
æ¨¡å‹å®šä¹‰12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class SentencePairClassifier(nn.Module):    def __init__(self, bert_model=&quot;albert-base-v2&quot;, freeze_bert=False):        super(SentencePairClassifier, self).__init__()        #  åˆå§‹åŒ–é¢„è®­ç»ƒæ¨¡å‹Bert xxx        self.bert_layer = AutoModel.from_pretrained(bert_model)        #  encoder éšè—å±‚å¤§å°        if bert_model == &quot;albert-base-v2&quot;:  # 12M å‚æ•°            hidden_size = 768        elif bert_model == &quot;albert-large-v2&quot;:  # 18M å‚æ•°            hidden_size = 1024        elif bert_model == &quot;albert-xlarge-v2&quot;:  # 60M å‚æ•°            hidden_size = 2048        elif bert_model == &quot;albert-xxlarge-v2&quot;:  # 235M å‚æ•°            hidden_size = 4096        elif bert_model == &quot;bert-base-uncased&quot;: # 110M å‚æ•°            hidden_size = 768        elif bert_model == &quot;roberta-base&quot;: #             hidden_size = 768        # å›ºå®šBertå±‚ æ›´æ–°åˆ†ç±»è¾“å‡ºå±‚        if freeze_bert:            for p in self.bert_layer.parameters():                p.requires_grad = False                        self.dropout = nn.Dropout(p=0.1)        # åˆ†ç±»è¾“å‡º        self.cls_layer = nn.Linear(hidden_size, 1)    @autocast()  # æ··åˆç²¾åº¦è®­ç»ƒ    def forward(self, input_ids, attn_masks, token_type_ids):        &#x27;&#x27;&#x27;        Inputs:            -input_ids : Tensor  containing token ids            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2        &#x27;&#x27;&#x27;        # è¾“å…¥ç»™Bertï¼Œè·å–ä¸Šä¸‹æ–‡è¡¨ç¤º        # cont_reps, pooler_output = self.bert_layer(input_ids, attn_masks, token_type_ids)        outputs = self.bert_layer(input_ids, attn_masks, token_type_ids)        # last_hidden_state,pooler_output,all_hidden_states 12å±‚        # å°†last layer hidden-state of the [CLS] è¾“å…¥åˆ° classifier layer        # - last_hidden_state çš„å‘é‡å¹³å‡        # - å–all_hidden_statesæœ€åå››å±‚ï¼Œç„¶ååšå¹³å‡ weighted å¹³å‡        # - last_hidden_state+lstm        # è·å–è¾“å‡º        logits = self.cls_layer(self.dropout(outputs[&#x27;pooler_output&#x27;]))        return logits

å›ºå®šéšæœºç§å­12345678910def set_seed(seed):    &quot;&quot;&quot; å›ºå®šéšæœºç§å­ï¼Œä¿è¯ç»“æœå¤ç°    &quot;&quot;&quot;    torch.manual_seed(seed)    torch.cuda.manual_seed_all(seed)    torch.backends.cudnn.deterministic = True    torch.backends.cudnn.benchmark = False    np.random.seed(seed)    random.seed(seed)    os.environ[&#x27;PYTHONHASHSEED&#x27;] = str(seed)

è®­ç»ƒå’Œè¯„ä¼°12!mkdir models 	#å¯ä»¥åœ¨ä¹‹å‰è¡¥å……ç»å¯¹è·¯å¾„!mkdir results



123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596def train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):    best_loss = np.Inf    best_ep = 1    nb_iterations = len(train_loader)    print_every = nb_iterations // 5  # æ‰“å°é¢‘ç‡    iters = []    train_losses = []    val_losses = []    scaler = GradScaler()    for ep in range(epochs):        net.train()        running_loss = 0.0        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(train_loader)):            # è½¬ä¸ºcudaå¼ é‡            seq, attn_masks, token_type_ids, labels = \                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)                # æ··åˆç²¾åº¦åŠ é€Ÿè®­ç»ƒ            with autocast():                # Obtaining the logits from the model                logits = net(seq, attn_masks, token_type_ids)                # Computing loss                loss = criterion(logits.squeeze(-1), labels.float())                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged            # Backpropagating the gradients            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.            scaler.scale(loss).backward()            if (it + 1) % iters_to_accumulate == 0:                # Optimization step                # scaler.step() first unscales the gradients of the optimizer&#x27;s assigned params.                # If these gradients do not contain infs or NaNs, opti.step() is then called,                # otherwise, opti.step() is skipped.                scaler.step(opti)                # Updates the scale for next iteration.                scaler.update()                # æ ¹æ®è¿­ä»£æ¬¡æ•°è°ƒæ•´å­¦ä¹ ç‡ã€‚                lr_scheduler.step()                # æ¢¯åº¦æ¸…é›¶                opti.zero_grad()            running_loss += loss.item()            if (it + 1) % print_every == 0:  # Print training loss information                print()                print(f&quot;Iteration &#123;it+1&#125;/&#123;nb_iterations&#125; of epoch &#123;ep+1&#125; complete. \                Loss : &#123;running_loss / print_every&#125; &quot;)                running_loss = 0.0        val_loss = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss        print()        print(f&quot;Epoch &#123;ep+1&#125; complete! Validation Loss : &#123;val_loss&#125;&quot;)        if val_loss &lt; best_loss:            print(&quot;Best validation loss improved from &#123;&#125; to &#123;&#125;&quot;.format(best_loss, val_loss))            print()            net_copy = copy.deepcopy(net)  # # ä¿å­˜æœ€ä¼˜æ¨¡å‹            best_loss = val_loss            best_ep = ep + 1    # ä¿å­˜æ¨¡å‹    path_to_model=f&#x27;models/&#123;bert_model&#125;_lr_&#123;lr&#125;_val_loss_&#123;round(best_loss, 5)&#125;_ep_&#123;best_ep&#125;.pt&#x27;    torch.save(net_copy.state_dict(), path_to_model)    print(&quot;The model has been saved in &#123;&#125;&quot;.format(path_to_model))    del loss    torch.cuda.empty_cache() # æ¸…ç©ºæ˜¾å­˜    def evaluate_loss(net, device, criterion, dataloader):    &quot;&quot;&quot;    è¯„ä¼°è¾“å‡º    &quot;&quot;&quot;    net.eval()    mean_loss = 0    count = 0    with torch.no_grad():        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):            seq, attn_masks, token_type_ids, labels = \                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)            logits = net(seq, attn_masks, token_type_ids)            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()            count += 1    return mean_loss / count


æ³¨æ„autocastå’Œç´¯è®¡æ¢¯åº¦ è¿™ä¸¤ç§åŠ é€Ÿè®¡ç®—çš„æ–¹æ³•

evaluateçš„æ—¶å€™è¦æ³¨æ„æ•°æ®çš„ç»´åº¦ï¼Œæ ‡ç­¾çš„ç±»å‹


è¶…å‚æ•° &amp; å¼€å§‹è®­ç»ƒ1234567bert_model = &quot;albert-base-v2&quot;  # &#x27;albert-base-v2&#x27;, &#x27;albert-large-v2&#x27;freeze_bert = False  # æ˜¯å¦å†»ç»“Bertmaxlen = 128  # æœ€å¤§é•¿åº¦bs = 16  # batch sizeiters_to_accumulate = 2  # æ¢¯åº¦ç´¯åŠ lr = 2e-5  # learning rateepochs = 2  # è®­ç»ƒè½®æ•°



123456789101112131415161718192021222324252627282930#  å›ºå®šéšæœºç§å­ ä¾¿äºå¤ç°set_seed(1) # 2022 # åˆ›å»ºè®­ç»ƒé›†ä¸éªŒè¯é›†print(&quot;Reading training data...&quot;)train_set = CustomDataset(df_train, maxlen, bert_model)print(&quot;Reading validation data...&quot;)val_set = CustomDataset(df_val, maxlen, bert_model)# å¸¸è§è®­ç»ƒé›†ä¸éªŒè¯é›†DataLoadertrain_loader = DataLoader(train_set, batch_size=bs, num_workers=0)val_loader = DataLoader(val_set, ba ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/26087.html" title="Weight &amp; Bias"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/Asuka/Asuka33.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Weight &amp; Bias"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/26087.html" title="Weight &amp; Bias">Weight &amp; Bias</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-26T09:17:27.733Z" title="å‘è¡¨äº 2022-11-26 17:17:27">2022-11-26</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-06T11:02:19.379Z" title="æ›´æ–°äº 2022-12-06 19:02:19">2022-12-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Trick/">Trick</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/wandb/">wandb</a><span class="article-meta-link">â€¢</span><a class="article-meta__tags" href="/tags/pytorch/">pytorch</a></span></div><div class="content">å¾…å®Œæˆ
æºç ç»†èŠ‚æ•´ç†

torch.inference_mode()with no_gradientçš„ä¸€ç§åŠ é€Ÿ  å‚è€ƒæ–‡æ¡£
 nn.MarginRankingLoss()æ–‡æ¡£ margin &#x3D; 0  x1å¤§äºx2 åˆ™å»-yï¼Œviceversa å– y
*loss(x1,x2,y)&#x3D;max(0,âˆ’yâˆ—(x1âˆ’x2)+margin)*
è¿™é‡Œæœ€åçš„lossæ˜¯å¹³å‡åçš„
1234567891011121314151617181920212223loss = nn.MarginRankingLoss()input1 = torch.randn(3, requires_grad=True)input2 = torch.randn(3, requires_grad=True)target = torch.randn(3).sign()output = loss(input1, input2, target)output.backward()```input1, input2, target, output(tensor([ 0.0277, -0.3806,  1.0405], requires_grad=True), tensor([-0.9075,  0.3271,  0.1156], requires_grad=True), tensor([ 1., -1., -1.]), tensor(0.3083, grad_fn=&lt;MeanBackward0&gt;)) input1 - input2 , (input1 - input2) * (-target)(tensor([ 0.9352, -0.7077,  0.9249], grad_fn=&lt;SubBackward0&gt;), tensor([-0.9352, -0.7077,  0.9249], grad_fn=&lt;MulBackward0&gt;), loss = 0.9249/3 ```



gc.collect()æ¸…é™¤å†…å­˜
defaultdictè·å¾—åˆ›å»ºkeyä¸ç»™valueä¹Ÿä¸æŠ¥é”™çš„dict
12345from collections import defaultdicthistory = defaultdict(list)history[&#x27;Train Loss&#x27;].append(1.1)



StratifiedKFold()12345678from sklearn.model_selection import StratifiedKFold, KFoldskf = StratifiedKFold(n_splits=CONFIG[&#x27;n_fold&#x27;], shuffle=True, random_state=CONFIG[&#x27;seed&#x27;])for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.worker)):    df.loc[val_ , &quot;kfold&quot;] = int(fold)    df[&quot;kfold&quot;] = df[&quot;kfold&quot;].astype(int)

ç¬¬äº”è¡Œ å°†Xåˆ†kæŠ˜ï¼Œyæ ‡ç­¾ä¸ºæ ·æœ¬å¯¹åº”indexï¼Œfold åœ¨ 0~5
å¾—åˆ°df[â€œkfoldâ€] åˆ—åŒ…å« å±äºç¬¬å‡ æŠ˜çš„ validæ•°æ®
é€šè¿‡ä¸‹é¢çš„å‡½æ•°ç›´æ¥é€‰æ‹©éæœ¬æŠ˜çš„æ•°æ®ä½œä¸ºtrainï¼Œå…¶ä»–çš„å°±æ˜¯valid
df_train = df[df.kfold != fold].reset_index(drop=True) df_valid = df[df.kfold == fold].reset_index(drop=True)
12345678910111213def prepare_loaders(fold):    df_train = df[df.kfold != fold].reset_index(drop=True)    df_valid = df[df.kfold == fold].reset_index(drop=True)        train_dataset = JigsawDataset(df_train, tokenizer=CONFIG[&#x27;tokenizer&#x27;], max_length=CONFIG[&#x27;max_length&#x27;])    valid_dataset = JigsawDataset(df_valid, tokenizer=CONFIG[&#x27;tokenizer&#x27;], max_length=CONFIG[&#x27;max_length&#x27;])    train_loader = DataLoader(train_dataset, batch_size=CONFIG[&#x27;train_batch_size&#x27;],                               num_workers=2, shuffle=True, pin_memory=True, drop_last=True)    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG[&#x27;valid_batch_size&#x27;],                               num_workers=2, shuffle=False, pin_memory=True)        return train_loader, valid_loade



tqdm1bar = tqdm(enumerate(dataloader), total=len(dataloader))

å•ä¸ªepochä¸‹é¢å¯¹baråšå¦‚ä¸‹è®¾ç½®
12bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,                        LR=optimizer.param_groups[0][&#x27;lr&#x27;])  



Weights &amp; Biases (W&amp;B) 
hash ä¸€ä¸ªé¡¹ç›®id

train valid å®šä¹‰ä¸€ä¸ª 1ä¸ªepoch çš„å‡½æ•° è¿”å› åˆ†åˆ«å…¶ä¸­çš„loss

wandb.log({â€œTrain Lossâ€: train_epoch_loss}) ä½¿ç”¨ log æ–¹å¼è®°å½• æŸå¤±å‡½æ•°

run = wandb.init(project=&#39;Jigsaw&#39;, 
                     config=CONFIG,
                     job_type=&#39;Train&#39;,
                     group=CONFIG[&#39;group&#39;],
                     tags=[&#39;roberta-base&#39;, f&#39;&#123;HASH_NAME&#125;&#39;, &#39;margin-loss&#39;],
                     name=f&#39;&#123;HASH_NAME&#125;-fold-&#123;fold&#125;&#39;,
                     anonymous=&#39;must&#39;)
1TRAIN PART

run.finish()

1234æ˜¾ç¤ºå¦‚ä¸‹			&#x27;hash--------name&#x27;Syncing run k5nu8k69390a-fold-0 to Weights &amp; Biases (docs).



æµç¨‹è®­ç»ƒæç‚¼
for fold in range(0, CONFIG[â€˜n_foldâ€™])
wandb.init
prepare_loadersã€fetch_scheduler
run_training
train_one_epochã€valid_one_epoch â€”-&gt; to got model, loss for wandb



ä¸­é—´æºæ‚ W&amp;B çš„æ•°æ®å®æ—¶è½½å…¥åˆ†æå³å¯
df[â€˜yâ€™].value_counts(normalize&#x3D;True) to got the percentage of each values
åŸæ–‡é“¾æ¥
</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/45348.html" title="HF 02"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris12.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HF 02"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/45348.html" title="HF 02">HF 02</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-21T08:59:54.815Z" title="å‘è¡¨äº 2022-11-21 16:59:54">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-06T10:59:33.572Z" title="æ›´æ–°äº 2022-12-06 18:59:33">2022-12-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Universe/">Universe</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/HuggingFace/">HuggingFace</a><span class="article-meta-link">â€¢</span><a class="article-meta__tags" href="/tags/Bert/">Bert</a></span></div><div class="content">å¾…å®Œæˆ
ç¤ºä¾‹è¯¦è§£

Transformeråˆ†ä¸¤å—BERT&amp;GPTéƒ½å¾ˆèƒ½æ‰“
BERTç”¨çš„æ˜¯transformerçš„encoder

BERTæ˜¯ç”¨äº†Transformerçš„encoderä¾§çš„ç½‘ç»œï¼Œencoderä¸­çš„Self-attentionæœºåˆ¶åœ¨ç¼–ç ä¸€ä¸ªtokençš„æ—¶å€™åŒæ—¶åˆ©ç”¨äº†å…¶ä¸Šä¸‹æ–‡çš„tokenï¼Œå…¶ä¸­â€˜åŒæ—¶åˆ©ç”¨ä¸Šä¸‹æ–‡â€™å³ä¸ºåŒå‘çš„ä½“ç°ï¼Œè€Œå¹¶éæƒ³Bi-LSTMé‚£æ ·æŠŠå¥å­å€’åºè¾“å…¥ä¸€éã€‚


GPTç”¨çš„æ˜¯transformerçš„decoder

åœ¨å®ƒä¹‹å‰æ˜¯GPTï¼ŒGPTä½¿ç”¨çš„æ˜¯Transformerçš„decoderä¾§çš„ç½‘ç»œï¼ŒGPTæ˜¯ä¸€ä¸ªå•å‘è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒè¿‡ç¨‹ï¼Œæ›´é€‚ç”¨äºæ–‡æœ¬ç”Ÿæˆï¼Œé€šè¿‡å‰æ–‡å»é¢„æµ‹å½“å‰çš„å­—ã€‚



Bertçš„embeddingEmbeddingç”±ä¸‰ç§Embeddingæ±‚å’Œè€Œæˆï¼š

Token Embeddingsæ˜¯è¯å‘é‡ï¼Œç¬¬ä¸€ä¸ªå•è¯æ˜¯CLSæ ‡å¿—ï¼Œå¯ä»¥ç”¨äºä¹‹åçš„åˆ†ç±»ä»»åŠ¡

BERTåœ¨ç¬¬ä¸€å¥å‰ä¼šåŠ ä¸€ä¸ª[CLS]æ ‡å¿—ï¼Œæœ€åä¸€å±‚è¯¥ä½å¯¹åº”å‘é‡å¯ä»¥ä½œä¸ºæ•´å¥è¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œä»è€Œç”¨äºä¸‹æ¸¸çš„åˆ†ç±»ä»»åŠ¡ç­‰ã€‚å› ä¸ºä¸æ–‡æœ¬ä¸­å·²æœ‰çš„å…¶å®ƒè¯ç›¸æ¯”ï¼Œè¿™ä¸ªæ— æ˜æ˜¾è¯­ä¹‰ä¿¡æ¯çš„ç¬¦å·ä¼šæ›´â€œå…¬å¹³â€åœ°èåˆæ–‡æœ¬ä¸­å„ä¸ªè¯çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä»è€Œæ›´å¥½çš„è¡¨ç¤ºæ•´å¥è¯çš„è¯­ä¹‰ã€‚ å…·ä½“æ¥è¯´ï¼Œself-attentionæ˜¯ç”¨æ–‡æœ¬ä¸­çš„å…¶å®ƒè¯æ¥å¢å¼ºç›®æ ‡è¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œä½†æ˜¯ç›®æ ‡è¯æœ¬èº«çš„è¯­ä¹‰è¿˜æ˜¯ä¼šå ä¸»è¦éƒ¨åˆ†çš„ï¼Œå› æ­¤ï¼Œç»è¿‡BERTçš„12å±‚ï¼ˆBERT-baseä¸ºä¾‹ï¼‰ï¼Œæ¯æ¬¡è¯çš„embeddingèåˆäº†æ‰€æœ‰è¯çš„ä¿¡æ¯ï¼Œå¯ä»¥å»æ›´å¥½çš„è¡¨ç¤ºè‡ªå·±çš„è¯­ä¹‰ã€‚è€Œ[CLS]ä½æœ¬èº«æ²¡æœ‰è¯­ä¹‰ï¼Œç»è¿‡12å±‚ï¼Œå¥å­çº§åˆ«çš„å‘é‡ï¼Œç›¸æ¯”å…¶ä»–æ­£å¸¸è¯ï¼Œå¯ä»¥æ›´å¥½çš„è¡¨å¾å¥å­è¯­ä¹‰ã€‚


Segment Embeddingsç”¨æ¥åŒºåˆ«ä¸¤ç§å¥å­ï¼Œå› ä¸ºé¢„è®­ç»ƒä¸å…‰åšLMè¿˜è¦åšä»¥ä¸¤ä¸ªå¥å­ä¸ºè¾“å…¥çš„åˆ†ç±»ä»»åŠ¡

Position Embeddingså’Œä¹‹å‰æ–‡ç« ä¸­çš„Transformerä¸ä¸€æ ·ï¼Œä¸æ˜¯ä¸‰è§’å‡½æ•°è€Œæ˜¯å­¦ä¹ å‡ºæ¥çš„


APItokenizer12345678910111213141516171819202122232425262728293031323334from transformers import AutoConfig,AutoModel,AutoTokenizer,AdamW,get_linear_schedule_with_warmup,logging# configæ¨¡å—MODEL_NAME=&quot;bert-base-chinese&quot;config = AutoConfig.from_pretrained(MODEL_NAME) #c onfigå¯ä»¥é…ç½®æ¨¡å‹ä¿¡æ¯# tokenizeræ¨¡å—tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)tokenizer.all_special_ids # æŸ¥çœ‹ç‰¹æ®Šç¬¦å·çš„id [100, 102, 0, 101, 103]tokenizer.all_special_tokens # æŸ¥çœ‹token  [&#x27;[UNK]&#x27;, &#x27;[SEP]&#x27;, &#x27;[PAD]&#x27;, &#x27;[CLS]&#x27;, &#x27;[MASK]&#x27;]tokenizer.vocab_size # è¯æ±‡è¡¨å¤§å°tokenizer.vocab # è¯æ±‡å¯¹åº”çš„dictå½¢å¼## tokeningtext=&quot;æˆ‘åœ¨åŒ—äº¬å·¥ä½œ&quot;token_ids=tokenizer.encode(text)token_ids # [101, 2769, 1762, 1266, 776, 2339, 868, 102]tokenizer.convert_ids_to_tokens(token_ids) # [&#x27;[CLS]&#x27;, &#x27;æˆ‘&#x27;, &#x27;åœ¨&#x27;, &#x27;åŒ—&#x27;, &#x27;äº¬&#x27;, &#x27;å·¥&#x27;, &#x27;ä½œ&#x27;, &#x27;[SEP]&#x27;]		  # convert_tokens_to_ids(tokens) ä¸ºå¯¹åº”æ–¹æ³•    ## padding åšå‘é‡å¡«å……token_ids=tokenizer.encode(text,padding=True,max_length=30,add_special_tokens=True)## encode_plustoken_ids=tokenizer.encode_plus(    text,padding=&quot;max_length&quot;,    max_length=30,    add_special_tokens=True,    return_tensors=&#x27;pt&#x27;,    return_token_type_ids=True,    return_attention_mask=True)



ä½¿ç”¨pre_trainæ¨¡å‹è½½å…¥æ•°æ®12model=AutoModel.from_pretrained(MODEL_NAME)outputs=model(token_ids[&#x27;input_ids&#x27;],token_ids[&#x27;attention_mask&#x27;])



æ•°æ®é›†datasetå®šä¹‰12345678910111213141516171819202122232425262728293031323334class EnterpriseDataset(Dataset):    def __init__(self,texts,labels,tokenizer,max_len):        self.texts=texts        self.labels=labels        self.tokenizer=tokenizer        self.max_len=max_len    def __len__(self):        return len(self.texts)        def __getitem__(self,item):        &quot;&quot;&quot;        item ä¸ºæ•°æ®ç´¢å¼•ï¼Œè¿­ä»£å–ç¬¬itemæ¡æ•°æ®        &quot;&quot;&quot;        text=str(self.texts[item])        label=self.labels[item]                encoding=self.tokenizer.encode_plus(            text,            add_special_tokens=True,            max_length=self.max_len,            return_token_type_ids=True,            pad_to_max_length=True,            return_attention_mask=True,            return_tensors=&#x27;pt&#x27;,  #è½¬ä¸ºtensor        )        #print(encoding[&#x27;input_ids&#x27;])        return &#123;            &#x27;texts&#x27;:text,            &#x27;input_ids&#x27;:encoding[&#x27;input_ids&#x27;].flatten(),            &#x27;attention_mask&#x27;:encoding[&#x27;attention_mask&#x27;].flatten(),            # toeken_type_ids:0            &#x27;labels&#x27;:torch.tensor(label,dtype=torch.long)        &#125;

</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/3/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/#content-inner">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/#content-inner">5</a><a class="extend next" rel="next" href="/page/5/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/eris11.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Poy One</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/poyone"><i></i><span>ğŸ›´å‰å¾€github...</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">æ¬¢è¿æ¥åˆ°æˆ‘çš„åšå®¢ <br> QQ 914987163</div></div><div class="sticky_layout"><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>ç½‘ç«™èµ„è®¯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">æ–‡ç« æ•°ç›® :</div><div class="item-count">27</div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™æ€»å­—æ•° :</div><div class="item-count">49.9k</div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™è®¿å®¢æ•° :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™æ€»è®¿é—®é‡ :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">æœ€åæ›´æ–°æ—¶é—´ :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-12-15T14:44:59.079Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Poy One</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script defer src="/js/light.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#web_bg",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 380px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 320px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka15.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/CV/&quot;);" href="javascript:void(0);">CV</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">è®¡ç®—æœºè§†è§‰</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka22.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/NLP/&quot;);" href="javascript:void(0);">NLP</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">è‡ªç„¶è¯­è¨€å¤„ç†</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka10.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Trick/&quot;);" href="javascript:void(0);">Trick</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">import torch as tf</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka29.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Dive-Into-Paper/&quot;);" href="javascript:void(0);">Dive Into Paper</a><span class="categoryBar-list-count">4</span><span class="categoryBar-list-descr">è®ºæ–‡ç²¾è¯»</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka16.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Python/&quot;);" href="javascript:void(0);">Python</a><span class="categoryBar-list-count">3</span><span class="categoryBar-list-descr">æµç•…çš„Python</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka32.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Universe/&quot;);" href="javascript:void(0);">Universe</a><span class="categoryBar-list-count">13</span><span class="categoryBar-list-descr">æ‹¥æœ‰ä¸€åˆ‡ å´å˜æˆå¤ªç©º</span></li></ul></div></div>';
      console.log('å·²æŒ‚è½½butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><!-- hexo injector body_end end --></body></html>