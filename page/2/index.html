<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Attention Is A Talent</title><meta name="author" content="Poy One"><meta name="copyright" content="Poy One"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Attention Is A Talent">
<meta property="og:url" content="https://poyone.github.io/page/2/index.html">
<meta property="og:site_name" content="Attention Is A Talent">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.imagehub.cc/images/2022/11/20/375c6e3994a1f2472da5b34c26e48f18ab750e42.jpg942w_1332h_progressive.webp">
<meta property="article:author" content="Poy One">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.imagehub.cc/images/2022/11/20/375c6e3994a1f2472da5b34c26e48f18ab750e42.jpg942w_1332h_progressive.webp"><link rel="shortcut icon" href="https://s1.imagehub.cc/images/2022/11/20/375c6e3994a1f2472da5b34c26e48f18ab750e42.jpg942w_1332h_progressive.webp"><link rel="canonical" href="https://poyone.github.io/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Attention Is A Talent',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-11-22 21:03:21'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card@1.0.0/lib/categorybar.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/20/375c6e3994a1f2472da5b34c26e48f18ab750e42.jpg942w_1332h_progressive.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://s1.imagehub.cc/images/2022/11/20/1199109.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Attention Is A Talent</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Attention Is A Talent</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/08%20QA_v2/" title="04 QA_v2"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/22/Mushoku.Tensei_.Isekai.Ittara.Honki.Dasu.full.3542652.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="04 QA_v2"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/08%20QA_v2/" title="04 QA_v2">04 QA_v2</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:15.057Z" title="发表于 2022-11-21 10:16:15">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-21T08:21:34.951Z" title="更新于 2022-11-21 16:21:34">2022-11-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/QA/">QA</a></span></div><div class="content">答案偏移加入问题之后，答案的偏移
DataLoader 坐标data[‘train’] [idx] [‘input_ids’]
data[‘train’] [idx] [‘token_type_ids’]
data[‘train’] [idx] [‘attention_mask’]
…
Model 输入只能是{‘input_ids’:sample[0], ‘token_type_ids’:sample[1], ‘attention_mask’:sample[2], ‘start_positions’:sample[3], ‘end_positions’:sample[4]}
进行字典解包 model(**inputs)
分布训练Code1.导包123456789101112131415import torchimport torch.nn as nnimport osimport copyimport torch.optim as optimimport randomimport numpy as npimport pandas as pdfrom torch.utils.data import DataLoader, Datasetfrom torch.cuda.amp import autocast, GradScalerfrom tqdm.auto import tqdmfrom transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmupfrom datasets import load_dataset, load_metricfrom transformers import AutoModelForQuestionAnsweringfrom datasets import load_dataset
2.文件路径12345678train_path = &#x27;../input/ml2022spring-hw7/hw7_train.json&#x27;dev_path = &#x27;../input/ml2022spring-hw7/hw7_dev.json&#x27;test_path = &#x27;../input/ml2022spring-hw7/hw7_test.json&#x27;model_name = &#x27;hfl/chinese-bert-wwm-ext&#x27;!mkdir models  #可以在之前补充绝对路径!mkdir results

3.固定种子1234567891011def set_seed(seed):    &quot;&quot;&quot; 固定随机种子，保证结果复现    &quot;&quot;&quot;    torch.manual_seed(seed)    torch.cuda.manual_seed_all(seed)    torch.backends.cudnn.deterministic = True    torch.backends.cudnn.benchmark = False    np.random.seed(seed)    random.seed(seed)    os.environ[&#x27;PYTHONHASHSEED&#x27;] = str(seed)set_seed(1222)

4.预处理4.1转换json格式12345678910111213141516171819import jsondef open_json(file_path):    with open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as f:        data = json.load(f)        return datadef txt_json(file_path):    dt = open_json(file_path)    for i in range(len(dt[&#x27;questions&#x27;])):        pg_id = dt[&#x27;questions&#x27;][i][&#x27;paragraph_id&#x27;]        dt[&#x27;questions&#x27;][i][&#x27;context&#x27;] = dt[&#x27;paragraphs&#x27;][pg_id]    return dtdef save_json(file_path, save_name):    info = txt_json(file_path)    with open(save_name, &#x27;w&#x27;) as f:        json.dump(info, f)        save_json(train_path, &#x27;qa_dataset.json&#x27;)save_json(dev_path, &#x27;dev_dataset.json&#x27;)

&#x3D;&#x3D;4.2处理答案偏移&#x3D;&#x3D;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def preprocess_function(examples):    questions = [q.strip() for q in examples[&quot;question_text&quot;]]    inputs = tokenizer(        questions,        examples[&quot;context&quot;],        max_length=384,        truncation=&quot;only_second&quot;,        return_offsets_mapping=True,        padding=&quot;max_length&quot;,        stride = 128,        return_overflowing_tokens=True,    )    offset_mapping = inputs.pop(&quot;offset_mapping&quot;)    sample_map = inputs.pop(&#x27;overflow_to_sample_mapping&#x27;)    start_positions = []    end_positions = []    for i, offset in enumerate(offset_mapping):        sample_idx = sample_map[i]        start_char = examples[&quot;answer_start&quot;][sample_idx]        end_char = examples[&quot;answer_start&quot;][sample_idx]+ len(examples[&quot;answer_text&quot;][sample_idx])+1        sequence_ids = inputs.sequence_ids(i)        idx = 0        while sequence_ids[idx] != 1:            idx += 1        context_start = idx        while sequence_ids[idx] == 1:            idx += 1        context_end = idx - 1        if offset[context_start][0] &gt; end_char or offset[context_end][1] &lt; start_char:            start_positions.append(0)            end_positions.append(0)        else:            idx = context_start            while idx &lt;= context_end and offset[idx][0] &lt;= start_char:                idx += 1            start_positions.append(idx - 1)            idx = context_end            while idx &gt;= context_start and offset[idx][1] &gt;= end_char:                idx -= 1            end_positions.append(idx + 1)    inputs[&quot;start_positions&quot;] = start_positions    inputs[&quot;end_positions&quot;] = end_positions    return inputsdef deal_dataset(file_path):    data_type = load_dataset(&quot;json&quot;, data_files=file_path, field=&#x27;questions&#x27;)    dataset = data_type.map(preprocess_function, batched=True, remove_columns=data_type[&quot;train&quot;].column_names)    return dataset

5.加载数据1234567tokenizer = AutoTokenizer.from_pretrained(model_name)json_train_path = &#x27;./qa_dataset.json&#x27;json_dev_path = &#x27;./dev_dataset.json&#x27;train_json_dataset = deal_dataset(json_train_path)dev_json_dataset = deal_dataset(json_dev_path)

6.Dataset DataLoader Model 三兄弟6.1dataset &amp; dataloader123456789101112131415161718192021class mydataset(Dataset):    def __init__(self, data):        self.data = data[&#x27;train&#x27;]    def __len__(self):        return len(self.data)    def __getitem__(self, idx):        input_ids = torch.tensor(self.data[idx][&#x27;input_ids&#x27;])        token_type_ids = torch.tensor(self.data[idx][&#x27;token_type_ids&#x27;])        attention_mask = torch.tensor(self.data[idx][&#x27;attention_mask&#x27;])        start_positions = torch.tensor(self.data[idx][&#x27;start_positions&#x27;])        end_positions = torch.tensor(self.data[idx][&#x27;end_positions&#x27;])                return input_ids, token_type_ids, attention_mask, start_positions, end_positions    train_dataset = mydataset(train_json_dataset)train_dataloader = DataLoader(train_dataset, batch_size=4)dev_dataset = mydataset(dev_json_dataset)dev_dataloader = DataLoader(dev_dataset, batch_size=4)

6.2model1model = AutoModelForQuestionAnswering.from_pretrained(model_name)
7.训练123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172def train_bert(net, device, opti, lr, train_loader, val_loader, epochs, iters_to_accumulate, bert_model):    best_loss = np.Inf    best_ep = 1    nb_iterations = len(train_loader)    print_every = nb_iterations // 5  # 打印频率    iters = []    train_losses = []    val_losses = []    for ep in range(epochs):        net.train()        running_loss = 0.0        for it, batch in enumerate(tqdm(train_loader)):            with autocast():                #这里的解包，可以换成元组或者字典                input_ids, token_type_ids, attention_mask, start_positions, end_positions = batch                input_ids, token_type_ids, attention_mask, start_positions, end_positions = input_ids.to(device), token_type_ids.to(device), attention_mask.to(device), start_positions.to(device), end_positions.to(device)                                outputs = net(**&#123;&#x27;input_ids&#x27;:input_ids, &#x27;token_type_ids&#x27;:token_type_ids, &#x27;attention_mask&#x27;:attention_mask, &#x27;start_positions&#x27;:start_positions, &#x27;end_positions&#x27;:end_positions&#125;)                                loss = outputs.loss                loss.backward()                opti.zero_grad()                opti.step()                            running_loss += loss.item()            if (it + 1) % print_every == 0:                 print()                print(f&quot;Iteration &#123;it+1&#125;/&#123;nb_iterations&#125; of epoch &#123;ep+1&#125; complete. \                Loss : &#123;running_loss / print_every&#125; &quot;)                running_loss = 0.0        val_loss = evaluate_loss(net, device, val_loader)  # Compute validation loss        print()        print(f&quot;Epoch &#123;ep+1&#125; complete! Validation Loss : &#123;val_loss&#125;&quot;)        if val_loss &lt; best_loss:            print(&quot;Best validation loss improved from &#123;&#125; to &#123;&#125;&quot;.format(best_loss, val_loss))            print()            net_copy = copy.deepcopy(net)              best_loss = val_loss            best_ep = ep + 1    path_to_model=f&#x27;models/&#123;bert_model&#125;_lr_&#123;lr&#125;_val_loss_&#123;round(best_loss, 5)&#125;_ep_&#123;best_ep&#125;.pt&#x27;    torch.save(net_copy.state_dict(), path_to_model)    print(&quot;The model has been saved in &#123;&#125;&quot;.format(path_to_model))    del loss    torch.cuda.empty_cache()    def evaluate_loss(net, device, dataloader):    net.eval()    mean_loss = 0    count = 0    with torch.no_grad():        for it, batch in enumerate(tqdm(dataloader)):            input_ids, token_type_ids, attention_mask, start_positions, end_positions = batch            input_ids, token_type_ids, attention_mask, start_positions, end_positions = input_ids.to(device), token_type_ids.to(device), attention_mask.to(device), start_positions.to(device), end_positions.to(device)                        outputs = net(**&#123;&#x27;input_ids&#x27;:input_ids, &#x27;token_type_ids&#x27;:token_type_ids, &#x27;attention_mask&#x27;:attention_mask, &#x27;start_positions&#x27;:start_positions, &#x27;end_positions&#x27;:end_positions&#125;)            loss = outputs.loss            mean_loss += loss.item()                        count += 1    return mean_loss / count



8.超参数 &amp; 分布式训练&#x3D;&#x3D;nn.DataParallel(model)方式已经过时&#x3D;&#x3D;，现在使用nn.parallel.DistributedDataParallel的API进行处理
DistributedDataParallel主要通过三个函数布置且需要安装NVIDIA的apex库

使用argparse布置通道、进程编号、指定的GPU等

12345678910111213141516171819202122import argparseimport torch.distributed as distparser = argparse.ArgumentParser()    parser.add_argument(&#x27;-n&#x27;, &#x27;--nodes&#x27;, default=1, type=int, metavar=&#x27;N&#x27;)    parser.add_argument(&#x27;-g&#x27;, &#x27;--gpus&#x27;, default=1, type=int,                        help=&#x27;number of gpus per node&# ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/08%20QA_v1/" title="04 QA_v1"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/20/d8bb56e073fef6e542612ede2bb337b7c20362c9.jpg942w_1332h_progressive.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="04 QA_v1"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/08%20QA_v1/" title="04 QA_v1">04 QA_v1</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:15.031Z" title="发表于 2022-11-21 10:16:15">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-21T08:21:30.583Z" title="更新于 2022-11-21 16:21:30">2022-11-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/QA/">QA</a></span></div><div class="content">API &amp; tricktokenizer中的
return_offsets_mapping  返回一个元组如( 0 , 1 ) 由于[CLS]的加入第一个字符的位置从0 边为 1

即(x , y)  x表示元素在这句截断的话中的

	

return_overflowing_tokens  #似乎没什么必要

在设定了stride才有用
由于滑窗将句子分割，此参数为True之后，将标记每个部分属于哪个序号
如长为 500的句子， stride &#x3D; 50， max_length&#x3D;200,
分组为【0,199】【149,349】【300,499】
设置参数后返回一个 [0，0，0] 表示三个列表属于0号段落




truncation ‘only second’ 表示 传入tonkinzer的一对句子( question， txt) 对第二个 (txt) 截断 question就不截断

inputs.sequence_ids(2) 表示 return_overflowing_tokens 后 input_ids的第三个列表


小结
return_overflowing_tokens 返回的是这种，使得截断后滑动窗口，返回多个数组，不滑动就没用了
且设定的每组都是【question，strided_context】
&#x3D;&#x3D;这是问题(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (0, 0)&#x3D;&#x3D; 每个分组都有吧


1[[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (0, 0)], [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (0, 0), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (34, 35), (0, 0)], 


return_offsets_mapping 返回的数组如上图所示，[CLS]的加入使得每次断句滑动之后起始下标都会加一，
而分组内的下标属于继承制。
 (0, 0), (15, 16), (16, 17), 如同这个，这里stride&#x3D;5 ，在第一句(6, 7), (0, 0), (0, 1),。。。。 (18, 19), (19, 20), (0, 0)这里结束
倒数五个数，拿到(15, 16), 即从这里开始

inputs.sequence_ids() 括号内设定为 input_ids的分组的编号
inputs.sequence_ids(0) 如下
&#x3D;&#x3D;None 0 0 0 0 0 0 0 None 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 None&#x3D;&#x3D;
[0,0] 代表【CLS】会被直接设成none， 将question和context 以0,1分离表示，方便下面处理
[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (0, 0)]


​	
官网套路12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def preprocess_function(examples):    questions = [q.strip() for q in examples[&quot;question&quot;]]    inputs = tokenizer(        questions,        examples[&quot;context&quot;],        max_length=384,        truncation=&quot;only_second&quot;,        return_offsets_mapping=True,        padding=&quot;max_length&quot;,    )    offset_mapping = inputs.pop(&quot;offset_mapping&quot;)    answers = examples[&quot;answers&quot;]    start_positions = []    end_positions = []    for i, offset in enumerate(offset_mapping):        answer = answers[i]        start_char = answer[&quot;answer_start&quot;][0]        end_char = answer[&quot;answer_start&quot;][0] + len(answer[&quot;text&quot;][0])        sequence_ids = inputs.sequence_ids(i)        # Find the start and end of the context        idx = 0        while sequence_ids[idx] != 1:            idx += 1        context_start = idx        while sequence_ids[idx] == 1:            idx += 1        context_end = idx - 1        # If the answer is not fully inside the context, label it (0, 0)        if offset[context_start][0] &gt; end_char or offset[context_end][1] &lt; start_char:            start_positions.append(0)            end_positions.append(0)        else:            # Otherwise it&#x27;s the start and end token positions            idx = context_start            while idx &lt;= context_end and offset[idx][0] &lt;= start_char:                idx += 1            start_positions.append(idx - 1)            idx = context_end            while idx &gt;= context_start and offset[idx][1] &gt;= end_char:                idx -= 1            end_positions.append(idx + 1)    inputs[&quot;start_positions&quot;] = start_positions    inputs[&quot;end_positions&quot;] = end_positions    return inputstokenized_squad = squad.map(preprocess_function,batched=True,remove_columns=squad[&quot;train&quot;].column_names)

offset内是本批次的字符排序，包含了CLS等特殊符的占位，
这种：(6, 7), (0, 0), (15, 16), (16, 17), (17, 18),
想把answer的原始位置映射，如原始answer【515,519】
首先offset是个列表idx表示坐标，由第一个while找到（x，y）中x大于515的第一个 那个idx就是 answer的起始
​															找到第一个小于 y的那个idx 对应的就是 answer的结束了。
每次处理的是一个问答格式(json)
12345678squad[&quot;train&quot;][0]&#123;&#x27;answers&#x27;: &#123;&#x27;answer_start&#x27;: [515], &#x27;text&#x27;: [&#x27;Saint Bernadette Soubirous&#x27;]&#125;, &#x27;context&#x27;: &#x27;Architecturally, the school has a Catholic character. Atop the Main Building\&#x27;s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend &quot;Venite Ad Me Omnes&quot;. Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.&#x27;, &#x27;id&#x27;: &#x27;5733be284776f41900661182&#x27;, &#x27;question&#x27;: &#x27;To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?&#x27;, &#x27;title&#x27;: &#x27;University_of_Notre_Dame&#x27;&#125;

真不容易啊这波，加油
总结以下为零号样本
12345&#123;&#x27;id&#x27;: &#x27;TRAIN_186_QUERY_0&#x27;, &#x27;title&#x27;: &#x27;范廷颂&#x27;, &#x27;context&#x27;: &#x27;范廷颂枢机（，），圣名保禄·若瑟（），是越南罗马天主教枢机。1963年被任为主教；1990年被擢升为天主教河内总教区宗座署理；1994年被擢升为总主教，同年年底被擢升为枢机；2009年2月离世。范廷颂于1919年6月15日在越南宁平省天主教发艳教区出生；童年时接受良好教育后，被一位越南神父带到河内继续其学业。范廷颂于1940年在河内大修道院完成神学学业。范廷颂于1949年6月6日在河内的主教座堂晋铎；及后被派到圣女小德兰孤儿院服务。1950年代，范廷颂在河内堂区创建移民接待中心以收容到河内避战的难民。1954年，法越战争结束，越南民主共和国建都河内，当时很多天主教神职人员逃至越南的南方，但范廷颂仍然留在河内。翌年管理圣若望小修院；惟在1960年因捍卫修院的自由、自治及拒绝政府在修院设政治课的要求而被捕。1963年4月5日，教宗任命范廷颂为天主教北宁教区主教，同年8月15日就任；其牧铭为「我信天主的爱」。由于范廷颂被越南政府软禁差不多30年，因此他无法到所属堂区进行牧灵工作而专注研读等工作。范廷颂除了面对战争、贫困、被当局迫害天主教会等问题外，也秘密恢复修院、创建女修会团体等。1990年，教宗若望保禄二世在同年6月18日擢升范廷颂为天主教河内总教区宗座署理以填补该教区总主教的空缺。1994年3月23日，范廷颂被教宗若望保禄二世擢升为天主教河内总教区总主教并兼天主教谅山教区宗座署理；同年11月26日，若望保禄二世擢升范廷颂为枢机。范廷颂在1995年至2001年期间出任天主教越南主教团主席。2003年4月26日，教宗若望保禄二世任命天主教谅山教区兼天主教高平教区吴光杰主教为天主教河内总教区署理主教；及至2005年2月19日，范廷颂因获批辞去总主教职务而荣休；吴光杰同日真除天主教河内总教区总主教职务。范廷颂于2009年2月22日清晨在河内离世，享年89岁；其葬礼于同月26日上午在天主教河内总教区总主教座堂举行。&#x27;, &#x27;question&#x27;: &#x27;范廷颂是什么时候被任为主教的？&#x27;, &#x27;answers&#x27;: &#123;&#x27;text&#x27;: [&#x27;1963年&#x27;], &#x27;answer_start&#x27;: [30]&#125;&#125;

对其编码
123456789101112context = train_data[0][&quot;context&quot;] # question = train_data[0][&quot;question&quot;]inputs = tokenizer(    question,    context,    max_length=300,# 最大长度    truncation=&quot;only_second&quot;,# 仅对第二个输入进行截断    stride=50,# 滑动窗口大小为50    return_overflowing_tokens=True,#设定分词器支持返回重叠 token。    return_offsets_mapping=True)

结果如下，input_ids、token_type_ids、attention_mask就省略了
滑动窗口50，最大长度300，对814的样本做四个分割，（0,299）（250,549）（500,799）（749,815）四份
offset记录的就是一个字符【‘汗’】对应的token_id, 它可能中间有【SEP】等符号，所以有些offset不只是1-2，可能是1-4等跨度
可以看到每一份都是【question+context[i]】的组合，前面都是问题，后面是文章
1&#x27;offset_mapping&#x27;: [[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (30, 34), (34, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 40), (40, 41), (41, 45), (45, 46), (46, 47), (47, 48), (48, 49), (49, 50), (50, 51), (51, 52), (52, 53), (53, 54), (54, 55), (55, 56), (56, 57), (57, 58), (58, 59), (59, 60), (60, 61), (61, 62), (62, 63), (63, 67), (67, 68), (68, 69), (69, 70), (70, 71), (71, 72), (72, 73), (73, 74), (74, 75), (75, 76), (76, 77), (77, 78), (78, 79), (79, 80), (80, 81), (81, 82), (82, 83), (83, 84), (84, 85), (85, 86), (86, 87), (87, 91), (91, 92), (92, 93), (93, 94), (94, 95), (95, 96), (96, 97), (97, 98), (98, 99), (99, 100), (100, 101), (101, 105), (105, 106), (106, 107), (107, 108), (108, 110), (110, 111), (111, 112), (112, 113), (113, 114), (114, 115), (115, 116), (116, 117), (117, 118), (118, 119), (119, 120), (120, 121), (121, 122), (122, 123), (123, 124), (124, 125), (125, 126), (126, 127), (127, 128), (128, 129), (129, 130), (130, 131), (131, 132), (132, 133), (133, 134), (134, 135), (135, 136), (136, 137), (137, 138), (138, 139), (139, 140), (140, 141), (141, 142), (142, 143), (143, 144), (144, 145), (145, 146), (146, 147), (147, 148), (148, 149), (149, 150), (150, 151), (151, 152), (152, 153), (153, 154), (154, 155), (155, 156), (156, 157), (157, 158), (158, 159), (159, 163), (163, 164), (164, 165), (165, 166), (166, 167), (167, 168), (168, 169), (169, 170), (170, 171), (171, 172), (172, 173), (173, 174), (174, 175), (175, 176), (176, 177), (177, 178), (178, 179), (179, 180), (180, 181), (181, 182), (182, 186), (186, 187), (187, 188), (188, 189), (189, 190), (190, 191), (191, 192), (192, 193), (193, 194), (194, 195), (195, 196), (196, 197), (197, 198), (198, 199), (199, 200), (200, 201), (201, 202), (202, 203), (203, 204), (204, 205), (205, 206), (206, 207), (207, 208), (208, 209), (209, 210), (210, 211), (211, 212), (212, 213), (213, 214), (214, 215), (215, 216), (216, 217), (217, 218), (218, 222), (222, 223), (223, 224), (224, 225), (225, 226), (226, 227), (227, 228), (228, 229), (229, 230), (230, 231), (231, 232), (232, 233), (233 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/03%20Pipeline%20%E5%8F%A5%E5%AD%90%E7%9B%B8%E4%BC%BC%E5%BA%A6/" title="03 Pipeline 句子相似度"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/22/Souryuu.Asuka.Langley.full.3048639.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="03 Pipeline 句子相似度"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/03%20Pipeline%20%E5%8F%A5%E5%AD%90%E7%9B%B8%E4%BC%BC%E5%BA%A6/" title="03 Pipeline 句子相似度">03 Pipeline 句子相似度</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:15.021Z" title="发表于 2022-11-21 10:16:15">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-21T08:21:26.326Z" title="更新于 2022-11-21 16:21:26">2022-11-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%8F%A5%E6%84%8F%E7%9B%B8%E4%BC%BC%E5%BA%A6/">句意相似度</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Pipeline/">Pipeline</a></span></div><div class="content">主要进行训练框架优化

端到端 ML 实施（训练、验证、预测、评估）
轻松适应您自己的数据集
促进其他基于 BERT 的模型（BERT、ALBERT、…）的快速实验
使用有限的计算资源进行快速训练（混合精度、梯度累积……）
多 GPU 执行
分类决策的阈值选择（不一定是 0.5）
冻结 BERT 层，只更新分类层权重或更新所有权重
种子设置，可复现结果

PipeLine导包12345678910111213import torchimport torch.nn as nnimport osimport copyimport torch.optim as optimimport randomimport numpy as npimport pandas as pdfrom torch.utils.data import DataLoader, Datasetfrom torch.cuda.amp import autocast, GradScalerfrom tqdm.auto import tqdmfrom transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmupfrom datasets import load_dataset, load_metric

Dataset123456789101112131415161718192021222324252627282930313233343536class CustomDataset(Dataset):    def __init__(self, data, maxlen, with_labels=True, bert_model=&#x27;albert-base-v2&#x27;):        self.data = data  # pandas dataframe        #Initialize the tokenizer        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)          self.maxlen = maxlen        self.with_labels = with_labels     def __len__(self):        return len(self.data)    def __getitem__(self, index):        #根据索引索取DataFrame中句子1余句子2        sent1 = str(self.data.loc[index, &#x27;sentence1&#x27;])        sent2 = str(self.data.loc[index, &#x27;sentence2&#x27;])        # 对句子对分词，得到input_ids、attention_mask和token_type_ids        encoded_pair = self.tokenizer(sent1, sent2,                                       padding=&#x27;max_length&#x27;,  # 填充到最大长度                                      truncation=True,  # 根据最大长度进行截断                                      max_length=self.maxlen,                                        return_tensors=&#x27;pt&#x27;)  # 返回torch.Tensor张量                token_ids = encoded_pair[&#x27;input_ids&#x27;].squeeze(0)  # tensor token ids        attn_masks = encoded_pair[&#x27;attention_mask&#x27;].squeeze(0)  # padded values对应为 &quot;0&quot; ，其他token为1        token_type_ids = encoded_pair[&#x27;token_type_ids&#x27;].squeeze(0)  #第一个句子的值为0，第二个句子的值为1 # 只有一句全为0        if self.with_labels:  # True if the dataset has labels            label = self.data.loc[index, &#x27;label&#x27;]            return token_ids, attn_masks, token_type_ids, label          else:            return token_ids, attn_masks, token_type_ids

建议，进行测试
12sample = next(iter(DataLoader(tr_dataset, batch_size=2)))sample

12tr_model = SentencePairClassifier(freeze_bert=True)tr_model(sample[0], sample[1], sample[2])

就是方便最后的维度转换，squeeze、flatten、view；甚至可以用reshape方法
模型定义12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class SentencePairClassifier(nn.Module):    def __init__(self, bert_model=&quot;albert-base-v2&quot;, freeze_bert=False):        super(SentencePairClassifier, self).__init__()        #  初始化预训练模型Bert xxx        self.bert_layer = AutoModel.from_pretrained(bert_model)        #  encoder 隐藏层大小        if bert_model == &quot;albert-base-v2&quot;:  # 12M 参数            hidden_size = 768        elif bert_model == &quot;albert-large-v2&quot;:  # 18M 参数            hidden_size = 1024        elif bert_model == &quot;albert-xlarge-v2&quot;:  # 60M 参数            hidden_size = 2048        elif bert_model == &quot;albert-xxlarge-v2&quot;:  # 235M 参数            hidden_size = 4096        elif bert_model == &quot;bert-base-uncased&quot;: # 110M 参数            hidden_size = 768        elif bert_model == &quot;roberta-base&quot;: #             hidden_size = 768        # 固定Bert层 更新分类输出层        if freeze_bert:            for p in self.bert_layer.parameters():                p.requires_grad = False                        self.dropout = nn.Dropout(p=0.1)        # 分类输出        self.cls_layer = nn.Linear(hidden_size, 1)    @autocast()  # 混合精度训练    def forward(self, input_ids, attn_masks, token_type_ids):        &#x27;&#x27;&#x27;        Inputs:            -input_ids : Tensor  containing token ids            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2        &#x27;&#x27;&#x27;        # 输入给Bert，获取上下文表示        # cont_reps, pooler_output = self.bert_layer(input_ids, attn_masks, token_type_ids)        outputs = self.bert_layer(input_ids, attn_masks, token_type_ids)        # last_hidden_state,pooler_output,all_hidden_states 12层        # 将last layer hidden-state of the [CLS] 输入到 classifier layer        # - last_hidden_state 的向量平均        # - 取all_hidden_states最后四层，然后做平均 weighted 平均        # - last_hidden_state+lstm        # 获取输出        logits = self.cls_layer(self.dropout(outputs[&#x27;pooler_output&#x27;]))        return logits

固定随机种子12345678910def set_seed(seed):    &quot;&quot;&quot; 固定随机种子，保证结果复现    &quot;&quot;&quot;    torch.manual_seed(seed)    torch.cuda.manual_seed_all(seed)    torch.backends.cudnn.deterministic = True    torch.backends.cudnn.benchmark = False    np.random.seed(seed)    random.seed(seed)    os.environ[&#x27;PYTHONHASHSEED&#x27;] = str(seed)

训练和评估12!mkdir models 	#可以在之前补充绝对路径!mkdir results



123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596def train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):    best_loss = np.Inf    best_ep = 1    nb_iterations = len(train_loader)    print_every = nb_iterations // 5  # 打印频率    iters = []    train_losses = []    val_losses = []    scaler = GradScaler()    for ep in range(epochs):        net.train()        running_loss = 0.0        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(train_loader)):            # 转为cuda张量            seq, attn_masks, token_type_ids, labels = \                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)                # 混合精度加速训练            with autocast():                # Obtaining the logits from the model                logits = net(seq, attn_masks, token_type_ids)                # Computing loss                loss = criterion(logits.squeeze(-1), labels.float())                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged            # Backpropagating the gradients            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.            scaler.scale(loss).backward()            if (it + 1) % iters_to_accumulate == 0:                # Optimization step                # scaler.step() first unscales the gradients of the optimizer&#x27;s assigned params.                # If these gradients do not contain infs or NaNs, opti.step() is then called,                # otherwise, opti.step() is skipped.                scaler.step(opti)                # Updates the scale for next iteration.                scaler.update()                # 根据迭代次数调整学习率。                lr_scheduler.step()                # 梯度清零                opti.zero_grad()            running_loss += loss.item()            if (it + 1) % print_every == 0:  # Print training loss information                print()                print(f&quot;Iteration &#123;it+1&#125;/&#123;nb_iterations&#125; of epoch &#123;ep+1&#125; complete. \                Loss : &#123;running_loss / print_every&#125; &quot;)                running_loss = 0.0        val_loss = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss        print()        print(f&quot;Epoch &#123;ep+1&#125; complete! Validation Loss : &#123;val_loss&#125;&quot;)        if val_loss &lt; best_loss:            print(&quot;Best validation loss improved from &#123;&#125; to &#123;&#125;&quot;.format(best_loss, val_loss))            print()            net_copy = copy.deepcopy(net)  # # 保存最优模型            best_loss = val_loss            best_ep = ep + 1    # 保存模型    path_to_model=f&#x27;models/&#123;bert_model&#125;_lr_&#123;lr&#125;_val_loss_&#123;round(best_loss, 5)&#125;_ep_&#123;best_ep&#125;.pt&#x27;    torch.save(net_copy.state_dict(), path_to_model)    print(&quot;The model has been saved in &#123;&#125;&quot;.format(path_to_model))    del loss    torch.cuda.empty_cache() # 清空显存    def evaluate_loss(net, device, criterion, dataloader):    &quot;&quot;&quot;    评估输出    &quot;&quot;&quot;    net.eval()    mean_loss = 0    count = 0    with torch.no_grad():        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):            seq, attn_masks, token_type_ids, labels = \                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)            logits = net(seq, attn_masks, token_type_ids)            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()            count += 1    return mean_loss / count


注意autocast和累计梯度 这两种加速计算的方法

evaluate的时候要注意数据的维度，标签的类型


超参数 &amp; 开始训练1234567bert_model = &quot;albert-base-v2&quot;  # &#x27;albert-base-v2&#x27;, &#x27;albert-large-v2&#x27;freeze_bert = False  # 是否冻结Bertmaxlen = 128  # 最大长度bs = 16  # batch sizeiters_to_accumulate = 2  # 梯度累加lr = 2e-5  # learning rateepochs = 2  # 训练轮数



123456789101112131415161718192021222324252627282930#  固定随机种子 便于复现set_seed(1) # 2022 # 创建训练集与验证集print(&quot;Reading training data...&quot;)train_set = CustomDataset(df_train, maxlen, bert_model)print(&quot;Reading validation data...&quot;)val_set = CustomDataset(df_val, maxlen, bert_model)# 常见训练集与验证集DataLoadertrain_loader = DataLoader(train_set, batch_size=bs, num_workers=0)val_loader = DataLoader(val_set, ba ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/02%20Bert%20Toxic%20%E8%AF%84%E8%AE%BA%20/" title="02 Bert Toxic 评论"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/22/Souryuu.Asuka.Langley.full.3259249.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="02 Bert Toxic 评论"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/02%20Bert%20Toxic%20%E8%AF%84%E8%AE%BA%20/" title="02 Bert Toxic 评论">02 Bert Toxic 评论</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:14.994Z" title="发表于 2022-11-21 10:16:14">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-21T08:21:20.965Z" title="更新于 2022-11-21 16:21:20">2022-11-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/">情感分析</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/%E5%8F%A5%E5%AD%90%E5%88%86%E7%B1%BB/">句子分类</a></span></div><div class="content">packagetqdm
1from tqdm.notebook import tqdm

Kfold 废了 没用的东西 nlp中还是去练prompt好了
kfold引用的是下标，所以在dataloader中加载时，将下标赋值给sampler进行采样
1234from sklearn.model_selection import KFoldk_folds = 5kfold = KFold(n_splits=k_folds, shuffle=True)



Datasetdataset的返回有大概两种

返回数据，可以直接处理的那种

返回路径，即列表是存储 指向数据的路径的字符串，

在dataloader( cutmix( dataset ) )进行二次处理，
dataloader( tokenizer( dataset ) ) 相同，&#x3D;&#x3D;大概吧，还没试过，tokenizer返回的是打包的元组&#x3D;&#x3D;  不行，换kfold了


与kfold 或者 特类notebook中的tqdm 使用要注意细节


Bert 模型选择
bert的选择很关键，注意要看到文档说明的返回数据的形状
损失函数的选择也很重要，BCE中要使用view( -1, num_class) 进行转换。

Pipeline导包123456789101112import reimport pandas as pdimport numpy as npfrom tqdm.auto import tqdmimport torchimport torch.nn as nnfrom torch.utils.data import DataLoader, Datasetfrom transformers import BertTokenizer, BertForSequenceClassificationfrom sklearn.utils import shuffle as resetfrom sklearn.metrics import f1_score, accuracy_score

预处理&#x3D;&#x3D;train、valid 划分&#x3D;&#x3D;12345678910111213141516171819202122232425262728293031def one_hot_key(file_path):    data_df = pd.read_csv(file_path, error_bad_lines=False,engine=&#x27;python&#x27;)    colunms_name = data_df.columns.to_list()    onehot_labels = train_df[colunms_name].values.tolist()    #onehot_labels = [data_df.iloc[i, -6:].to_list() for i in tqdm(range(len(data_df)))]    data_df[&#x27;label&#x27;] = onehot_labels    data_for_bert = data_df[[&#x27;comment_text&#x27;, &#x27;label&#x27;]]        return data_for_bert# 对数据集index打乱后进行 82分def train_valid_split(data_df, test_size, shuffle=True, random_state=None):    if shuffle:        data_df = reset(data_df, random_state=random_state)    train = data_df[int(len(data_df)*test_size):].reset_index(drop = True)    valid  = data_df[:int(len(data_df)*test_size)].reset_index(drop = True)    return train, validdef train_epoch(num, file_path, batch_num):    data_df = one_hot_key(file_path)    # 进行 fold次划分返回 input_ids, token_type, mask    for i in range(num):        train, valid = train_valid_split(data_df, test_size=(1/fold))        train_set = mydataset(train)        valid_set = mydataset(valid)                yield train_loader, valid_loader # 做yield一次一次返回

补充一个对含有字符串的处理
123456def df_to_content(file_path):     colunms_name = data_df.columns.to_list()    onehot_labels = list(data_df[colunms_name].applymap(str).values.tolist())    data_df[&#x27;content&#x27;] = onehot_labels    data_df[&#x27;content&#x27;] = data_df[&#x27;content&#x27;].apply(lambda x: &#x27; &#x27;.join(x))     return train_df



Dataset12345678910111213141516171819202122232425class mydataset(Dataset):    def __init__(self, data, with_label=True):        self.data = data        self.tokenizer = tokenizer        self.with_label = with_label            def __getitem__(self, idx):        self.feature = self.data.comment_text[idx]        self.label = self.data.label[idx]                inputs = tokenizer(self.feature, return_tensors=&quot;pt&quot;,                            padding=&#x27;max_length&#x27;, max_length=160, truncation=True)                input_ids= inputs.input_ids.squeeze(0)        token_type = inputs.token_type_ids.squeeze(0)        mask = inputs.attention_mask.squeeze(0)        label = torch.Tensor(self.label)                if self.with_label:            return input_ids, token_type, mask, label        else:            return input_ids, token_type, mask            def __len__(self):        return self.data.shape[0]

训练Config123456789101112131415device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)model = BertForSequenceClassification.from_pretrained(&quot;bert-base-uncased&quot;, num_labels=6) tokenizer = BertTokenizer.from_pretrained(&#x27;bert-base-uncased&#x27;)loss_func = nn.BCEWithLogitsLoss()optimizer = torch.optim.Adam(model.parameters(), lr=0.001)path = &#x27;/content/train.csv&#x27;epochs = 5batch_num = 64best_score = 0!mkdir model!nvidia-smi

Train1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162for train_set, valid_set in train_epoch(epochs, path, batch_num):        train_loader = DataLoader(train_set, batch_size=batch_num)    valid_loader = DataLoader(valid_set, batch_size=batch_num)    train_loss, valid_loss = [], []    # train    model.to(device)    model.train()    for batch in tqdm(train_loader):        input_ids, token_type, mask, label = batch        input_ids, token_type, mask, label = input_ids.to(device), token_type.to(device),         									 mask.to(device), label.to(device)                optimizer.zero_grad()                outputs = model(input_ids, token_type, mask)        logits = outputs[0]        loss = loss_func(logits.view(-1,6),label.view(-1,6))        train_loss.append(loss.item())                loss.backward()        optimizer.step()            train_ave_loss = ( sum(train_loss)/ len(train_loss))        # valid    model.eval()    logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]    for batch in tqdm(valid_loader):        input_ids, token_type, mask, label = tuple(t.to(device) for t in batch)                with torch.no_grad():            outputs = model(input_ids, token_type, mask)            b_logit_pred = outputs[0]            pred_label = torch.sigmoid(b_logit_pred)                        b_logit_pred = b_logit_pred.detach().cpu().numpy()            pred_label = pred_label.to(&#x27;cpu&#x27;).numpy()            label = label.to(&#x27;cpu&#x27;).numpy()            #tokenized_texts.append(b_input_ids) #这是啥            #logit_preds.append(b_logit_pred)            true_labels.append(label)            pred_labels.append(pred_label)                pred_labels = [item for sublist in pred_labels for item in sublist]    true_labels = [item for sublist in true_labels for item in sublist]    threshold = 0.50    pred_bools = [pl&gt;threshold for pl in pred_labels] #大于0.5的会被设置为True    true_bools = [tl==1 for tl in true_labels]    val_f1_accuracy = f1_score(true_bools,pred_bools,average=&#x27;micro&#x27;)*100    val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100    print(&#x27;F1 Validation Accuracy: &#x27;, val_f1_accuracy)    print(&#x27;Flat Validation Accuracy: &#x27;, val_flat_accuracy)            	global best_score             if best_score &lt; val_f1_accuracy + val_flat_accuracy:            best_score = val_f1_accuracy + val_flat_accuracy            torch.save(model.state_dict(), f&#x27;/model/Score:&#123;best_score&#125;.pth&#x27;)            #model.config.to_json_file()

不太明白为什么要阀值输出，做了以下优化
12345678910sample = np.random.random((3,4)).tolist()label = np.array([[1,1,0,0],[0,1,1,1],[0,0,0,1]]).tolist()df = pd.DataFrame(sample)result = []for i in range(df.shape[0]):    length = sum(label[i])    result.append(df.iloc[i,:].sort_values(ascending=False).index.to_list()[:length])result

12345678pred_df = pd.DataFrame(pred_labels.tolist())result = []for i in range(df.shape[0]):    length = sum(label[i])    result.append(pred_df[i,:].sort_values(ascending=False).index.to_list()[:length])# result即为结果

是因为预测的时候，没有标签数量啦，笨蛋
测试测试的时候就不能shuffle了
123456#preprocesing 之后直接丢给 fine_tune好的 bertmodel = BertForSequenceClassification.from_pretrained(&#x27;model_path.pth&#x27;).to(device)pred_label_ids = torch.argmax(outputs[0])name_class = tokenizer.convert_ids_to_tokens(pred_label_ids)

F1：阈值搜索123456789101112131415161718192021222324252627282930313233macro_thresholds = np.array(range(1,10))/10f1_results, flat_acc_results = [], []for th in macro_thresholds:    pred_bools = [pl&gt;th for pl in pred_labels]    test_f1_accuracy = f1_score(true_bools,pred_bools,average=&#x27;micro&#x27;)    test_flat_accuracy = accuracy_score(true_bools, pred_bools)    f1_results.append(test_f1_accuracy)    flat_acc_results.append(test_flat_accuracy)best_macro_th = macro_thresholds[np.argmax(f1_results)] #best macro threshold valuemicro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold valuesf1_results, flat_acc_results = [], []for th in micro_thresholds:    pred_bools = [pl&gt;th for pl in pred_labels]    test_f1_accuracy = f1_score(true_bools,pred_bools,average=&#x27;micro&#x27;)    test_flat_accuracy = accuracy_score(true_bools, pred_bools)    f1_results.append(test_f1_accuracy)    flat_acc_results.append(test_flat_accuracy)best_f1_idx = np.argmax(f1_results) #best threshold value# Printing and saving classification reportprint(&#x27;Best Threshold: &#x27;, micro_thresholds[best_f1_idx])print(&#x27;Test F1 Accuracy: &#x27;, f1_results[best_f1_idx])print(&#x27;Test Flat Accuracy: &#x27;, flat_acc_results[best_f1_idx], &#x27;\n&#x27;)best_pred_bools = [pl&gt;micro_thresholds[best_f1_idx] for pl in pred_labels]clf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)pickle.dump(clf_report_optimized, open(&#x27;classification_report_optimized.txt&#x27;,&#x27;wb&#x27;))print(clf_report_optimized)

</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/01%20%E5%8F%B6%E5%AD%90%E5%88%86%E7%B1%BBTricks%20/" title="01 叶子分类Tricks"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/22/Souryuu.Asuka.Langley.full.3259249.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="01 叶子分类Tricks"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/01%20%E5%8F%B6%E5%AD%90%E5%88%86%E7%B1%BBTricks%20/" title="01 叶子分类Tricks">01 叶子分类Tricks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:14.970Z" title="发表于 2022-11-21 10:16:14">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-21T08:21:16.191Z" title="更新于 2022-11-21 16:21:16">2022-11-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/CV/">CV</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%9B%BE%E7%89%87%E8%AF%86%E5%88%AB/">图片识别</a></span></div><div class="content">LibrarySklearn
预处理函数preprocessing

12345678910from sklearn import preprocessing# preprocessing有很多个子函数，比如正态化数据，做one-hot-key等sex = pd.Series([&quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;])encoder = preprocessing.LabelEncoder()       #获取一个LabelEncoder					#可用df[&#x27;label&#x27;].unique().to_list()获得标签类别model = encoder.fit([&quot;male&quot;, &quot;female&quot;])      #训练LabelEncoder, 把male编码为0，female编码为1sex = model.transform(sex)                   #使用训练好的LabelEncoder对原数据进行编码# 得到[1 0 0 1 1]

CutMix1234567891011121314151617181920212223242526from cutmix.cutmix import CutMixfrom cutmix.utils import CutMixCrossEntropyLosstrain_loss_function = CutMixCrossEntropyLoss(True)#其内部实现如下:	  # Compute the accuracy for current batch.      # acc = (logits.argmax(dim=-1) == labels).float().mean()      # Record the loss and accuracy    trainloader = torch.utils.data.DataLoader(                      CutMix(TrainValidData(train_val_path, img_path, transform = train_transform), 	                              num_class=176, beta=1.0, prob=0.5, num_mix=2),                       batch_size=128, sampler=train_subsampler, num_workers=0)#train_transform、train_subsampler变量如下:train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)train_transform = transforms.Compose([    # 随机裁剪图像，所得图像为原始面积的0.08到1之间，高宽比在3/4和4/3之间。    # 然后，缩放图像以创建224 x 224的新图像    transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3.0 / 4.0, 4.0 / 3.0)),    transforms.RandomHorizontalFlip(),    # 随机更改亮度，对比度和饱和度    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),    # 添加随机噪声    transforms.ToTensor(),    # 标准化图像的每个通道    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])



TrickLr_scheduler1234from torch.optim.lr_scheduler import CosineAnnealingLRscheduler = CosineAnnealingLR(optimizer,T_max=10)scheduler.step()



数据增强图片增强: 随机剪裁、翻转、对比度和颜色调整、随机噪声
1234567891011121314151617train_transform = transforms.Compose([    # 随机裁剪图像，所得图像为原始面积的0.08到1之间，高宽比在3/4和4/3之间。    # 然后，缩放图像以创建224 x 224的新图像    transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3.0 / 4.0, 4.0 / 3.0)),    transforms.RandomHorizontalFlip(),    # 随机更改亮度，对比度和饱和度    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),    # 添加随机噪声    transforms.ToTensor(),    # 标准化图像的每个通道    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])val_test_transform = transforms.Compose([    transforms.Resize(256),    # 从图像中心裁切224x224大小的图片    transforms.CenterCrop(224),    transforms.ToTensor(),    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])



Ensemble将数据通过多个不同的模型，以其最终在验证集上的正确率做权重分配，投票得出最终的submission
或者直接平均，要注意每个模型对数据的要求和敏感度。
K折交叉验证不光训练的时候K折验证，提交submission也要K折，以获得最平滑平均的正确率
示例:
123456789101112131415&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; from sklearn.model_selection import KFold&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])&gt;&gt;&gt; y = np.array([1, 2, 3, 4])&gt;&gt;&gt; kf = KFold(n_splits=2)&gt;&gt;&gt; kf.get_n_splits(X)2&gt;&gt;&gt; print(kf)KFold(n_splits=2, random_state=None, shuffle=False)&gt;&gt;&gt; for train_index, test_index in kf.split(X):...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)...     X_train, X_test = X[train_index], X[test_index]...     y_train, y_test = y[train_index], y[test_index]TRAIN: [2 3] TEST: [0 1]TRAIN: [0 1] TEST: [2 3]

kfold.split()将返回一个训练索引集合，一个验证索引集合
1234567from sklearn.model_selection import KFoldk_folds = 5kfold = KFold(n_splits=k_folds, shuffle=True)#trainin：for fold, (train_ids,valid_ids) in enumerate(kfold.split(train_val_dataset)):



Code Trick
固定随机种子seed

12345678910111213141516def seed_everything(seed):    random.seed(seed)    np.random.seed(seed)    torch.manual_seed(seed)    torch.cuda.manual_seed(seed)    torch.backends.cudnn.deterministic = True    torch.backends.cudnn.benchmark = True    # LHY版本myseed = 6666  # set a random seed for reproducibilitytorch.backends.cudnn.deterministic = Truetorch.backends.cudnn.benchmark = Falsenp.random.seed(myseed)      torch.manual_seed(myseed)if torch.cuda.is_available():    torch.cuda.manual_seed_all(myseed)


查看模型信息summary

12from torchinfo import summarysummary(model)


模型的参数冷冻

123456789101112131415# 是否要冻住模型的前面一些层def set_parameter_requires_grad(model, feature_extracting):    if feature_extracting:        model = model        for param in model.parameters():            param.requires_grad = False   		# 因为是全局变量，设置为false就会冻住# ResNeSt模型def resnest_model(num_classes, feature_extract = False):    model_ft = resnest50(pretrained=True)    set_parameter_requires_grad(model_ft, feature_extract)    num_ftrs = model_ft.fc.in_features    model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))    return model_ft



Summary查看博主的论文inference

EDA
Train trick

具体代码training epoch可以换成LHY的不进步多少个循环再停止
12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667print(&#x27;--------------------------------------&#x27;)#使用sklearn分割数据集 									#注意此处使用的特殊的数据集，kfold本质是对index处理for fold, (train_ids,valid_ids) in enumerate(kfold.split(train_val_dataset)):  print(f&#x27;FOLD &#123;fold&#125;&#x27;)  print(&#x27;--------------------------------------&#x27;)  #采样加入噪音  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)  valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)  #因为分割后返回的只是数据集的索引编号，所以需腰引入dataloader  trainloader = torch.utils.data.DataLoader(                      CutMix(TrainValidData(train_val_path, img_path, transform = train_transform), num_class=176, beta=1.0, prob=0.5, num_mix=2),                       batch_size=32, sampler=train_subsampler, num_workers=0)  validloader = torch.utils.data.DataLoader(                      TrainValidData(train_val_path, img_path, transform = val_test_transform),                      batch_size=32, sampler=valid_subsampler, num_workers=0)    #放到gpu  model = resnest_model(176)  model = model.to(device)  model.device = device    #优化器和优化方案  optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay= weight_decay)  scheduler = CosineAnnealingLR(optimizer,T_max=10)  #训练循环  for epoch in range(0,num_epochs):        model.train()    print(f&#x27;Starting epoch &#123;epoch+1&#125;&#x27;)    train_losses = []    train_accs = []    for batch in tqdm(trainloader):	  #GPU      imgs, labels = batch      imgs = imgs.to(device)      labels = labels.to(device)      logits = model(imgs)      loss = train_loss_function(logits,labels)      optimizer.zero_grad()      loss.backward()      optimizer.step()          # Compute the accuracy for current batch. 注意这里是每个batch的loss      # acc = (logits.argmax(dim=-1) == labels).float().mean()      # Record the loss and accuracy.              train_losses.append(loss.item())      # train_accs.append(acc)    print(&quot;第%d个epoch的学习率：%f&quot; % (epoch+1,optimizer.param_groups[0][&#x27;lr&#x27;]))        scheduler.step()	# 总loss / batch数    train_loss = np.sum(train_losses) / len(train_losses)    # train_acc = np.sum(train_accs) / len(train_accs)    print(f&quot;[ Train | &#123;epoch + 1:03d&#125;/&#123;num_epochs:03d&#125; ] loss = &#123;train_loss:.5f&#125;&quot;)  # Train process (all epochs) is complete  print(&#x27;Training process has finished. Saving trained model.&#x27;)  print(&#x27;Starting validation&#x27;)

validation123456789101112131415161718192021222324252627282930313233343536#这一段代码跟上面是连着的  # 按K折存储模型  print(&#x27;saving model with loss &#123;:.3f&#125;&#x27;.format(train_loss))  save_path = f&#x27;./model-fold-&#123;fold&#125;.pth&#x27;  torch.save(model.state_dict(),save_path)  #开始验证  model.eval()  valid_losses = []  valid_accs = []  with torch.no_grad():    for batch in tqdm(validloader):      imgs, labels = batch      logits = model(imgs.to(device))      #这里的loss-function用的是nn.CrossEntropyLoss()      loss = valid_loss_function(logits,labels.to(device))       acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()      valid_losses.append(loss.item())              valid_accs.append(acc)    valid_loss = np.sum(valid_losses)/len(valid_losses)    valid_acc = np.sum(valid_accs)/len(valid_accs)    print(f&quot;[ Valid | &#123;epoch + 1:03d&#125;/&#123;num_epochs:03d&#125; ] loss = &#123;valid_loss:.5f&#125;,           acc =&#123;valid_acc:.5f&#125;&quot;)    print(&#x27;Accuracy for fold %d: %d&#x27; % (fold, valid_acc))    print(&#x27;--------------------------------------&#x27;)    results[fold] = valid_acc          print(f&#x27;K-FOLD CROSS VALIDATION RESULTS FOR &#123;k_folds&#125; FOLDS&#x27;)print(&#x27;--------------------------------&#x27;)total_summation = 0.0for key, value in results.items():  print(f&#x27;Fold &#123;key&#125;: &#123;value&#125; &#x27;)  total_summation += valueprint(f&#x27;Average: &#123;total_summation/len(results.items())&#125; &#x27;)



test submission1234567891011121314151617181920212223242526272829303132333435363738394041424344#加入TTA数据增强包 不知道增强了什么import ttach as tta#载入测试数据集testloader = torch.utils.data.DataLoader(                      TestData(test_path, img_path, transform = val_test_transform),                      batch_size=32, num_workers=0)##模型预设model = resnest_model(176)model = model.to(device)#按K折载入模型for test_fold in range(k_folds):  model_path = f&#x27;./model-fold-&#123;test_fold&#125;.pth&#x27;  saveFileName = f&#x27;./submission-fold-&#123;test_fold&#125;.csv&#x27;  model.load_state_dict(torch.load(model_path))  # Some modules like Dropout o ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/20/375c6e3994a1f2472da5b34c26e48f18ab750e42.jpg942w_1332h_progressive.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Poy One</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/poyone"><i></i><span>🛴前往github...</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客</div></div><div class="sticky_layout"><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">11</div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">16.1k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-11-22T13:03:20.818Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Poy One</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script defer src="/js/light.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 380px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 320px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(https://s1.imagehub.cc/images/2022/11/21/Souryuu.Asuka.Langley.full.3306081.jpg);"> <a class="categoryBar-list-link" href="categories/NLP/">NLP</a><span class="categoryBar-list-count">7</span><span class="categoryBar-list-descr">自然语言处理</span></li><li class="categoryBar-list-item" style="background:url(https://s1.imagehub.cc/images/2022/11/21/Souryuu.Asuka.Langley.600.3414217.jpg);"> <a class="categoryBar-list-link" href="categories/CV/">CV</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">计算机视觉</span></li><li class="categoryBar-list-item" style="background:url(https://s1.imagehub.cc/images/2022/11/22/Souryuu.Asuka.Langley.full.3684208.jpg);"> <a class="categoryBar-list-link" href="categories/Trick/">Trick</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">小技巧</span></li><li class="categoryBar-list-item" style="background:url(https://s1.imagehub.cc/images/2022/11/21/Souryuu.Asuka.Langley.full.3198846.png);"> <a class="categoryBar-list-link" href="categories/HuggingFace/">HuggingFace</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">HuggingFace Summary</span></li></ul></div></div>';
      console.log('已挂载butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><!-- hexo injector body_end end --></body></html>