<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Attention Is A Talent</title><meta name="author" content="Poy One"><meta name="copyright" content="Poy One"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Attention Is A Talent">
<meta property="og:url" content="https://poyone.github.io/page/2/index.html">
<meta property="og:site_name" content="Attention Is A Talent">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://npm.elemecdn.com/poyone1222/eris/eris11.webp">
<meta property="article:author" content="Poy One">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://npm.elemecdn.com/poyone1222/eris/eris11.webp"><link rel="shortcut icon" href="https://npm.elemecdn.com/poyone1222/eris/eris11.webp"><link rel="canonical" href="https://poyone.github.io/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"ä½ å·²åˆ‡æ¢ä¸ºç¹ä½“","cht_to_chs":"ä½ å·²åˆ‡æ¢ä¸ºç®€ä½“","day_to_night":"ä½ å·²åˆ‡æ¢ä¸ºæ·±è‰²æ¨¡å¼","night_to_day":"ä½ å·²åˆ‡æ¢ä¸ºæµ…è‰²æ¨¡å¼","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Attention Is A Talent',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-12-11 00:26:56'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card@1.0.0/lib/categorybar.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/eris11.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> å…³äº</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Attention Is A Talent</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> å…³äº</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Attention Is A Talent</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/posts/4330.html" title="Transformer &amp; Self-Attention"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris33.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformer &amp; Self-Attention"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/4330.html" title="Transformer &amp; Self-Attention">Transformer &amp; Self-Attention</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-21T09:00:10.398Z" title="å‘è¡¨äº 2022-11-21 17:00:10">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-09T07:40:28.351Z" title="æ›´æ–°äº 2022-12-09 15:40:28">2022-12-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Dive-Into-Paper/">Dive Into Paper</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a></span></div><div class="content">å¾…å®Œæˆ
å¤±æ•ˆå›¾ç‰‡å¤„ç†

é˜¿ä¸‰åšå®¢åœ°å€

ææ²è€å¸ˆ 48åˆ†é’Ÿè®²è§£ encoder-decoderä¸­(KVâ€“Q)çš„è¿ç®—: 

KQç›¸ä¹˜å°±æ˜¯å•ä¸ªqå¯¹æ‰€æœ‰kçš„ç›¸ä¼¼åº¦ä½œä¸ºattention score(ç»™è¿™ä¸ªKå€¼å¤šå°‘æ³¨æ„åŠ›)ï¼Œä¸å•ä¸ªvåšåŠ æƒå’Œ(æƒå€¼æ¥è‡ªKQ)
å†é€šè¿‡æ³¨æ„åŠ›åˆ†æ•°ä¸Vå‘é‡ç›¸ä¹˜ï¼Œå¾—åˆ°æ¯ä¸ªVåº”è¯¥å¤šå¤§çš„ç¼©æ”¾ï¼Œ è¿›è¡Œç›¸åŠ åå°±å¾—åˆ°äº†æœ€ç»ˆVåº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­äº†




ææ²è€å¸ˆ 56åˆ† å¯¹multi-headè¾“å‡ºå’Œlinearå±‚ç›¸è¾ƒäºRNNçš„è®²è§£ï¼š

è¯å‘é‡ç»è¿‡Attentionå±‚æŠ“å–å…¨å±€ä¿¡æ¯ï¼Œæ±‡èšä¹‹åï¼Œåœ¨æ¯ä¸ªç‚¹ä¸Šéƒ½æœ‰äº†æ‰€éœ€è¦çš„ä¿¡æ¯
(æƒé‡ä¸åŒï¼Œæ¯ä¸ªè¾“å‡ºçš„å‘é‡çš„é‡ç‚¹åœ¨ä¸åŒçš„positionç¼–ç ä½ç½®ä¸Š)ï¼Œå› æ­¤åªéœ€è¦åšlinear transformationã€‚

bertä¸­transformerå‚æ•°è®¡ç®—:



embedding: vocab_size&#x3D;30522, max_position_embeddings&#x3D;512, token_type_embeddings&#x3D;2(å°±è¿›è¡Œä¸¤å¥åˆ†åˆ«æ ‡è®°ï¼Œå¤šäº†æˆªæ–­)
â€‹					ï¼ˆ30522+512+2ï¼‰*768 &#x3D; 23835648 (23M)
self-attention: 768&#x2F;12 &#x3D; 64 (å¤šå¤´æ¯å¤´åˆ†64ç»´åº¦çš„å‘é‡) ï¼Œ64*768(æ¯ä¸ª64æ˜ å°„å›768)ï¼ŒQKVä¸‰ä¸ªçŸ©é˜µ, 
â€‹						  æœ€åä¸€å±‚ 786(64 *12çš„æ‹¼æ¥)-&gt;768çš„çº¿æ€§å˜æ¢
â€‹						(768&#x2F;12 * 768 3 ) * 12 + (768768) &#x3D; 2359296
â€‹						ç»è¿‡12ä¸ªtransformer
â€‹						2359296*12 &#x3D; 28311552 (28M)
feedfoward: è‡ªæ³¨æ„åŠ›å±‚ä¹‹å åˆ†åˆ«åœ¨ encoder å’Œ decoder ä¸­æœ‰ä¸ªä¸€ä¸ªå…¨è¿æ¥å±‚
â€‹						ç»´åº¦ä» 768-&gt;4*768_768-&gt;768
â€‹						(768*4 * 768 )*2 &#x3D; 4718592
â€‹						(768*4 * 768 )*2  * 12 &#x3D; 56623104 (56M)
layernorm: æœ‰ä¼½é©¬å’Œè´å¡”ä¸¤ä¸ªå‚æ•°ï¼Œembeddingå±‚ï¼ˆ768 * 2ï¼‰ï¼Œ12å±‚çš„self-attentionï¼Œ
â€‹						768 * 2 + 768 * 2 * 2 * 12 &#x3D; 38400
æ€»è®¡: 23835648+28311552+56623104+38400 &#x3D; 108808704      				(108M)
æ¯ä¸€å±‚çš„å‚æ•°ä¸º:  å¤šå¤´æ³¨æ„åŠ›çš„å‚æ•° + æ‹¼æ¥çº¿æ€§å˜æ¢çš„å‚æ•° + feed-forwardçš„å‚æ•° + layer-normçš„å‚æ•°
768 * 768 &#x2F; 12 * 3 * 12 + 768 * 768 + 768 * 3072 * 2 + 768 * 2 * 2 &#x3D; 7080960  (7M)

Encoder ç¼–ç é˜¶æ®µMulti-head Attentionå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å°†ä¸€ä¸ªè¯å‘é‡ç•™è¿‡å…«ä¸ª self-attention å¤´ç”Ÿæˆå…«ä¸ªè¯å‘é‡ vectorï¼Œ
å°†å…«ä¸ªè¯å‘é‡æ‹¼æ¥ï¼Œé€šè¿‡ fc å±‚è¿›è¡Œ softmax è¾“å‡ºã€‚
ä¾‹å¦‚ï¼š
è¯å‘é‡ä¸º (1,4) â€“&gt; 
ç»è¿‡ QKV çŸ©é˜µ(ç³»æ•°) å¾—åˆ° (1,3) å…«ä¸ª (1,3)*8 â€“&gt;
å°†è¾“å‡ºæ‹¼æ¥æˆ (8,3) çŸ©é˜µä¸å…¨è¿æ¥å±‚çš„ç³»æ•°çŸ©é˜µè¿›è¡Œç›¸ä¹˜å† softmax ç¡®å®šæœ€åè¾“å‡ºçš„ è¯å‘é‡ â€“&gt; (1,4)
æ³¨æ„ QKVçŸ©é˜µæ€ä¹ˆæ¥çš„(attentionåˆ†æ•°)ï¼Œæœ€åä¸ºä»€ä¹ˆè¦æ‹¼æ¥ï¼Œä»¥åŠFCå±‚çš„ç³»æ•°
qkç›¸ä¹˜å¾—åˆ°ï¼Œè¯å‘é‡ä¸å…¶ä»–è¯çš„attentionåˆ†æ•°( q1*(k1,k2,k3) )

å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶è®©ä¸€ä»½è¯å‘é‡äº§ç”Ÿäº†å¤šä»½ç­”æ¡ˆï¼Œå°†æ¯ä¸€ä»½æ³¨æ„åŠ›æœºåˆ¶çš„äº§ç‰©æ‹¼æ¥ï¼Œ
è·å¾—äº†è¯å‘é‡åœ¨ä¸åŒæ³¨æ„åŠ›çŸ©é˜µè¿ç®—åçš„åˆ†æ•°ï¼Œè¿›è¡Œæ‹¼æ¥åï¼Œsoftmaxè¾“å‡ºæœ€æ³¨æ„çš„è¯ï¼Œå³æ˜¯æ³¨æ„åŠ›æœºåˆ¶ã€‚

å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†å‘é‡å¤åˆ¶nä»½(nä¸ºå¤šå¤´å¤´æ•°)ï¼ŒæŠ•å½±åˆ°å¦‚512&#x2F;8 &#x3D; 64çš„64ç»´çš„ä½ç»´ç©ºé—´ï¼Œæœ€åå°†æ¯ä¸€å±‚çš„è¾“å‡ºç»“æœ
æ­¤å¤„ä¸ºå…«å±‚ï¼Œ8*64&#x3D;512 æ‹¼å›512ç»´çš„è¾“å‡ºæ•°æ®
ç”±äºScale Dot Product åªæ˜¯åšä¹˜æ³•ç‚¹ç§¯(å‘é‡å˜æˆqvkä¹‹åçš„attentionè¿ç®—)ï¼Œæ²¡ä»€ä¹ˆå‚æ•°ï¼Œå› æ­¤é‡ç‚¹å­¦ä¹ çš„å‚æ•°åœ¨Multi-Headçš„çº¿æ€§å˜æ¢ä¸­ï¼Œ
å³å°† 64*8çš„å…«ä»½æ•°æ®çº¿æ€§å˜æ¢çš„ä¸‹æ–‡ä¸­çš„W0ï¼Œç»™æ¨¡å‹å…«æ¬¡æœºä¼šå¸Œæœ›èƒ½å¤Ÿå­¦åˆ°ä»€ä¹ˆï¼Œæœ€ååœ¨æ‹¼æ¥å›æ¥ã€‚&#x3D;&#x3D;



æ³¨æ„åŠ›æœºåˆ¶æµç¨‹ï¼š
q â€“&gt; æŸ¥è¯¢å‘é‡
set( kï¼Œv)    		k â€“&gt;å…³é”®å­— vâ€”-&gt; å€¼
å¦‚æœ qå¯¹kçš„ç›¸ä¼¼åº¦å¾ˆé«˜ï¼Œåˆ™è¾“å‡ºvçš„æ¦‚ç‡ä¹Ÿå˜é«˜


â€™å¤šå¤´â€™æ³¨æ„åŠ›æœºåˆ¶ 
è¯·æ³¨æ„å¹¶æ¨æ¼”å…¶è¯å‘é‡ç»´åº¦ä¸ç³»æ•°çŸ©é˜µå¸¦çš„è¡Œæ•°


Scale Dot Product
step1
QKåšç‚¹ç§¯ï¼Œåˆ™è¾“å‡ºæ¯ä¸€è¡Œï¼Œæ˜¯qä¸æ‰€æœ‰kçš„ç›¸ä¹˜ç›¸åŠ ç»“æœï¼Œ
Î±1 &#x3D; ï¼ˆq11k11+q12k21+q13k31 ,  q11k12+q12k22+q13k32 )
Î±2åŒç†ã€‚
step2
æ‰€ä»¥å¾—åˆ°äº†query1å¯¹æ‰€æœ‰keyçš„ç›¸ä¼¼åº¦ï¼Œæœ€åæ¯ä¸€è¡Œåšä¸ªsoftmaxè¿›è¡Œæ¦‚ç‡åˆ†å¸ƒã€‚
é™¤ä»¥æ ¹å·dkæ˜¯ä¸ºäº†å¹³æ»‘æ¢¯åº¦ï¼Œå…·ä½“æ¥è¯´ï¼šå½“æ¦‚ç‡è¶‹è¿‘äº1çš„æ—¶å€™softmaxå‡½æ•°çš„æ¢¯åº¦å¾ˆå°ï¼Œé™¤ä»¥dkè®©æ•°å€¼æ¥è¿‘å‡½æ•°ä¸­éƒ¨ï¼Œæ¢¯åº¦ä¼šæ¯”è¾ƒé™¡å³­
step3
å°†ç¬¬äºŒæ­¥çš„ç»“æœä¸Vç›¸ä¹˜å¾—åˆ°æœ€åçš„è¾“å‡º

Position Embeddingä½ç½®ç¼–ç æ˜¯ å°†embeddingå¥½çš„è¯å‘é‡åŠ ä¸Š position embedding vector å°†ä¿¡æ¯èåˆï¼Œåœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­è¿›è¡Œè®¡ç®—ã€‚
(åŸæ–‡æ˜¯ä½¿ç”¨sin coså°†è¯å‘é‡ä»½ä¸¤éƒ¨åˆ†è¿›è¡Œç¼–ç ï¼Œ æœ¬æ–‡ä¸­å°†äº¤æ›¿ä½¿ç”¨sin cosï¼Œå³å•æ•°sin åŒæ•°cos)
ä½ç½®åµŒå…¥ç¼–ç ï¼Œä¸»è¦æ˜¯ä¸ºäº†ç¼–è¾‘å®šä½è¯å‘é‡çš„ä½ç½®ä»¥åŠè¯å‘é‡é—´çš„ç›¸å¯¹è·ç¦»

posä¸º è¯çš„ç§ç±»æ•°ï¼Œä¸ºè¡Œæ ‡å·
i ä¸ºç‰¹å¾ç»´åº¦
len(pos) * len(i)  è¡¨ç¤ºä¸ºä¸€position embedding çŸ©é˜µï¼Œ æ¯ä¸€è¡Œä¸ºè¯çš„ä½ç½®ä¿¡æ¯ï¼Œæ¯ä¸€åˆ—è¡¨ç¤ºåœ¨ç‰¹å¾ä¸Šåç½®ï¼Œ
å°†ä½ç½®ä¿¡æ¯ èå…¥ è¯å‘é‡ä¿¡æ¯ ä½¿è¯è·å¾— æ—¶é—´ä¸Šçš„ç›¸å¯¹ä¿¡æ¯










Residual ç»†èŠ‚
Decoder è§£ç é˜¶æ®µMask Multi-headä¸encoderä¸åŒçš„æ˜¯ï¼Œè§£ç å™¨åœ¨å·¥ä½œæ—¶ä¼šå¼•å…¥ Mask Multi-head æœºåˆ¶ï¼Œå°†å³ä¾§çš„è¯ç›–ä½(è®¾ä¸ºè´Ÿæ— ç©·æˆ–è€…åˆ«çš„)ã€‚
å…·ä½“æ¥è¯´:

encoder å°†ç”Ÿæˆçš„Kå’ŒVçŸ©é˜µä¼ å…¥ decoder çš„ self-attention æ¨¡å—ä¸­ï¼Œè€Œ decoder å°† mask åçš„QçŸ©é˜µä¸å…¶åšattentionã€‚

maskåšçš„äº‹æƒ…




è§£ç è¿˜æ˜¯å¾—ä¸€ä¸ªä¸ªæ¥çš„
æ—¶é—´ç»´åº¦ 
åœ¨æ—¶é—´åºåˆ—çš„æƒ…å†µä¸‹ï¼Œè¯å‘é‡è¡¨ç¤ºä¸ºï¼Œt1æ—¶åˆ»çš„vectorï¼Œt2æ—¶åˆ»çš„vectorâ€¦.
maskåšçš„äº‹æƒ…å°±æ˜¯å°†åé¢(å³è¾¹)çš„ tnä¸ªæ—¶åˆ»éƒ½å±è”½æ‰ï¼Œ
è€ŒQmatrixçš„å½¢æˆ å°†vectorå«æœ‰äº†å…¶ä¹‹åè¯çš„ä¿¡æ¯(å…±äº«äº†ç³»æ•°çŸ©é˜µ)ï¼Œæ‰€ä»¥å°†å…¶å³è¾¹å±è”½ã€‚
åˆ™å‰”é™¤äº†åé¢è¯çš„ä¿¡æ¯ï¼Œä»è€Œä¸è¿›è¡Œè€ƒè™‘ã€‚
Mask ç»†èŠ‚maskå°±æ˜¯ä¸ºäº†é˜»æ­¢è¯çŸ¥é“åé¢çš„ä¿¡æ¯ï¼Œå…·ä½“æ¥è¯´å°±æ˜¯QKVçŸ©é˜µè¿˜ç›¸ä¹˜ï¼Œä½†æ˜¯å¼•å…¥-infæ¥é˜»æ­¢å³è¾¹(åé¢çš„ä¿¡æ¯æ±‡èš)

ç¬¬ä¸€æ¬¡ç‚¹ç§¯ï¼šå°†Qå’ŒKçŸ©é˜µç›¸ä¹˜å¾—åˆ°attentionåˆ†æ•°ï¼Œ
å°†å³ä¸Šè§’ç½®é›¶å°±ä¼šå¾—åˆ°åªå«æœ‰æœ¬èº«ä¿¡æ¯å’Œç›¸å¯¹ä½ç½®ä¹‹å‰(å·¦è¾¹)çš„ä¿¡æ¯ï¼Œ
ä¸”ç¬¬äºŒæ¬¡ç‚¹ç§¯: Mask(QK)ä¸Vç›¸ä¹˜ç”±ä¸‹ä¸‰è§’çŸ©é˜µçš„æ€§è´¨ï¼Œ



æ³¨: maskå»è´Ÿæ— ç©·æ˜¯å› ä¸º SoftMaxä¸­ eçš„æŒ‡æ•°å½¢å¼åªæœ‰åœ¨è´Ÿæ— ç©·æ‰ä¸ºé›¶ï¼Œ
è¿™æ ·ç›¸ä¹˜æ•°æ®ä¸ä¼šæœ‰ä¸€ç‚¹å½±å“ï¼Œå–å…¶ä»–å€¼ï¼Œéƒ½ä¼šå½±å“softmax



æ€»ç»“
ç‰¹åˆ«æ³¨æ„ç†è§£ attentionæœºåˆ¶å°†è¯å‘é‡ä¹‹é—´çš„è”ç³»ï¼Œ attentionåˆ†æ•°
embeddingæ–¹å¼ä¸º è¯å‘é‡+ä½ç½®ç¼–ç å‘é‡
å¼•å…¥äº† Residual
encoder-decoderå±‚çš„ä¼ å…¥ä¸ºKVçŸ©é˜µï¼Œdecoderç”ŸæˆQçŸ©é˜µ
Maskæ–¹å¼

</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/54367.html" title="Attentionæœºåˆ¶"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris33.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Attentionæœºåˆ¶"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/54367.html" title="Attentionæœºåˆ¶">Attentionæœºåˆ¶</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-21T09:00:10.386Z" title="å‘è¡¨äº 2022-11-21 17:00:10">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-09T07:40:19.051Z" title="æ›´æ–°äº 2022-12-09 15:40:19">2022-12-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Dive-Into-Paper/">Dive Into Paper</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Attention/">Attention</a></span></div><div class="content">å¾…å®Œæˆ
å¤±æ•ˆå›¾ç‰‡å¤„ç†

åšå®¢åœ°å€
ä¼ ç»ŸSeq2Seqâ€‹	
åŠ¨ç”»è¿æ¥
å·¦ä¾§ä¸º input å°†å¥å­ä¸€ä¸ªä¸€ä¸ªæŠ•å…¥åˆ° encoder ä¸­ï¼Œ
encoderæ•´ä¸ªå¤„ç†å…¶ç›¸å…³æ€§å¾—åˆ° contextï¼Œåç»™ decoderï¼Œ
decoder è¿›è¡Œä¸€ä¸ªä¸€ä¸ªè§£ç è¾“å‡ºï¼Œå¾—åˆ°æ•´ä¸ªç¿»è¯‘åçš„å¥å­ã€‚
AttentionAn attention model differs from a classic sequence-to-sequence model in two main ways:

First, the encoder passes a lot more data to the decoder. Instead of passing the last hidden state of the encoding stage, the encoder passes all the hidden states to the decoder:

â€‹		æ³¨æ„åŠ›æœºåˆ¶å°†äº§ç”Ÿçš„éšè—å±‚ä¿¡æ¯(æ—¶é—´æ­¥éª¤ä¿¡æ¯)ï¼Œå…¨éƒ¨ä¿ç•™ï¼Œä¸€æ¬¡æ€§ä¼ ç»™ Decoderã€‚



Second, an attention decoder does an extra step before producing its output. In order to focus on the parts of the input that are relevant to this decoding time step, the decoder does the following:

Look at the set of encoder hidden states it received â€“ each encoder hidden state is most associated with a certain word in the input sentence

Give each hidden state a score (letâ€™s ignore how the scoring is done for now)

Multiply each hidden state by its softmaxed score, thus amplifying hidden states with high scores, and drowning out hidden states with low scores




â€‹		decoder å°† encoder è¾“å…¥çš„éšè—å±‚çš„ vector è¿›è¡Œæ‰“åˆ†å¾—åˆ°ä¸€ä¸ªåˆ†æ•°vectorï¼Œ
â€‹		å°†åˆ†æ•° vector åš softmaxï¼Œå¾—åˆ°ä¸€ä¸ªæƒé‡ vectorï¼Œ
â€‹		å°†æƒé‡ vector ä¸éšè—å±‚ vector ç›¸ä¹˜å¾—åˆ° æ³¨æ„åŠ› vectorï¼Œ
â€‹		æœ€åæŠŠæ³¨æ„åŠ› vector è¿›è¡Œç›¸åŠ å°±å®Œæˆäº†ã€‚


æ³¨æ„: å°† encoder çš„éšè—å±‚ä¿¡æ¯ä¼ å…¥ decoderä¹‹åï¼Œdecoder æ¯ä¸€æ­¥éƒ½å°†ä½¿ç”¨å…¶ä¼ å…¥çš„éšè—å±‚ä¿¡æ¯åš attentionã€‚


â€‹			ç”±ä¸Šå›¾å¯ä»¥çœ‹åˆ°ï¼Œè¾“å‡ºæ—¶ Attention æœºåˆ¶å°±æ˜¯å°†æ³¨æ„åŠ›æ”¾åœ¨åˆ†æ•°æœ€é«˜çš„å‘é‡ä¸Šï¼Œæ‰€ä»¥ï¼Œç§°ä¹‹ä¸ºâ€™æ³¨æ„åŠ›æœºåˆ¶â€™
</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/18130.html" title="Huggingface Course 03 å¾®è°ƒèŒƒå¼"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris32.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Huggingface Course 03 å¾®è°ƒèŒƒå¼"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/18130.html" title="Huggingface Course 03 å¾®è°ƒèŒƒå¼">Huggingface Course 03 å¾®è°ƒèŒƒå¼</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-12-06T10:52:16.506Z" title="å‘è¡¨äº 2022-12-06 18:52:16">2022-12-06</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-06T11:09:23.577Z" title="æ›´æ–°äº 2022-12-06 19:09:23">2022-12-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Universe/">Universe</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Huggingface/">Huggingface</a></span></div><div class="content">dataIn this section we will use as an example the MRPC (Microsoft Research Paraphrase Corpus) dataset, introduced in a paper by William B. Dolan and Chris Brockett. The dataset consists of 5,801 pairs of sentences, with a label indicating if they are paraphrases or not (i.e., if both sentences mean the same thing). Weâ€™ve selected it for this chapter because itâ€™s a small dataset, so itâ€™s easy to experiment with training on it.
 letâ€™s focus on the MRPC dataset! This is one of the 10 datasets composing the GLUE benchmark

ä½¿ç”¨çš„æ˜¯MRPCï¼Œå¾ˆå°å¾ˆå¥½å®éªŒ

å®ƒå±äº GLUE


æ¥ä¸‹æ¥æŸ¥çœ‹ä¸‹æ•°æ®
12345678910111213141516171819from datasets import load_datasetraw_datasets = load_dataset(&quot;glue&quot;, &quot;mrpc&quot;)raw_datasets&#x27;&#x27;&#x27;DatasetDict(&#123;    train: Dataset(&#123;        features: [&#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;label&#x27;, &#x27;idx&#x27;],        num_rows: 3668    &#125;)    validation: Dataset(&#123;        features: [&#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;label&#x27;, &#x27;idx&#x27;],        num_rows: 408    &#125;)    test: Dataset(&#123;        features: [&#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;label&#x27;, &#x27;idx&#x27;],        num_rows: 1725    &#125;)&#125;)&#x27;&#x27;&#x27;



1234567raw_train_dataset = raw_datasets[&quot;train&quot;]raw_train_dataset[0]&#x27;&#x27;&#x27;&#123;&#x27;idx&#x27;: 0, &#x27;label&#x27;: 1, &#x27;sentence1&#x27;: &#x27;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .&#x27;, &#x27;sentence2&#x27;: &#x27;Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#x27;&#125;&#x27;&#x27;&#x27;



123456raw_train_dataset.features&#x27;&#x27;&#x27;&#123;&#x27;sentence1&#x27;: Value(dtype=&#x27;string&#x27;, id=None), &#x27;sentence2&#x27;: Value(dtype=&#x27;string&#x27;, id=None), &#x27;label&#x27;: ClassLabel(num_classes=2, names=[&#x27;not_equivalent&#x27;, &#x27;equivalent&#x27;], names_file=None, id=None), &#x27;idx&#x27;: Value(dtype=&#x27;int32&#x27;, id=None)&#125;&#x27;&#x27;&#x27;



é¢„å¤„ç†tokenizeræ–¹æ³•
123456tokenized_dataset = tokenizer(    raw_datasets[&quot;train&quot;][&quot;sentence1&quot;],    raw_datasets[&quot;train&quot;][&quot;sentence2&quot;],    padding=True,    truncation=True,)

This works well, but it has the disadvantage of returning a dictionary (with our keys, input_ids, attention_mask, and token_type_ids, and values that are lists of lists). It will also only work if you have enough RAM to store your whole dataset during the tokenization (whereas the datasets from the ğŸ¤— Datasets library are Apache Arrow files stored on the disk, so you only keep the samples you ask for loaded in memory).

å å†…å­˜

dataset.map æ–¹æ³•
1234567891011121314151617181920def tokenize_function(example):    return tokenizer(example[&quot;sentence1&quot;], example[&quot;sentence2&quot;], truncation=True)    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)tokenized_datasets&#x27;&#x27;&#x27;DatasetDict(&#123;    train: Dataset(&#123;        features: [&#x27;attention_mask&#x27;, &#x27;idx&#x27;, &#x27;input_ids&#x27;, &#x27;label&#x27;, &#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;token_type_ids&#x27;],        num_rows: 3668    &#125;)    validation: Dataset(&#123;        features: [&#x27;attention_mask&#x27;, &#x27;idx&#x27;, &#x27;input_ids&#x27;, &#x27;label&#x27;, &#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;token_type_ids&#x27;],        num_rows: 408    &#125;)    test: Dataset(&#123;        features: [&#x27;attention_mask&#x27;, &#x27;idx&#x27;, &#x27;input_ids&#x27;, &#x27;label&#x27;, &#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;token_type_ids&#x27;],        num_rows: 1725    &#125;)&#125;)&#x27;&#x27;&#x27;



since the tokenizer works on lists of pairs of sentences, as seen before. This will allow us to use the option batched=True in our call to map(), which will greatly speed up the tokenization. The tokenizer is backed by a tokenizer written in Rust from the ğŸ¤— Tokenizers library. This tokenizer can be very fast, but only if we give it lots of inputs at once.

batch

This is because padding all the samples to the maximum length is not efficient: itâ€™s better to pad the samples when weâ€™re building a batch, as then we only need to pad to the maximum length in that batch, and not the maximum length in the entire dataset. This can save a lot of time and processing power when the inputs have very variable lengths!

batchå†…æœ€é•¿paddingï¼Œå°†åœ¨ä¸‹ä¸€å°èŠ‚ä»‹ç»DataCollatorWithPadding

You can even use multiprocessing when applying your preprocessing function with map() by passing along a num_proc argument. We didnâ€™t do this here because the ğŸ¤— Tokenizers library already uses multiple threads to tokenize our samples faster, but if you are not using a fast tokenizer backed by this library, this could speed up your preprocessing.

å¤šçº¿ç¨‹


but note that if youâ€™re training on a TPU it can cause problems â€” TPUs prefer fixed shapes, even when that requires extra padding.

tpuæ›´å–œæ¬¢æ’å®šå½¢çŠ¶ï¼Œæ‰€ä»¥ä½ å¾ˆå°‘æ•°æ®with large pad ä¹Ÿæ²¡äº‹


Dynamic paddingThe function that is responsible for putting together samples inside a batch is called a collate function. Itâ€™s an argument you can pass when you build a DataLoader, the default being a function that will just convert your samples to PyTorch tensors and concatenate them (recursively if your elements are lists, tuples, or dictionaries). This wonâ€™t be possible in our case since the inputs we have wonâ€™t all be of the same size.

DataCollatorå¯ä»¥çœ‹æˆæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå¯ä»¥ä¼ å…¥pytorchçš„dataloaderçš„collate_fnå‚æ•°

123from transformers import DataCollatorWithPaddingdata_collator = DataCollatorWithPadding(tokenizer=tokenizer) # æœ‰modelå‚æ•°ï¼Œå¯ä»¥æŠŠmodelä¹Ÿè®©collatorçŸ¥é“



å†›ç«å±•ç¤º
12345678910111213samples = tokenized_datasets[&quot;train&quot;][:8]samples = &#123;k: v for k, v in samples.items() if k not in [&quot;idx&quot;, &quot;sentence1&quot;, &quot;sentence2&quot;]&#125;[len(x) for x in samples[&quot;input_ids&quot;]]&#x27;&#x27;&#x27;[50, 59, 47, 67, 59, 50, 62, 32]&#x27;&#x27;&#x27;batch = data_collator(samples)&#123;k: v.shape for k, v in batch.items()&#125;&#x27;&#x27;&#x27;&#123;&#x27;attention_mask&#x27;: torch.Size([8, 67]), &#x27;input_ids&#x27;: torch.Size([8, 67]), &#x27;token_type_ids&#x27;: torch.Size([8, 67]), &#x27;labels&#x27;: torch.Size([8])&#125;&#x27;&#x27;&#x27;



Fine-tuneTraineré¦–å…ˆæ˜¯TrainingArgumentsçš„å®šä¹‰
The first step before we can define our Trainer is to define a TrainingArguments class that will contain all the hyperparameters the Trainer will use for training and evaluation. The only argument you have to provide is a directory where the trained model will be saved, as well as the checkpoints along the way. For all the rest, you can leave the defaults, which should work pretty well for a basic fine-tuning.
123456from transformers import TrainingArgumentsfrom transformers import AutoModelForSequenceClassificationtraining_args = TrainingArguments(&quot;test-trainer&quot;)model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)



You will notice that unlike in Chapter 2, you get a warning after instantiating this pretrained model. This is because BERT has not been pretrained on classifying pairs of sentences, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead. The warnings indicate that some weights were not used (the ones corresponding to the dropped pretraining head) and that some others were randomly initialized (the ones for the new head). It concludes by encouraging you to train the model, which is exactly what we are going to do now.

ä½¿ç”¨ç»†åˆ†æ¨¡å‹ (automodeåå¸¦ä»»åŠ¡åç§°çš„)ä¸ä¼šå¾—åˆ°è­¦å‘Šï¼Œæ˜¯å› ä¸ºä»–ä¼šåŠ è½½ æœ€åé¢é‚£ä¸ªå¤šåˆ†ç±»çš„æƒé‡ç»™ä½ ï¼Œè¿™æ ·é¢„è®­ç»ƒå°±åˆå¿«äº†äº›ï¼Œä¸Šé¢å†™çš„head åº”è¯¥æ˜¯æŒ‡classifierçš„é‚£å‡ å±‚å§ã€‚

æ¥ä¸‹æ¥å¯ä»¥trainäº†
123456789101112from transformers import Trainertrainer = Trainer(    model,    training_args,    train_dataset=tokenized_datasets[&quot;train&quot;],    eval_dataset=tokenized_datasets[&quot;validation&quot;],    data_collator=data_collator,    tokenizer=tokenizer,)trainer.train() # è°ƒç”¨è®­ç»ƒ

Note that when you pass the tokenizer as we did here, the default data_collator used by the Trainer will be a DataCollatorWithPadding as defined previously, so you can skip the line data_collator=data_collator in this call.
This will start the fine-tuning (which should take a couple of minutes on a GPU) and report the training loss every 500 steps.

ä¸å†™collateçš„è¯é»˜è®¤å°±æ˜¯DataCollatorWithPaddingï¼Œä¸è¿‡å£°æ˜ä¸€ä¸‹ï¼Œæ¯”è¾ƒå¥½ï¼Œä¸ºäº†å¯è¯»æ€§
æ¯500æ­¥ç»™ä½ ä¸€ä¸ªlossè¿”å›ï¼Œçœ‹çœ‹need lossæœ‰å¤šå¤§

Evaluation1234predictions = trainer.predict(tokenized_datasets[&quot;validation&quot;])print(predictions.predictions.shape, predictions.label_ids.shape)# (408, 2) (408,)


predictçš„ç»“æœå°±æ˜¯äºŒåˆ†ç±»çš„logits æ¥ä¸‹æ¥åšä¸ªargmax å–ä½ç½®ä¿¡æ¯å³å¯

1234567891011import numpy as npimport evaluatepreds = np.argmax(predictions.predictions, axis=-1)metric = evaluate.load(&quot;glue&quot;, &quot;mrpc&quot;)metric.compute(predictions=preds, references=predictions.label_ids)&#x27;&#x27;&#x27;&#123;&#x27;accuracy&#x27;: 0.8578431372549019, &#x27;f1&#x27;: 0.8996539792387542&#125;&#x27;&#x27;&#x27;

The table in the BERT paper reported an F1 score of 88.9 for the base model. That was the uncased model while we are currently using the cased model, which explains the better result.

ä¸Šé¢è¯´ å¾®è°ƒçš„powerï¼

12345def compute_metrics(eval_preds):    metric = evaluate.load(&quot;glue&quot;, &quot;mrpc&quot;)    logits, labels = eval_preds    predictions = np.argmax(logits, axis=-1)    return metric.compute(predicti ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/64185.html" title="Huggingface Course 02 APIæ¦‚è¦"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris32.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Huggingface Course 02 APIæ¦‚è¦"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/64185.html" title="Huggingface Course 02 APIæ¦‚è¦">Huggingface Course 02 APIæ¦‚è¦</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-12-06T10:52:16.501Z" title="å‘è¡¨äº 2022-12-06 18:52:16">2022-12-06</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-06T11:09:18.692Z" title="æ›´æ–°äº 2022-12-06 19:09:18">2022-12-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Universe/">Universe</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Huggingface/">Huggingface</a></span></div><div class="content">outputsNote that the outputs of ğŸ¤— Transformers models behave like namedtuples or dictionaries. You can access the elements by attributes (like we did) or by key (outputs[&quot;last_hidden_state&quot;]), or even by index if you know exactly where the thing you are looking for is (outputs[0]).

HFçš„è¾“å…¥è¿”å› å¤§å¤šä»¥æ˜¯å…ƒç»„æˆ–å­—å…¸å½¢å¼å‡ºï¼Œå¤„ç†çš„æ—¶å€™è¦æ³¨æ„ã€‚

ä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»ï¼Œå¤šåˆ†ç±»ä¸­æ¯ä¸ªç±»åˆ«åˆ†åˆ«ä½œäºŒåˆ†ç±»ï¼Œæ˜¯å¦å±äºè¿™ä¸ªç±»åˆ«è¿›è¡Œè¾“å‡º
[[0.2,0.8]ã€[0.4,0.6]ã€[0.7,0.3]]  &#x3D; [[1]ã€[1]ã€[0]]
Config12345678910111213141516171819from transformers import BertConfig, BertModel# Building the configconfig = BertConfig()# Building the model from the configmodel = BertModel(config)config&#x27;&#x27;&#x27;BertConfig &#123;  [...]  &quot;hidden_size&quot;: 768,  &quot;intermediate_size&quot;: 3072,  &quot;max_position_embeddings&quot;: 512,  &quot;num_attention_heads&quot;: 12,  &quot;num_hidden_layers&quot;: 12,  [...]&#125;&#x27;&#x27;&#x27;



ç¯å¢ƒå˜é‡The weights have been downloaded and cached (so future calls to the from_pretrained() method wonâ€™t re-download them) in the cache folder, which defaults to ~&#x2F;.cache&#x2F;huggingface&#x2F;transformers. You can customize your cache folder by setting the HF_HOME environment variable.

é…ç½®ä½ å½“å‰çš„ç¯å¢ƒå˜é‡ os.environ[&#39;HF_HOME&#39;]= &#39;~/.cache/huggingface/transformers&#39; 

Saving12345678model.save_pretrained(&quot;directory_on_my_computer&quot;)&#x27;&#x27;&#x27;This saves two files to your disk:ls directory_on_my_computerconfig.json pytorch_model.bin&#x27;&#x27;&#x27;


If you take a look at the config.json file, youâ€™ll recognize the attributes necessary to build the model architecture. This file also contains some metadata, such as where the checkpoint originated and what ğŸ¤— Transformers version you were using when you last saved the checkpoint

The pytorch_model.bin file is known as the state dictionary; it contains all your modelâ€™s weights. The two files go hand in hand; the configuration is necessary to know your modelâ€™s architecture, while the model weights are your modelâ€™s parameters.


Tokenizerencodeé€šè¿‡tokenizer.tokenize(sequence)æŸ¥çœ‹åˆ†è¯åçš„ç»“æœ
12345678910from transformers import AutoTokenizertokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-cased&quot;)sequence = &quot;Using a Transformer network is simple&quot;tokens = tokenizer.tokenize(sequence)print(tokens)&#x27;&#x27;&#x27;[&#x27;Using&#x27;, &#x27;a&#x27;, &#x27;transform&#x27;, &#x27;##er&#x27;, &#x27;network&#x27;, &#x27;is&#x27;, &#x27;simple&#x27;]&#x27;&#x27;&#x27;



ids = tokenizer.convert_tokens_to_ids(tokens)
è¿˜å¯ä»¥åè¿‡æ¥å¾—åˆ°tokenï¼Œä¹Ÿå°±æ˜¯è·Ÿä¸Šé¢çš„ tokenize(seq) ä¸€æ ·çš„æ•ˆæœ
123ids = tokenizer.convert_tokens_to_ids(tokens)print(ids)



decode12345decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])print(decoded_string)&#x27;&#x27;&#x27;&#x27;Using a Transformer network is simple&#x27;&#x27;&#x27;&#x27;



paddingæŸ¥çœ‹tokenizer.pad_token_id padçš„id
123456789# Will pad the sequences up to the maximum sequence lengthmodel_inputs = tokenizer(sequences, padding=&quot;longest&quot;)# Will pad the sequences up to the model max length# (512 for BERT or DistilBERT)model_inputs = tokenizer(sequences, padding=&quot;max_length&quot;)# Will pad the sequences up to the specified max lengthmodel_inputs = tokenizer(sequences, padding=&quot;max_length&quot;, max_length=8)


ç›´æ¥max_lengthæ˜¯åˆ°æ¨¡å‹çš„æœ€å¤§é•¿åº¦ï¼Œlongestæ˜¯åˆ°æ‰¹æ¬¡é‡Œå¥å­çš„æœ€å¤§é•¿åº¦

1234567891011sequence1_ids = [[200, 200, 200]]sequence2_ids = [[200, 200]]batched_ids = [    [200, 200, 200],    [200, 200, tokenizer.pad_token_id],]&#x27;&#x27;&#x27;tensor([[ 1.5694, -1.3895]], grad_fn=&lt;AddmmBackward&gt;)tensor([[ 0.5803, -0.4125]], grad_fn=&lt;AddmmBackward&gt;)tensor([[ 1.5694, -1.3895],        [ 1.3373, -1.2163]], grad_fn=&lt;AddmmBackward&gt;)&#x27;&#x27;&#x27;



This is because the key feature of Transformer models is attention layers that contextualize each token. These will take into account the padding tokens since they attend to all of the tokens of a sequence. To get the same result when passing individual sentences of different lengths through the model or when passing a batch with the same sentences and padding applied, we need to tell those attention layers to ignore the padding tokens. This is done by using an attention mask.

è¿™é‡Œä¸¤æ¡å•ç‹¬çš„æ•°æ®çš„ç»“æœè·Ÿç»„åˆèµ·æ¥çš„æ˜¯ä¸åŒçš„ï¼Œæ˜¯å› ä¸ºpadçš„ä½ç½®ä¹Ÿåˆ†æ•£äº†æ¨¡å‹çš„æ³¨æ„åŠ›ï¼Œè¿™ä¸æ˜¯æˆ‘ä»¬å¸Œæœ›æ¨¡å‹å­¦ä¹ çš„åœ°æ–¹

ATTENTION MASK123456789101112131415batched_ids = [    [200, 200, 200],    [200, 200, tokenizer.pad_token_id],]attention_mask = [    [1, 1, 1],    [1, 1, 0],]outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))print(outputs.logits)&#x27;&#x27;&#x27;tensor([[ 1.5694, -1.3895],        [ 0.5803, -0.4125]], grad_fn=&lt;AddmmBackward&gt;)&#x27;&#x27;&#x27;



é•¿å¥å­å¤„ç†Models have different supported sequence lengths, and some specialize in handling very long sequences. Longformer is one example, and another is LED. If youâ€™re working on a task that requires very long sequences, we recommend you take a look at those models.
ä¸€èˆ¬æ˜¯åœ¨tokenizeré‡Œè®¾ç½®truncation max_lenï¼Œè¿™é‡Œæ²¡è®²ï¼Œå¯ä»¥å»çœ‹çœ‹æ¨¡å‹ã€‚
</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/16149.html" title="Huggingface Course 01 åŸºç¡€æ¦‚å¿µ"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris32.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Huggingface Course 01 åŸºç¡€æ¦‚å¿µ"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/16149.html" title="Huggingface Course 01 åŸºç¡€æ¦‚å¿µ">Huggingface Course 01 åŸºç¡€æ¦‚å¿µ</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-12-06T10:52:16.495Z" title="å‘è¡¨äº 2022-12-06 18:52:16">2022-12-06</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-06T11:12:26.942Z" title="æ›´æ–°äº 2022-12-06 19:12:26">2022-12-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Universe/">Universe</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Huggingface/">Huggingface</a></span></div><div class="content">Some of the currently available pipelines are:

feature-extraction (get the vector representation of a text)
fill-mask
ner (named entity recognition)
question-answering
sentiment-analysis
summarization
text-generation
translation
zero-shot-classification

pipeline12345678from transformers import pipelinegenerator = pipeline(&quot;text-generation&quot;, model=&quot;distilgpt2&quot;)generator(    &quot;In this course, we will teach you how to&quot;,    max_length=30,    num_return_sequences=2,)





modelæ¨¡å‹å‘å±•æ—¶é—´å²

June 2018: GPT, the first pretrained Transformer model, used for fine-tuning on various NLP tasks and obtained state-of-the-art results

October 2018: BERT, another large pretrained model, this one designed to produce better summaries of sentences (more on this in the next chapter!)

February 2019: GPT-2, an improved (and bigger) version of GPT that was not immediately publicly released due to ethical concerns

October 2019: DistilBERT, a distilled version of BERT that is 60% faster, 40% lighter in memory, and still retains 97% of BERTâ€™s performance

October 2019: BART and T5, two large pretrained models using the same architecture as the original Transformer model (the first to do so)

May 2020, GPT-3, an even bigger version of GPT-2 that is able to perform well on a variety of tasks without the need for fine-tuning (called zero-shot learning)

GPT-like (also called auto-regressive Transformer models)

BERT-like (also called auto-encoding Transformer models)

BART&#x2F;T5-like (also called sequence-to-sequence Transformer models)


encoder-decoderç‰¹æ”»ç±»ç¼–ç å™¨çš„ä¸»è¦ç”¨å¤„

Encoder-only models: Good for tasks that require understanding of the input, such as sentence classification and named entity recognition.
ALBERT
BERT
DistilBERT
ELECTRA
RoBERTa


Decoder-only models: Good for generative tasks such as text generation
CTRL
GPT
GPT-2
Transformer XL.


Encoder-decoder models or sequence-to-sequence models: Good for generative tasks that require an input, such as translation or summarization.
BART
mBART
Marian
T5



cross-attentionå±‚ä½¿å¾—decoderèƒ½æŸ¥çœ‹æ•´ä¸ªå¥æ„ï¼Œä»¥è°ƒæ•´é¡ºåºç¿»è¯‘è¾“å‡º
Note that the first attention layer in a decoder block pays attention to all (past) inputs to the decoder, but the second attention layer uses the output of the encoder. It can thus access the whole input sentence to best predict the current word. This is very useful as different languages can have grammatical rules that put the words in different orders, or some context provided later in the sentence may be helpful to determine the best translation of a given word.
æ¶æ„å’Œæ£€æŸ¥ç‚¹

Architecture: This is the skeleton of the model â€” the definition of each layer and each operation that happens within the model.
Checkpoints: These are the weights that will be loaded in a given architecture.
Model: This is an umbrella term that isnâ€™t as precise as â€œarchitectureâ€ or â€œcheckpointâ€: it can mean both. This course will specify architecture or checkpoint when it matters to reduce ambiguity.

For example, BERT is an architecture while bert-base-cased, a set of weights trained by the Google team for the first release of BERT, is a checkpoint. However, one can say â€œthe BERT modelâ€ and â€œthe bert-base-cased model.â€
å³ä½¿ä½¿ç”¨å¹²å‡€çš„è¯åº“ï¼Œä¹Ÿå¯èƒ½äº§ç”Ÿæ€§åˆ«æ­§è§†ï¼Œç§æ—æ­§è§†
When asked to fill in the missing word in these two sentences, the model gives only one gender-free answer (waiter&#x2F;waitress). The others are work occupations usually associated with one specific gender â€” and yes, prostitute ended up in the top 5 possibilities the model associates with â€œwomanâ€ and â€œwork.â€ This happens even though BERT is one of the rare Transformer models not built by scraping data from all over the internet, but rather using apparently neutral data (itâ€™s trained on the English Wikipedia and BookCorpus datasets).
When you use these tools, you therefore need to keep in the back of your mind that the original model you are using could very easily generate sexist, racist, or homophobic content. Fine-tuning the model on your data wonâ€™t make this intrinsic bias disappear.
</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/2534.html" title="22-12-3 e.g etc. è¯¦è§£"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/made in Abyss/nanachi02.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="22-12-3 e.g etc. è¯¦è§£"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/2534.html" title="22-12-3 e.g etc. è¯¦è§£">22-12-3 e.g etc. è¯¦è§£</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-12-04T16:08:37.456Z" title="å‘è¡¨äº 2022-12-05 00:08:37">2022-12-05</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-12-04T16:38:46.207Z" title="æ›´æ–°äº 2022-12-05 00:38:46">2022-12-05</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Universe/">Universe</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%8B%B1%E8%AF%AD/">è‹±è¯­</a></span></div><div class="content">
â€œe.g.â€æ˜¯æ‹‰ä¸æ–‡â€œexempli gratiaâ€çš„ç¸®å¯«ï¼Œæ„æ€æ˜¯ã€Œä¾‹å¦‚ã€èˆ‰ä¾‹ä¾†èªªã€ï¼Œå°±æ˜¯è‹±æ–‡çš„for exampleæˆ–for instanceã€‚

ex.çš„æ„æ€æ˜¯ã€Œç¯„ä¾‹æˆ–ç·´ç¿’ã€ï¼Œä¹Ÿå°±æ˜¯è‹±æ–‡çš„exampleæˆ–exerciseã€‚æ‰€ä»¥åˆ¥å†æŠŠex.æ”¾åˆ°å¥å­è£¡ç•¶ã€Œä¾‹å¦‚ã€ç”¨äº†å–”ã€‚

é‚„æœ‰â€œi.e.â€ä¹Ÿæ˜¯éå¸¸è®“äººå›°æƒ‘çš„ç¸®å¯«ï¼Œâ€œi.e.â€å…¶å¯¦æ˜¯æ‹‰ä¸æ–‡â€œid estâ€çš„ç¸®å¯«ï¼Œæ„æŒ‡ã€Œæ›å¥è©±èªªã€ã€‚è‹±æ–‡å°±æ˜¯that is &#x2F; in other wordsï¼Œç›®çš„æ˜¯çµ¦äºˆæ›´å¤šè³‡è¨Šä¾†é—¡è¿°å‰é¢æ‰€èªªçš„è©±ã€‚

é™¤æ­¤ä¹‹å¤–ï¼Œåœ¨èˆ‰ä¾‹çš„æ™‚å€™é‚„è¦ç‰¹åˆ¥æ³¨æ„etc.çš„æ­£ç¢ºç”¨æ³•ï¼Œetc.æ˜¯â€œet ceteraâ€çš„ç¸®å¯«ï¼Œæ„æ€æ˜¯ã€Œç­‰ç­‰ã€ï¼Œç›¸ç•¶æ–¼â€œâ€¦and so on.â€ã€‚
æé†’å¤§å®¶ï¼Œâ€œe.g.â€å’Œâ€œetc.â€ä¸èƒ½å‡ºç¾åœ¨åŒä¸€å€‹å¥å­ä¸­å–”ã€‚å› ç‚ºe.g.æ˜¯èˆ‰ä¾‹ä¾†èªªï¼Œæ„æ—¨èˆ‰å¹¾å€‹ä¾‹å­ï¼Œæ‰€ä»¥å…¶ä¸­å°±å·²ç¶“æœ‰ã€Œç­‰ç­‰ã€çš„å«æ„ï¼Œå› æ­¤è‹¥å†åŠ ä¸Šetc.å°±æ˜¯ç•«è›‡æ·»è¶³äº†ã€‚


</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><a class="page-number" href="/page/4/#content-inner">4</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/eris11.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Poy One</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/poyone"><i></i><span>ğŸ›´å‰å¾€github...</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">æ¬¢è¿æ¥åˆ°æˆ‘çš„åšå®¢ <br> QQ 914987163</div></div><div class="sticky_layout"><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>ç½‘ç«™èµ„è®¯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">æ–‡ç« æ•°ç›® :</div><div class="item-count">20</div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™æ€»å­—æ•° :</div><div class="item-count">33.1k</div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™è®¿å®¢æ•° :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™æ€»è®¿é—®é‡ :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">æœ€åæ›´æ–°æ—¶é—´ :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-12-10T16:26:55.466Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Poy One</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script defer src="/js/light.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#web_bg",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 380px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 320px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka15.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/CV/&quot;);" href="javascript:void(0);">CV</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">è®¡ç®—æœºè§†è§‰</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka22.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/NLP/&quot;);" href="javascript:void(0);">NLP</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">è‡ªç„¶è¯­è¨€å¤„ç†</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka10.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Trick/&quot;);" href="javascript:void(0);">Trick</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">import torch as tf</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka29.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Dive-Into-Paper/&quot;);" href="javascript:void(0);">Dive Into Paper</a><span class="categoryBar-list-count">3</span><span class="categoryBar-list-descr">è®ºæ–‡ç²¾è¯»</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka16.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Python/&quot;);" href="javascript:void(0);">Python</a><span class="categoryBar-list-count">3</span><span class="categoryBar-list-descr">æµç•…çš„Python</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka32.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Universe/&quot;);" href="javascript:void(0);">Universe</a><span class="categoryBar-list-count">8</span><span class="categoryBar-list-descr">æ‹¥æœ‰ä¸€åˆ‡ å´å˜æˆå¤ªç©º</span></li></ul></div></div>';
      console.log('å·²æŒ‚è½½butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><!-- hexo injector body_end end --></body></html>