<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Attention Is A Talent</title><meta name="author" content="Poy One"><meta name="copyright" content="Poy One"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Attention Is A Talent">
<meta property="og:url" content="https://poyone.github.io/page/2/index.html">
<meta property="og:site_name" content="Attention Is A Talent">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://npm.elemecdn.com/poyone1222/eris/eris11.webp">
<meta property="article:author" content="Poy One">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://npm.elemecdn.com/poyone1222/eris/eris11.webp"><link rel="shortcut icon" href="https://npm.elemecdn.com/poyone1222/eris/eris11.webp"><link rel="canonical" href="https://poyone.github.io/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Attention Is A Talent',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-11-26 00:21:48'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card@1.0.0/lib/categorybar.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/eris11.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://npm.elemecdn.com/poyone1222/zelda/Zelda3.webp')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Attention Is A Talent</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Attention Is A Talent</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/posts/45347.html" title="02 HuggingFace基础"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris21.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="02 HuggingFace基础"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/45347.html" title="02 HuggingFace基础">02 HuggingFace基础</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T08:59:54.804Z" title="发表于 2022-11-21 16:59:54">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-24T05:08:15.464Z" title="更新于 2022-11-24 13:08:15">2022-11-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Package/">Package</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/HuggingFace/">HuggingFace</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Bert/">Bert</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Preprocessing/">Preprocessing</a></span></div><div class="content">Attention 原文
Why
全面拥抱Transformer：NLP三大特征抽取器(CNN&#x2F;RNN&#x2F;TF)中，近两年新欢Transformer明显会很快成为NLP里担当大任的最主流的特征抽取器。

像Wordvec出现之后一样，在人工智能领域种各种目标皆可向量化，也就是我们经常听到的“万物皆可Embedding”。而Transformer模型和Bert模型的出现，更是NLP领域划时代的产物：将transformer和双向语言模型进行融合，便得到NLP划时代的，也是当下在各自NLP下流任务中获得state-of-the-art的模型-BERT

BERT起源于预训练的上下文表示学习，与之前的模型不同，BERT是一种深度双向的、无监督的语言表示，且仅使用纯文本语料库进行预训练的模型。上下文无关模型（如word2vec或GloVe）为词汇表中的每个单词生成一个词向量表示，因此容易出现单词的歧义问题。BERT考虑到单词出现时的上下文。例如，词“水分”的word2vec词向量在“植物需要吸收水分”和“财务报表里有水分”是相同的，但BERT根据上下文的不同提供不同的词向量，词向量与句子表达的句意有关。


Embedding：

首先类似 word2vec 的 token化，再进行片段标记( segment )，最后 ids 的位置编码(  position )
编码后一个 ’词‘ 有三个信息，token、段落位置信息、绝对位置信息( id: 1、2、3…)

Embedding解决的问题:
首先是之前用的 One-Hot Key，高维度，离散的，低信息密度的储存形式
其次是更好的 Contextual Similarity，上下文相关相似性。

Preview Api前置查看：123456from transformers import BertTokenizertokenizer = BertTokenizer.from_pretrained(&quot;bert-base-chinese&quot;) # 获取相应模型的tokenizerfrom transformers import AutoTokenizer, AutoModelForMaskedLMmodel = AutoModelForMaskedLM.from_pretrained(&quot;bert-base-chinese&quot;) #查看模型的分层



函数调用：字典大小，token化，ids化12345678910vocab = tokenizer.vocabprint(&quot;字典大小：&quot;, len(vocab)) 	# 查看字典大小text = &quot;[CLS] 等到潮水 [MASK] 了，就知道谁沒穿裤子。&quot;tokens = tokenizer.tokenize(text)				# 将文字分词ids = tokenizer.convert_tokens_to_ids(tokens)	# 将文字转化为数字，进行编码&#x27;&#x27;&#x27;[&#x27;[CLS]&#x27;, &#x27;等&#x27;, &#x27;到&#x27;, &#x27;潮&#x27;, &#x27;水&#x27;, &#x27;[MASK]&#x27;, &#x27;了&#x27;, &#x27;，&#x27;, &#x27;就&#x27;, &#x27;知&#x27;] ...[101, 5023, 1168, 4060, 3717, 103, 749, 8024, 2218, 4761] ... &#x27;&#x27;&#x27;

Mask模型的使用1234567891011121314151617181920212223242526from transformers import BertForMaskedLM# 除了 tokens 以外我們還需要辨別句子的 segment idstokens_tensor = torch.tensor([ids])  # (1, seq_len)segments_tensors = torch.zeros_like(tokens_tensor)  # (1, seq_len)maskedLM_model = BertForMaskedLM.from_pretrained(PRETRAINED_MODEL_NAME)# 使用 masked LM 估計 [MASK] 位置所代表的實際 token maskedLM_model.eval()with torch.no_grad():    outputs = maskedLM_model(tokens_tensor, segments_tensors)    predictions = outputs[0]    # (1, seq_len, num_hidden_units)del maskedLM_model# 將 [MASK] 位置的機率分佈取 top k 最有可能的 tokens 出來masked_index = 5k = 3probs, indices = torch.topk(torch.softmax(predictions[0, masked_index], -1), k)predicted_tokens = tokenizer.convert_ids_to_tokens(indices.tolist())# 顯示 top k 可能的字。一般我們就是取 top 1 当做预测值print(&quot;輸入 tokens ：&quot;, tokens[:10], &#x27;...&#x27;)print(&#x27;-&#x27; * 50)for i, (t, p) in enumerate(zip(predicted_tokens, probs), 1):    tokens[masked_index] = t    print(&quot;Top &#123;&#125; (&#123;:2&#125;%)：&#123;&#125;&quot;.format(i, int(p.item() * 100), tokens[:10]), &#x27;...&#x27;)

​	輸入 tokens ： [‘[CLS]’, ‘等’, ‘到’, ‘潮’, ‘水’, ‘[MASK]’, ‘了’, ‘，’, ‘就’, ‘知’] …​	Top 1 (65%)：[‘[CLS]’, ‘等’, ‘到’, ‘潮’, ‘水’, ‘来’, ‘了’, ‘，’, ‘就’, ‘知’] …​	Top 2 ( 4%)：[‘[CLS]’, ‘等’, ‘到’, ‘潮’, ‘水’, ‘过’, ‘了’, ‘，’, ‘就’, ‘知’] …​	Top 3 ( 4%)：[‘[CLS]’, ‘等’, ‘到’, ‘潮’, ‘水’, ‘干’, ‘了’, ‘，’, ‘就’, ‘知’] …
可视化模型: bertvizPandas预处理文本
多使用自定义函数
nltk库的stopwords
textblob库的拼写检查、词干抽取、词性还原等

文本数据的基本体征提取
词汇数量

字符数量

平均字长

停用词数量

特殊字符数量

数字数量

大写字母数量


文本数据的基本预处理
小写转换
去除标点符号
去除停用词
去除频现词
去除稀疏词
拼写校正
分词(tokenization)
词干提取(stemming)
词形还原(lemmatization)

</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/51428.html" title="05 问题总结"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris49.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="05 问题总结"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/51428.html" title="05 问题总结">05 问题总结</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:15.091Z" title="发表于 2022-11-21 10:16:15">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-23T06:22:50.449Z" title="更新于 2022-11-23 14:22:50">2022-11-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Trick/">Trick</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/">可视化</a></span></div><div class="content">typing库主要是进行注解 List Tuple Optional 
def aa( input0: str)  冒号后面为推荐的数据类型，使用Union 进行组合类型推荐 
如 input1 ：List(str)  推荐传入一个列表，列表内容为字符串
TensorBoard使用 
1234567891011import numpy as npfrom torch.utils.tensorboard import SummaryWriter  # 也可以使用 tensorboardX# from tensorboardX import SummaryWriter  # 也可以使用 pytorch 集成的 tensorboardwriter = SummaryWriter()for epoch in range(100):    writer.add_scalar(&#x27;add_scalar/squared&#x27;, np.square(epoch), epoch)    writer.add_scalars(&quot;add_scalars/trigonometric&quot;, &#123;&#x27;xsinx&#x27;: epoch * np.sin(epoch/5), &#x27;xcosx&#x27;: epoch* np.cos(epoch/5), &#x27;xtanx&#x27;: np.tan(epoch/5)&#125;, epoch)writer.close()

&#x3D;&#x3D;writer.add_scalar&#x3D;&#x3D;
PyTorch 修改保存模型 修改：
1vgg.classifer[layer_num] = nn.linear(dim1,dim2)

 保存：
1vgg.save(vagg.state_dict(), &#x27;model_parameters.pth&#x27;)

加载：
1vgg.load_state_dict(torch.load(&#x27;model_parameters.pth&#x27;))

</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/8398.html" title="04 QA_v3"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris44.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="04 QA_v3"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/8398.html" title="04 QA_v3">04 QA_v3</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:15.068Z" title="发表于 2022-11-21 10:16:15">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-24T14:17:59.459Z" title="更新于 2022-11-24 22:17:59">2022-11-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/QA/">QA</a></span></div><div class="content">Pipeline1234567891011121314151617import copyimport jsonimport osimport randomimport numpy as npimport pandas as pdimport torchimport torch.nn as nnimport torch.optim as optimfrom datasets import load_datasetfrom fastprogress.fastprogress import master_bar, progress_barfrom torch.cuda.amp import autocastfrom torch.utils.data import DataLoader, Datasetfrom tqdm.auto import tqdmfrom transformers import (AdamW, AutoModel, AutoModelForQuestionAnswering,                          AutoTokenizer, get_scheduler)
12345678910def set_seed(seed):    &quot;&quot;&quot; 固定随机种子，保证结果复现    &quot;&quot;&quot;    torch.manual_seed(seed)    torch.cuda.manual_seed_all(seed)    torch.backends.cudnn.deterministic = True    torch.backends.cudnn.benchmark = False    np.random.seed(seed)    random.seed(seed)    os.environ[&#x27;PYTHONHASHSEED&#x27;] = str(seed)



preprocesing1234567891011121314def open_json(file_path):    with open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as f:        data = json.load(f)        return datadef txt_json(file_path):    dt = open_json(file_path)    for i in range(len(dt[&#x27;questions&#x27;])):        pg_id = dt[&#x27;questions&#x27;][i][&#x27;paragraph_id&#x27;]        dt[&#x27;questions&#x27;][i][&#x27;context&#x27;] = dt[&#x27;paragraphs&#x27;][pg_id]    return dtdef save_json(file_path, save_name):    info = txt_json(file_path)    with open(save_name, &#x27;w&#x27;) as f:        json.dump(info, f)

123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def preprocess_function(examples):    questions = [q.strip() for q in examples[&quot;question_text&quot;]]    inputs = tokenizer(        questions,        examples[&quot;context&quot;],        max_length=384,        truncation=&quot;only_second&quot;,        return_offsets_mapping=True,        padding=&quot;max_length&quot;,        stride = 128,        return_overflowing_tokens=True,    )    offset_mapping = inputs.pop(&quot;offset_mapping&quot;)    sample_map = inputs.pop(&#x27;overflow_to_sample_mapping&#x27;)    start_positions = []    end_positions = []    for i, offset in enumerate(offset_mapping):        sample_idx = sample_map[i]        start_char = examples[&quot;answer_start&quot;][sample_idx]        end_char = examples[&quot;answer_start&quot;][sample_idx]+ len(examples[&quot;answer_text&quot;][sample_idx])+1        sequence_ids = inputs.sequence_ids(i)        idx = 0        while sequence_ids[idx] != 1:            idx += 1        context_start = idx        while sequence_ids[idx] == 1:            idx += 1        context_end = idx - 1        if offset[context_start][0] &gt; end_char or offset[context_end][1] &lt; start_char:            start_positions.append(0)            end_positions.append(0)        else:            idx = context_start            while idx &lt;= context_end and offset[idx][0] &lt;= start_char:                idx += 1            start_positions.append(idx - 1)            idx = context_end            while idx &gt;= context_start and offset[idx][1] &gt;= end_char:                idx -= 1            end_positions.append(idx + 1)    inputs[&quot;start_positions&quot;] = start_positions    inputs[&quot;end_positions&quot;] = end_positions    return inputsdef deal_dataset(file_path):    data_type = load_dataset(&quot;json&quot;, data_files=file_path, field=&#x27;questions&#x27;)    dataset = data_type.map(preprocess_function, batched=True, remove_columns=data_type[&quot;train&quot;].column_names)    return dataset

1234567891011121314151617class mydataset(Dataset):    def __init__(self, data):        self.data = data[&#x27;train&#x27;]    def __len__(self):        return len(self.data)    def __getitem__(self, idx):        input_ids = torch.tensor(self.data[idx][&#x27;input_ids&#x27;])        token_type_ids = torch.tensor(self.data[idx][&#x27;token_type_ids&#x27;])        attention_mask = torch.tensor(self.data[idx][&#x27;attention_mask&#x27;])        start_positions = torch.tensor(self.data[idx][&#x27;start_positions&#x27;])        end_positions = torch.tensor(self.data[idx][&#x27;end_positions&#x27;])                return &#123;&#x27;input_ids&#x27;:input_ids, &#x27;token_type_ids&#x27;:token_type_ids,                &#x27;attention_mask&#x27;:attention_mask, &#x27;start_positions&#x27;:start_positions,                &#x27;end_positions&#x27;:end_positions&#125;

train123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def train_bert(net, device, opti, lr, lr_scheduler, batch_size, train_loader, val_loader, epochs, model_name):        best_ep = 1    best_loss = 4.20051    train_loss, valid_loss = [], []    mb = master_bar(range(1, epochs+1))    for epoch in mb:        train_ls, valid_ls = 0, 0        # train_part        net.train()        with autocast():            for batch_data in progress_bar(train_loader, parent=mb):                                batch_data = &#123;k: v.to(device) for k, v in batch_data.items()&#125;                outputs = net(**batch_data)                loss = outputs.loss                train_ls += loss.item()                                opti.zero_grad()                loss.backward()                lr_scheduler.step()                opti.step()                            train_loss.append(train_ls/(len(train_loader)))                                    # valid_part        net.eval()        with torch.no_grad():            for batch in progress_bar(val_loader, parent=mb):                            batch_data = &#123;k: v.to(device) for k, v in batch_data.items()&#125;                outputs = net(**batch_data)                                loss = outputs.loss                valid_ls += loss.item()                            valid_loss.append(valid_ls/(len(val_loader)))                    # plot#         print(train_loss, &#x27;\n&#x27;, valid_loss) # 经常出错，不知道为什么        plot_loss_update(epoch, mb, train_loss, valid_loss)                # save        valid_loss_now = valid_loss[-1]        print(f&quot;Epoch &#123;epoch+1&#125; complete! Validation Loss : &#123;valid_loss_now:.5f&#125;&quot;, &#x27;\n&#x27;)        if valid_loss_now &lt; best_loss:            print(f&quot;Best validation loss improved from &#123;best_loss:.5f&#125; to &#123;valid_loss_now:.5f&#125;&quot;)            net_copy = copy.deepcopy(net)            best_loss = valid_loss_now            best_ep = epoch + 1            path_to_model = f&#x27;caofei_model/&#123;model_name&#125;_lr_&#123;lr&#125;_val_loss_&#123;best_loss:.5f&#125;_epoch_&#123;best_ep&#125;.pt&#x27;            torch.save(net_copy.state_dict(), path_to_model)            print(f&quot;The model has been saved in &#123;path_to_model&#125;&quot;)

1234567891011def plot_loss_update(epoch, mb, train_loss, valid_loss):    x = range(1, epoch+1)    y = np.concatenate((train_loss, valid_loss))    graphs = [[x,train_loss], [x,valid_loss]]    x_margin = 0.2    y_margin = 0.05    x_bounds = [1-x_margin, epochs+x_margin]    y_bounds = [np.min(y)-y_margin, np.max(y)+y_margin]    mb.update_graph(graphs, x_bounds, y_bounds)

调用12345678910111213141516171819# 路径设置!mkdir caofei_model  # !mkdir resultstrain_path = &#x27;../input/ml2022spring-hw7/hw7_train.json&#x27;dev_path = &#x27;../input/ml2022spring-hw7/hw7_dev.json&#x27;test_path = &#x27;../input/ml2022spring-hw7/hw7_test.json&#x27;model_name = &#x27;hfl/chinese-bert-wwm-ext&#x27;json_train_path = &#x27;./qa_dataset.json&#x27;json_dev_path = &#x27;./dev_dataset.json&#x27;# 训练超参数seed = 1222bs = 64lr = 2e-5epochs = 20

1234567tokenizer = AutoTokenizer.from_pretrained(model_name)save_json(train_path, json_train_path)save_json(dev_path, json_dev_path)train_json_dataset = deal_dataset(json_train_path)dev_json_dataset = deal_dataset(json_dev_path)

12345678import osos.environ[&quot;TOKENIZERS_PARALLELISM&quot;] = &quot;false&quot;train_dataset = mydataset(train_json_dataset)train_dataloader = DataLoader(train_dataset, batch_size=bs, num_workers=2)dev_dataset = mydataset(dev_json_dataset)dev_dataloader = DataLoader(dev_dataset, batch_size=bs, num_workers=2)

12345678910111213141516171819set_seed(seed)model = AutoModelForQuestionAnswering.from_pretrained(model_name)# model.load_state_dict(torch.load(&#x27;final_model/chineseQA_model_lr_2e-05_val_loss_4.20051_epoch_21.pt&#x27;))# len(list(model.parameters()))for idx, para in enumerate(model.parameters()):    para.requires_grad = False    if idx == 195:        break        device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)opti = torch.optim.Adam(model.parameters(), lr=lr)lr_scheduler = get_scheduler(    &quot;linear&quot;,    optimizer=opti,    num_warmup_steps=0,    num_training_steps=epochs*len(train_dataloader),)

1234model.to(device)train_bert(net=model, device=device, opti=opti, lr=lr,            lr_scheduler=lr_scheduler, batch_size=bs, train_loader=dev_dataloader,            val_loader=dev_dataloader, epochs=epochs, model_name=&#x27;chineseQA_model&#x27;)

</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/57359.html" title="04 QA_v2"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris31.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="04 QA_v2"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/57359.html" title="04 QA_v2">04 QA_v2</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:15.057Z" title="发表于 2022-11-21 10:16:15">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-23T06:22:50.439Z" title="更新于 2022-11-23 14:22:50">2022-11-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/QA/">QA</a></span></div><div class="content">答案偏移加入问题之后，答案的偏移
DataLoader 坐标data[‘train’] [idx] [‘input_ids’]
data[‘train’] [idx] [‘token_type_ids’]
data[‘train’] [idx] [‘attention_mask’]
…
Model 输入只能是{‘input_ids’:sample[0], ‘token_type_ids’:sample[1], ‘attention_mask’:sample[2], ‘start_positions’:sample[3], ‘end_positions’:sample[4]}
进行字典解包 model(**inputs)
分布训练Code1.导包123456789101112131415import torchimport torch.nn as nnimport osimport copyimport torch.optim as optimimport randomimport numpy as npimport pandas as pdfrom torch.utils.data import DataLoader, Datasetfrom torch.cuda.amp import autocast, GradScalerfrom tqdm.auto import tqdmfrom transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmupfrom datasets import load_dataset, load_metricfrom transformers import AutoModelForQuestionAnsweringfrom datasets import load_dataset
2.文件路径12345678train_path = &#x27;../input/ml2022spring-hw7/hw7_train.json&#x27;dev_path = &#x27;../input/ml2022spring-hw7/hw7_dev.json&#x27;test_path = &#x27;../input/ml2022spring-hw7/hw7_test.json&#x27;model_name = &#x27;hfl/chinese-bert-wwm-ext&#x27;!mkdir models  #可以在之前补充绝对路径!mkdir results

3.固定种子1234567891011def set_seed(seed):    &quot;&quot;&quot; 固定随机种子，保证结果复现    &quot;&quot;&quot;    torch.manual_seed(seed)    torch.cuda.manual_seed_all(seed)    torch.backends.cudnn.deterministic = True    torch.backends.cudnn.benchmark = False    np.random.seed(seed)    random.seed(seed)    os.environ[&#x27;PYTHONHASHSEED&#x27;] = str(seed)set_seed(1222)

4.预处理4.1转换json格式12345678910111213141516171819import jsondef open_json(file_path):    with open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as f:        data = json.load(f)        return datadef txt_json(file_path):    dt = open_json(file_path)    for i in range(len(dt[&#x27;questions&#x27;])):        pg_id = dt[&#x27;questions&#x27;][i][&#x27;paragraph_id&#x27;]        dt[&#x27;questions&#x27;][i][&#x27;context&#x27;] = dt[&#x27;paragraphs&#x27;][pg_id]    return dtdef save_json(file_path, save_name):    info = txt_json(file_path)    with open(save_name, &#x27;w&#x27;) as f:        json.dump(info, f)        save_json(train_path, &#x27;qa_dataset.json&#x27;)save_json(dev_path, &#x27;dev_dataset.json&#x27;)

&#x3D;&#x3D;4.2处理答案偏移&#x3D;&#x3D;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def preprocess_function(examples):    questions = [q.strip() for q in examples[&quot;question_text&quot;]]    inputs = tokenizer(        questions,        examples[&quot;context&quot;],        max_length=384,        truncation=&quot;only_second&quot;,        return_offsets_mapping=True,        padding=&quot;max_length&quot;,        stride = 128,        return_overflowing_tokens=True,    )    offset_mapping = inputs.pop(&quot;offset_mapping&quot;)    sample_map = inputs.pop(&#x27;overflow_to_sample_mapping&#x27;)    start_positions = []    end_positions = []    for i, offset in enumerate(offset_mapping):        sample_idx = sample_map[i]        start_char = examples[&quot;answer_start&quot;][sample_idx]        end_char = examples[&quot;answer_start&quot;][sample_idx]+ len(examples[&quot;answer_text&quot;][sample_idx])+1        sequence_ids = inputs.sequence_ids(i)        idx = 0        while sequence_ids[idx] != 1:            idx += 1        context_start = idx        while sequence_ids[idx] == 1:            idx += 1        context_end = idx - 1        if offset[context_start][0] &gt; end_char or offset[context_end][1] &lt; start_char:            start_positions.append(0)            end_positions.append(0)        else:            idx = context_start            while idx &lt;= context_end and offset[idx][0] &lt;= start_char:                idx += 1            start_positions.append(idx - 1)            idx = context_end            while idx &gt;= context_start and offset[idx][1] &gt;= end_char:                idx -= 1            end_positions.append(idx + 1)    inputs[&quot;start_positions&quot;] = start_positions    inputs[&quot;end_positions&quot;] = end_positions    return inputsdef deal_dataset(file_path):    data_type = load_dataset(&quot;json&quot;, data_files=file_path, field=&#x27;questions&#x27;)    dataset = data_type.map(preprocess_function, batched=True, remove_columns=data_type[&quot;train&quot;].column_names)    return dataset

5.加载数据1234567tokenizer = AutoTokenizer.from_pretrained(model_name)json_train_path = &#x27;./qa_dataset.json&#x27;json_dev_path = &#x27;./dev_dataset.json&#x27;train_json_dataset = deal_dataset(json_train_path)dev_json_dataset = deal_dataset(json_dev_path)

6.Dataset DataLoader Model 三兄弟6.1dataset &amp; dataloader123456789101112131415161718192021class mydataset(Dataset):    def __init__(self, data):        self.data = data[&#x27;train&#x27;]    def __len__(self):        return len(self.data)    def __getitem__(self, idx):        input_ids = torch.tensor(self.data[idx][&#x27;input_ids&#x27;])        token_type_ids = torch.tensor(self.data[idx][&#x27;token_type_ids&#x27;])        attention_mask = torch.tensor(self.data[idx][&#x27;attention_mask&#x27;])        start_positions = torch.tensor(self.data[idx][&#x27;start_positions&#x27;])        end_positions = torch.tensor(self.data[idx][&#x27;end_positions&#x27;])                return input_ids, token_type_ids, attention_mask, start_positions, end_positions    train_dataset = mydataset(train_json_dataset)train_dataloader = DataLoader(train_dataset, batch_size=4)dev_dataset = mydataset(dev_json_dataset)dev_dataloader = DataLoader(dev_dataset, batch_size=4)

6.2model1model = AutoModelForQuestionAnswering.from_pretrained(model_name)
7.训练123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172def train_bert(net, device, opti, lr, train_loader, val_loader, epochs, iters_to_accumulate, bert_model):    best_loss = np.Inf    best_ep = 1    nb_iterations = len(train_loader)    print_every = nb_iterations // 5  # 打印频率    iters = []    train_losses = []    val_losses = []    for ep in range(epochs):        net.train()        running_loss = 0.0        for it, batch in enumerate(tqdm(train_loader)):            with autocast():                #这里的解包，可以换成元组或者字典                input_ids, token_type_ids, attention_mask, start_positions, end_positions = batch                input_ids, token_type_ids, attention_mask, start_positions, end_positions = input_ids.to(device), token_type_ids.to(device), attention_mask.to(device), start_positions.to(device), end_positions.to(device)                                outputs = net(**&#123;&#x27;input_ids&#x27;:input_ids, &#x27;token_type_ids&#x27;:token_type_ids, &#x27;attention_mask&#x27;:attention_mask, &#x27;start_positions&#x27;:start_positions, &#x27;end_positions&#x27;:end_positions&#125;)                                loss = outputs.loss                loss.backward()                opti.zero_grad()                opti.step()                            running_loss += loss.item()            if (it + 1) % print_every == 0:                 print()                print(f&quot;Iteration &#123;it+1&#125;/&#123;nb_iterations&#125; of epoch &#123;ep+1&#125; complete. \                Loss : &#123;running_loss / print_every&#125; &quot;)                running_loss = 0.0        val_loss = evaluate_loss(net, device, val_loader)  # Compute validation loss        print()        print(f&quot;Epoch &#123;ep+1&#125; complete! Validation Loss : &#123;val_loss&#125;&quot;)        if val_loss &lt; best_loss:            print(&quot;Best validation loss improved from &#123;&#125; to &#123;&#125;&quot;.format(best_loss, val_loss))            print()            net_copy = copy.deepcopy(net)              best_loss = val_loss            best_ep = ep + 1    path_to_model=f&#x27;models/&#123;bert_model&#125;_lr_&#123;lr&#125;_val_loss_&#123;round(best_loss, 5)&#125;_ep_&#123;best_ep&#125;.pt&#x27;    torch.save(net_copy.state_dict(), path_to_model)    print(&quot;The model has been saved in &#123;&#125;&quot;.format(path_to_model))    del loss    torch.cuda.empty_cache()    def evaluate_loss(net, device, dataloader):    net.eval()    mean_loss = 0    count = 0    with torch.no_grad():        for it, batch in enumerate(tqdm(dataloader)):            input_ids, token_type_ids, attention_mask, start_positions, end_positions = batch            input_ids, token_type_ids, attention_mask, start_positions, end_positions = input_ids.to(device), token_type_ids.to(device), attention_mask.to(device), start_positions.to(device), end_positions.to(device)                        outputs = net(**&#123;&#x27;input_ids&#x27;:input_ids, &#x27;token_type_ids&#x27;:token_type_ids, &#x27;attention_mask&#x27;:attention_mask, &#x27;start_positions&#x27;:start_positions, &#x27;end_positions&#x27;:end_positions&#125;)            loss = outputs.loss            mean_loss += loss.item()                        count += 1    return mean_loss / count



8.超参数 &amp; 分布式训练&#x3D;&#x3D;nn.DataParallel(model)方式已经过时&#x3D;&#x3D;，现在使用nn.parallel.DistributedDataParallel的API进行处理
DistributedDataParallel主要通过三个函数布置且需要安装NVIDIA的apex库

使用argparse布置通道、进程编号、指定的GPU等

12345678910111213141516171819202122import argparseimport torch.distributed as distparser = argparse.ArgumentParser()    parser.add_argument(&#x27;-n&#x27;, &#x27;--nodes&#x27;, default=1, type=int, metavar=&#x27;N&#x27;)    parser.add_argument(&#x27;-g&#x27;, &#x27;--gpus&#x27;, default=1, type=int,                        help=&#x27;number of gpus per node&# ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/posts/57679.html" title="04 QA_v1"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris41.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="04 QA_v1"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/57679.html" title="04 QA_v1">04 QA_v1</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:15.031Z" title="发表于 2022-11-21 10:16:15">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-23T15:31:15.477Z" title="更新于 2022-11-23 23:31:15">2022-11-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/QA/">QA</a></span></div><div class="content">API &amp; tricktokenizer中的
return_offsets_mapping  返回一个元组如( 0 , 1 ) 由于[CLS]的加入第一个字符的位置从0 边为 1

即(x , y)  x表示元素在这句截断的话中的

	

return_overflowing_tokens  #似乎没什么必要

在设定了stride才有用
由于滑窗将句子分割，此参数为True之后，将标记每个部分属于哪个序号
如长为 500的句子， stride &#x3D; 50， max_length&#x3D;200,
分组为【0,199】【149,349】【300,499】
设置参数后返回一个 [0，0，0] 表示三个列表属于0号段落




truncation ‘only second’ 表示 传入tonkinzer的一对句子( question， txt) 对第二个 (txt) 截断 question就不截断

inputs.sequence_ids(2) 表示 return_overflowing_tokens 后 input_ids的第三个列表


小结
return_overflowing_tokens 返回的是这种，使得截断后滑动窗口，返回多个数组，不滑动就没用了
且设定的每组都是【question，strided_context】
&#x3D;&#x3D;这是问题(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (0, 0)&#x3D;&#x3D; 每个分组都有吧


1[[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (0, 0)], [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (0, 0), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (34, 35), (0, 0)], 


return_offsets_mapping 返回的数组如上图所示，[CLS]的加入使得每次断句滑动之后起始下标都会加一，
而分组内的下标属于继承制。
 (0, 0), (15, 16), (16, 17), 如同这个，这里stride&#x3D;5 ，在第一句(6, 7), (0, 0), (0, 1),。。。。 (18, 19), (19, 20), (0, 0)这里结束
倒数五个数，拿到(15, 16), 即从这里开始

inputs.sequence_ids() 括号内设定为 input_ids的分组的编号
inputs.sequence_ids(0) 如下
&#x3D;&#x3D;None 0 0 0 0 0 0 0 None 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 None&#x3D;&#x3D;
[0,0] 代表【CLS】会被直接设成none， 将question和context 以0,1分离表示，方便下面处理
[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (0, 0)]


​	
官网套路12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def preprocess_function(examples):    questions = [q.strip() for q in examples[&quot;question&quot;]]    inputs = tokenizer(        questions,        examples[&quot;context&quot;],        max_length=384,        truncation=&quot;only_second&quot;,        return_offsets_mapping=True,        padding=&quot;max_length&quot;,    )    offset_mapping = inputs.pop(&quot;offset_mapping&quot;)    answers = examples[&quot;answers&quot;]    start_positions = []    end_positions = []    for i, offset in enumerate(offset_mapping):        answer = answers[i]        start_char = answer[&quot;answer_start&quot;][0]        end_char = answer[&quot;answer_start&quot;][0] + len(answer[&quot;text&quot;][0])        sequence_ids = inputs.sequence_ids(i)        # Find the start and end of the context        idx = 0        while sequence_ids[idx] != 1:            idx += 1        context_start = idx        while sequence_ids[idx] == 1:            idx += 1        context_end = idx - 1        # If the answer is not fully inside the context, label it (0, 0)        if offset[context_start][0] &gt; end_char or offset[context_end][1] &lt; start_char:            start_positions.append(0)            end_positions.append(0)        else:            # Otherwise it&#x27;s the start and end token positions            idx = context_start            while idx &lt;= context_end and offset[idx][0] &lt;= start_char:                idx += 1            start_positions.append(idx - 1)            idx = context_end            while idx &gt;= context_start and offset[idx][1] &gt;= end_char:                idx -= 1            end_positions.append(idx + 1)    inputs[&quot;start_positions&quot;] = start_positions    inputs[&quot;end_positions&quot;] = end_positions    return inputstokenized_squad = squad.map(preprocess_function,batched=True,remove_columns=squad[&quot;train&quot;].column_names)

offset内是本批次的字符排序，包含了CLS等特殊符的占位，
这种：(6, 7), (0, 0), (15, 16), (16, 17), (17, 18),
想把answer的原始位置映射，如原始answer【515,519】
首先offset是个列表idx表示坐标，由第一个while找到（x，y）中x大于515的第一个 那个idx就是 answer的起始
​															找到第一个小于 y的那个idx 对应的就是 answer的结束了。
每次处理的是一个问答格式(json)
12345678squad[&quot;train&quot;][0]&#123;&#x27;answers&#x27;: &#123;&#x27;answer_start&#x27;: [515], &#x27;text&#x27;: [&#x27;Saint Bernadette Soubirous&#x27;]&#125;, &#x27;context&#x27;: &#x27;Architecturally, the school has a Catholic character. Atop the Main Building\&#x27;s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend &quot;Venite Ad Me Omnes&quot;. Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.&#x27;, &#x27;id&#x27;: &#x27;5733be284776f41900661182&#x27;, &#x27;question&#x27;: &#x27;To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?&#x27;, &#x27;title&#x27;: &#x27;University_of_Notre_Dame&#x27;&#125;

真不容易啊这波，加油
总结以下为零号样本
12345&#123;&#x27;id&#x27;: &#x27;TRAIN_186_QUERY_0&#x27;, &#x27;title&#x27;: &#x27;范廷颂&#x27;, &#x27;context&#x27;: &#x27;范廷颂枢机（，），圣名保禄·若瑟（），是越南罗马天主教枢机。1963年被任为主教；1990年被擢升为天主教河内总教区宗座署理；1994年被擢升为总主教，同年年底被擢升为枢机；2009年2月离世。范廷颂于1919年6月15日在越南宁平省天主教发艳教区出生；童年时接受良好教育后，被一位越南神父带到河内继续其学业。范廷颂于1940年在河内大修道院完成神学学业。范廷颂于1949年6月6日在河内的主教座堂晋铎；及后被派到圣女小德兰孤儿院服务。1950年代，范廷颂在河内堂区创建移民接待中心以收容到河内避战的难民。1954年，法越战争结束，越南民主共和国建都河内，当时很多天主教神职人员逃至越南的南方，但范廷颂仍然留在河内。翌年管理圣若望小修院；惟在1960年因捍卫修院的自由、自治及拒绝政府在修院设政治课的要求而被捕。1963年4月5日，教宗任命范廷颂为天主教北宁教区主教，同年8月15日就任；其牧铭为「我信天主的爱」。由于范廷颂被越南政府软禁差不多30年，因此他无法到所属堂区进行牧灵工作而专注研读等工作。范廷颂除了面对战争、贫困、被当局迫害天主教会等问题外，也秘密恢复修院、创建女修会团体等。1990年，教宗若望保禄二世在同年6月18日擢升范廷颂为天主教河内总教区宗座署理以填补该教区总主教的空缺。1994年3月23日，范廷颂被教宗若望保禄二世擢升为天主教河内总教区总主教并兼天主教谅山教区宗座署理；同年11月26日，若望保禄二世擢升范廷颂为枢机。范廷颂在1995年至2001年期间出任天主教越南主教团主席。2003年4月26日，教宗若望保禄二世任命天主教谅山教区兼天主教高平教区吴光杰主教为天主教河内总教区署理主教；及至2005年2月19日，范廷颂因获批辞去总主教职务而荣休；吴光杰同日真除天主教河内总教区总主教职务。范廷颂于2009年2月22日清晨在河内离世，享年89岁；其葬礼于同月26日上午在天主教河内总教区总主教座堂举行。&#x27;, &#x27;question&#x27;: &#x27;范廷颂是什么时候被任为主教的？&#x27;, &#x27;answers&#x27;: &#123;&#x27;text&#x27;: [&#x27;1963年&#x27;], &#x27;answer_start&#x27;: [30]&#125;&#125;

对其编码
123456789101112context = train_data[0][&quot;context&quot;] # question = train_data[0][&quot;question&quot;]inputs = tokenizer(    question,    context,    max_length=300,# 最大长度    truncation=&quot;only_second&quot;,# 仅对第二个输入进行截断    stride=50,# 滑动窗口大小为50    return_overflowing_tokens=True,#设定分词器支持返回重叠 token。    return_offsets_mapping=True)

结果如下，input_ids、token_type_ids、attention_mask就省略了
滑动窗口50，最大长度300，对814的样本做四个分割，（0,299）（250,549）（500,799）（749,815）四份
offset记录的就是一个字符【‘汗’】对应的token_id, 它可能中间有【SEP】等符号，所以有些offset不只是1-2，可能是1-4等跨度
注：英文中有word到sub-word的概念，如speaking可以分解为speak和ing，即作为两个token，更长的单词可能跨度更大，所以offset也会更长
可以看到每一份都是【question+context[i]】的组合，前面都是问题，后面是文章
1&#x27;offset_mapping&#x27;: [[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (30, 34), (34, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 40), (40, 41), (41, 45), (45, 46), (46, 47), (47, 48), (48, 49), (49, 50), (50, 51), (51, 52), (52, 53), (53, 54), (54, 55), (55, 56), (56, 57), (57, 58), (58, 59), (59, 60), (60, 61), (61, 62), (62, 63), (63, 67), (67, 68), (68, 69), (69, 70), (70, 71), (71, 72), (72, 73), (73, 74), (74, 75), (75, 76), (76, 77), (77, 78), (78, 79), (79, 80), (80, 81), (81, 82), (82, 83), (83, 84), (84, 85), (85, 86), (86, 87), (87, 91), (91, 92), (92, 93), (93, 94), (94, 95), (95, 96), (96, 97), (97, 98), (98, 99), (99, 100), (100, 101), (101, 105), (105, 106), (106, 107), (107, 108), (108, 110), (110, 111), (111, 112), (112, 113), (113, 114), (114, 115), (115, 116), (116, 117), (117, 118), (118, 119), (119, 120), (120, 121), (121, 122), (122, 123), (123, 124), (124, 125), (125, 126), (126, 127), (127, 128), (128, 129), (129, 130), (130, 131), (131, 132), (132, 133), (133, 134), (134, 135), (135, 136), (136, 137), (137, 138), (138, 139), (139, 140), (140, 141), (141, 142), (142, 143), (143, 144), (144, 145), (145, 146), (146, 147), (147, 148), (148, 149), (149, 150), (150, 151), (151, 152), (152, 153), (153, 154), (154, 155), (155, 156), (156, 157), (157, 158), (158, 159), (159, 163), (163, 164), (164, 165), (165, 166), (166, 167), (167, 168), (168, 169), (169, 170), (170, 171), (171, 172), (172, 173), (173, 174), (174, 175), (175, 176), (176, 177), (177, 178), (178, 179), (179, 180), (180, 181), (181, 182), (182, 186), (186, 187), (187, 188), (188, 189), (189, 190), (190, 191), (191, 192), (192, 193), (193, 194), (194, 195), (195, 196), (196, 197), (197, 198), (198, 199), (199, 200), (200, 201), (201, 202), (202, 203), (203, 204), (204, 205), (205, 206), (206, 207), (207, 208), (208, 209), (209, 210), (210, 211), (211, 212), (212, 213), (213, 214), (214, 215), (215, 216), (216, 217), (217, 218), (218, 222), (222, 223), (223, 224), (224, 225), (225, 226), (226, ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/posts/10656.html" title="03 Pipeline 句子相似度"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris31.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="03 Pipeline 句子相似度"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/10656.html" title="03 Pipeline 句子相似度">03 Pipeline 句子相似度</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:15.021Z" title="发表于 2022-11-21 10:16:15">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-23T06:22:50.410Z" title="更新于 2022-11-23 14:22:50">2022-11-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%8F%A5%E6%84%8F%E7%9B%B8%E4%BC%BC%E5%BA%A6/">句意相似度</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Pipeline/">Pipeline</a></span></div><div class="content">主要进行训练框架优化

端到端 ML 实施（训练、验证、预测、评估）
轻松适应您自己的数据集
促进其他基于 BERT 的模型（BERT、ALBERT、…）的快速实验
使用有限的计算资源进行快速训练（混合精度、梯度累积……）
多 GPU 执行
分类决策的阈值选择（不一定是 0.5）
冻结 BERT 层，只更新分类层权重或更新所有权重
种子设置，可复现结果

PipeLine导包12345678910111213import torchimport torch.nn as nnimport osimport copyimport torch.optim as optimimport randomimport numpy as npimport pandas as pdfrom torch.utils.data import DataLoader, Datasetfrom torch.cuda.amp import autocast, GradScalerfrom tqdm.auto import tqdmfrom transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmupfrom datasets import load_dataset, load_metric

Dataset123456789101112131415161718192021222324252627282930313233343536class CustomDataset(Dataset):    def __init__(self, data, maxlen, with_labels=True, bert_model=&#x27;albert-base-v2&#x27;):        self.data = data  # pandas dataframe        #Initialize the tokenizer        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)          self.maxlen = maxlen        self.with_labels = with_labels     def __len__(self):        return len(self.data)    def __getitem__(self, index):        #根据索引索取DataFrame中句子1余句子2        sent1 = str(self.data.loc[index, &#x27;sentence1&#x27;])        sent2 = str(self.data.loc[index, &#x27;sentence2&#x27;])        # 对句子对分词，得到input_ids、attention_mask和token_type_ids        encoded_pair = self.tokenizer(sent1, sent2,                                       padding=&#x27;max_length&#x27;,  # 填充到最大长度                                      truncation=True,  # 根据最大长度进行截断                                      max_length=self.maxlen,                                        return_tensors=&#x27;pt&#x27;)  # 返回torch.Tensor张量                token_ids = encoded_pair[&#x27;input_ids&#x27;].squeeze(0)  # tensor token ids        attn_masks = encoded_pair[&#x27;attention_mask&#x27;].squeeze(0)  # padded values对应为 &quot;0&quot; ，其他token为1        token_type_ids = encoded_pair[&#x27;token_type_ids&#x27;].squeeze(0)  #第一个句子的值为0，第二个句子的值为1 # 只有一句全为0        if self.with_labels:  # True if the dataset has labels            label = self.data.loc[index, &#x27;label&#x27;]            return token_ids, attn_masks, token_type_ids, label          else:            return token_ids, attn_masks, token_type_ids

建议，进行测试
12sample = next(iter(DataLoader(tr_dataset, batch_size=2)))sample

12tr_model = SentencePairClassifier(freeze_bert=True)tr_model(sample[0], sample[1], sample[2])

就是方便最后的维度转换，squeeze、flatten、view；甚至可以用reshape方法
模型定义12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class SentencePairClassifier(nn.Module):    def __init__(self, bert_model=&quot;albert-base-v2&quot;, freeze_bert=False):        super(SentencePairClassifier, self).__init__()        #  初始化预训练模型Bert xxx        self.bert_layer = AutoModel.from_pretrained(bert_model)        #  encoder 隐藏层大小        if bert_model == &quot;albert-base-v2&quot;:  # 12M 参数            hidden_size = 768        elif bert_model == &quot;albert-large-v2&quot;:  # 18M 参数            hidden_size = 1024        elif bert_model == &quot;albert-xlarge-v2&quot;:  # 60M 参数            hidden_size = 2048        elif bert_model == &quot;albert-xxlarge-v2&quot;:  # 235M 参数            hidden_size = 4096        elif bert_model == &quot;bert-base-uncased&quot;: # 110M 参数            hidden_size = 768        elif bert_model == &quot;roberta-base&quot;: #             hidden_size = 768        # 固定Bert层 更新分类输出层        if freeze_bert:            for p in self.bert_layer.parameters():                p.requires_grad = False                        self.dropout = nn.Dropout(p=0.1)        # 分类输出        self.cls_layer = nn.Linear(hidden_size, 1)    @autocast()  # 混合精度训练    def forward(self, input_ids, attn_masks, token_type_ids):        &#x27;&#x27;&#x27;        Inputs:            -input_ids : Tensor  containing token ids            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2        &#x27;&#x27;&#x27;        # 输入给Bert，获取上下文表示        # cont_reps, pooler_output = self.bert_layer(input_ids, attn_masks, token_type_ids)        outputs = self.bert_layer(input_ids, attn_masks, token_type_ids)        # last_hidden_state,pooler_output,all_hidden_states 12层        # 将last layer hidden-state of the [CLS] 输入到 classifier layer        # - last_hidden_state 的向量平均        # - 取all_hidden_states最后四层，然后做平均 weighted 平均        # - last_hidden_state+lstm        # 获取输出        logits = self.cls_layer(self.dropout(outputs[&#x27;pooler_output&#x27;]))        return logits

固定随机种子12345678910def set_seed(seed):    &quot;&quot;&quot; 固定随机种子，保证结果复现    &quot;&quot;&quot;    torch.manual_seed(seed)    torch.cuda.manual_seed_all(seed)    torch.backends.cudnn.deterministic = True    torch.backends.cudnn.benchmark = False    np.random.seed(seed)    random.seed(seed)    os.environ[&#x27;PYTHONHASHSEED&#x27;] = str(seed)

训练和评估12!mkdir models 	#可以在之前补充绝对路径!mkdir results



123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596def train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):    best_loss = np.Inf    best_ep = 1    nb_iterations = len(train_loader)    print_every = nb_iterations // 5  # 打印频率    iters = []    train_losses = []    val_losses = []    scaler = GradScaler()    for ep in range(epochs):        net.train()        running_loss = 0.0        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(train_loader)):            # 转为cuda张量            seq, attn_masks, token_type_ids, labels = \                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)                # 混合精度加速训练            with autocast():                # Obtaining the logits from the model                logits = net(seq, attn_masks, token_type_ids)                # Computing loss                loss = criterion(logits.squeeze(-1), labels.float())                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged            # Backpropagating the gradients            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.            scaler.scale(loss).backward()            if (it + 1) % iters_to_accumulate == 0:                # Optimization step                # scaler.step() first unscales the gradients of the optimizer&#x27;s assigned params.                # If these gradients do not contain infs or NaNs, opti.step() is then called,                # otherwise, opti.step() is skipped.                scaler.step(opti)                # Updates the scale for next iteration.                scaler.update()                # 根据迭代次数调整学习率。                lr_scheduler.step()                # 梯度清零                opti.zero_grad()            running_loss += loss.item()            if (it + 1) % print_every == 0:  # Print training loss information                print()                print(f&quot;Iteration &#123;it+1&#125;/&#123;nb_iterations&#125; of epoch &#123;ep+1&#125; complete. \                Loss : &#123;running_loss / print_every&#125; &quot;)                running_loss = 0.0        val_loss = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss        print()        print(f&quot;Epoch &#123;ep+1&#125; complete! Validation Loss : &#123;val_loss&#125;&quot;)        if val_loss &lt; best_loss:            print(&quot;Best validation loss improved from &#123;&#125; to &#123;&#125;&quot;.format(best_loss, val_loss))            print()            net_copy = copy.deepcopy(net)  # # 保存最优模型            best_loss = val_loss            best_ep = ep + 1    # 保存模型    path_to_model=f&#x27;models/&#123;bert_model&#125;_lr_&#123;lr&#125;_val_loss_&#123;round(best_loss, 5)&#125;_ep_&#123;best_ep&#125;.pt&#x27;    torch.save(net_copy.state_dict(), path_to_model)    print(&quot;The model has been saved in &#123;&#125;&quot;.format(path_to_model))    del loss    torch.cuda.empty_cache() # 清空显存    def evaluate_loss(net, device, criterion, dataloader):    &quot;&quot;&quot;    评估输出    &quot;&quot;&quot;    net.eval()    mean_loss = 0    count = 0    with torch.no_grad():        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):            seq, attn_masks, token_type_ids, labels = \                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)            logits = net(seq, attn_masks, token_type_ids)            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()            count += 1    return mean_loss / count


注意autocast和累计梯度 这两种加速计算的方法

evaluate的时候要注意数据的维度，标签的类型


超参数 &amp; 开始训练1234567bert_model = &quot;albert-base-v2&quot;  # &#x27;albert-base-v2&#x27;, &#x27;albert-large-v2&#x27;freeze_bert = False  # 是否冻结Bertmaxlen = 128  # 最大长度bs = 16  # batch sizeiters_to_accumulate = 2  # 梯度累加lr = 2e-5  # learning rateepochs = 2  # 训练轮数



123456789101112131415161718192021222324252627282930#  固定随机种子 便于复现set_seed(1) # 2022 # 创建训练集与验证集print(&quot;Reading training data...&quot;)train_set = CustomDataset(df_train, maxlen, bert_model)print(&quot;Reading validation data...&quot;)val_set = CustomDataset(df_val, maxlen, bert_model)# 常见训练集与验证集DataLoadertrain_loader = DataLoader(train_set, batch_size=bs, num_workers=0)val_loader = DataLoader(val_set, ba ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/eris11.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Poy One</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/poyone"><i></i><span>🛴前往github...</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客</div></div><div class="sticky_layout"><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">14</div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">28.2k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-11-25T16:21:48.338Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Poy One</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script defer src="/js/light.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 380px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 320px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka15.webp);"> <a class="categoryBar-list-link" href="categories/CV/">CV</a><span class="categoryBar-list-count">3</span><span class="categoryBar-list-descr">计算机视觉</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka22.webp);"> <a class="categoryBar-list-link" href="categories/NLP/">NLP</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr">自然语言处理</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka10.webp);"> <a class="categoryBar-list-link" href="categories/Trick/">Trick</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">小技巧</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka29.webp);"> <a class="categoryBar-list-link" href="categories/Dive-Into-Paper/">Dive Into Paper</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">论文精读</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka16.webp);"> <a class="categoryBar-list-link" href="categories/Python/">Python</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">流畅的Python</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka32.webp);"> <a class="categoryBar-list-link" href="categories/Package/">Package</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">import torch as tf</span></li></ul></div></div>';
      console.log('已挂载butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><!-- hexo injector body_end end --></body></html>