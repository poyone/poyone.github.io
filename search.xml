<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Huggingface Course 03 å¾®è°ƒèŒƒå¼</title>
      <link href="/posts/18130.html"/>
      <url>/posts/18130.html</url>
      
        <content type="html"><![CDATA[<h1 id="data"><a href="#data" class="headerlink" title="data"></a>data</h1><p>In this section we will use as an example the <strong>MRPC</strong> (Microsoft Research Paraphrase Corpus) dataset, introduced in a <a href="https://www.aclweb.org/anthology/I05-5002.pdf">paper</a> by William B. Dolan and Chris Brockett. <strong>The dataset consists of 5,801 pairs of sentences, with a label indicating if they are paraphrases</strong> or not (i.e., if both sentences mean the same thing). Weâ€™ve selected it for this chapter <strong>because itâ€™s a small dataset,</strong> so itâ€™s easy to experiment with training on it.</p><p> letâ€™s focus on the MRPC dataset! This is one of the 10 datasets composing the <a href="https://gluebenchmark.com/">GLUE benchmark</a></p><ul><li><p>ä½¿ç”¨çš„æ˜¯MRPCï¼Œå¾ˆå°å¾ˆå¥½å®éªŒ</p></li><li><p>å®ƒå±äº GLUE</p></li></ul><p>æ¥ä¸‹æ¥æŸ¥çœ‹ä¸‹æ•°æ®</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">raw_datasets = load_dataset(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">raw_datasets</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">DatasetDict(&#123;</span></span><br><span class="line"><span class="string">    train: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;label&#x27;, &#x27;idx&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 3668</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">    validation: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;label&#x27;, &#x27;idx&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 408</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">    test: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;label&#x27;, &#x27;idx&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 1725</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">&#125;)&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">raw_train_dataset = raw_datasets[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">raw_train_dataset[<span class="number">0</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;idx&#x27;: 0,</span></span><br><span class="line"><span class="string"> &#x27;label&#x27;: 1,</span></span><br><span class="line"><span class="string"> &#x27;sentence1&#x27;: &#x27;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;sentence2&#x27;: &#x27;Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#x27;&#125;&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">raw_train_dataset.features</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;sentence1&#x27;: Value(dtype=&#x27;string&#x27;, id=None),</span></span><br><span class="line"><span class="string"> &#x27;sentence2&#x27;: Value(dtype=&#x27;string&#x27;, id=None),</span></span><br><span class="line"><span class="string"> &#x27;label&#x27;: ClassLabel(num_classes=2, names=[&#x27;not_equivalent&#x27;, &#x27;equivalent&#x27;], names_file=None, id=None),</span></span><br><span class="line"><span class="string"> &#x27;idx&#x27;: Value(dtype=&#x27;int32&#x27;, id=None)&#125;&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="é¢„å¤„ç†"><a href="#é¢„å¤„ç†" class="headerlink" title="é¢„å¤„ç†"></a>é¢„å¤„ç†</h1><p>tokenizeræ–¹æ³•</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tokenized_dataset = tokenizer(</span><br><span class="line">    raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;sentence1&quot;</span>],</span><br><span class="line">    raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;sentence2&quot;</span>],</span><br><span class="line">    padding=<span class="literal">True</span>,</span><br><span class="line">    truncation=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>This works well, but it has the disadvantage of returning a dictionary (with our keys, <code>input_ids</code>, <code>attention_mask</code>, and <code>token_type_ids</code>, and values that are lists of lists). It will also only work if you have enough RAM to store your whole dataset during the tokenization (whereas the datasets from the ğŸ¤— Datasets library are <a href="https://arrow.apache.org/">Apache Arrow</a> files stored on the disk, so you only keep the samples you ask for loaded in memory).</p><ul><li>å å†…å­˜</li></ul><p>dataset.map æ–¹æ³•</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_function</span>(<span class="params">example</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(example[<span class="string">&quot;sentence1&quot;</span>], example[<span class="string">&quot;sentence2&quot;</span>], truncation=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">tokenized_datasets = raw_datasets.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>)</span><br><span class="line">tokenized_datasets</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">DatasetDict(&#123;</span></span><br><span class="line"><span class="string">    train: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;attention_mask&#x27;, &#x27;idx&#x27;, &#x27;input_ids&#x27;, &#x27;label&#x27;, &#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;token_type_ids&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 3668</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">    validation: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;attention_mask&#x27;, &#x27;idx&#x27;, &#x27;input_ids&#x27;, &#x27;label&#x27;, &#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;token_type_ids&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 408</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">    test: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;attention_mask&#x27;, &#x27;idx&#x27;, &#x27;input_ids&#x27;, &#x27;label&#x27;, &#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;token_type_ids&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 1725</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">&#125;)&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>since the <code>tokenizer</code> works on lists of pairs of sentences, as seen before. This will allow us to use the option <code>batched=True</code> in our call to <code>map()</code>, which will greatly speed up the tokenization. The <code>tokenizer</code> is backed by a tokenizer written in Rust from the <a href="https://github.com/huggingface/tokenizers">ğŸ¤— Tokenizers</a> library. This tokenizer can be very fast, but only if we give it lots of inputs at once.</p><ul><li>batch</li></ul><p>This is because padding all the samples to the maximum length is not efficient: itâ€™s better to pad the samples when weâ€™re building a batch, <strong>as then we only need to pad to the maximum length in that batch</strong>, and not the maximum length in the entire dataset. This can save a lot of time and processing power when the inputs have very variable lengths!</p><ul><li>batchå†…æœ€é•¿paddingï¼Œå°†åœ¨ä¸‹ä¸€å°èŠ‚ä»‹ç»<code>DataCollatorWithPadding</code></li></ul><p>You can even use multiprocessing when applying your preprocessing function with <code>map()</code> by passing along a <code>num_proc</code> argument. We didnâ€™t do this here because the ğŸ¤— Tokenizers library already uses multiple threads to tokenize our samples faster, but if you are not using a fast tokenizer backed by this library, this could speed up your preprocessing.</p><ul><li>å¤šçº¿ç¨‹</li></ul><blockquote><p>but note that if youâ€™re training on a TPU it can cause problems â€” TPUs prefer fixed shapes, even when that requires extra padding.</p><ul><li>tpuæ›´å–œæ¬¢æ’å®šå½¢çŠ¶ï¼Œæ‰€ä»¥ä½ å¾ˆå°‘æ•°æ®with large pad ä¹Ÿæ²¡äº‹</li></ul></blockquote><h2 id="Dynamic-padding"><a href="#Dynamic-padding" class="headerlink" title="Dynamic padding"></a>Dynamic padding</h2><p>The function that is responsible for putting together samples inside a batch is called a <em>collate function</em>. Itâ€™s an argument you can pass when you build a <code>DataLoader</code>, the default being a function that will just convert your samples to PyTorch tensors and concatenate them (recursively if your elements are lists, tuples, or dictionaries). This wonâ€™t be possible in our case since the inputs we have wonâ€™t all be of the same size.</p><ul><li>DataCollatorå¯ä»¥çœ‹æˆæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå¯ä»¥ä¼ å…¥pytorchçš„dataloaderçš„<code>collate_fn</code>å‚æ•°</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorWithPadding</span><br><span class="line"></span><br><span class="line">data_collator = DataCollatorWithPadding(tokenizer=tokenizer) <span class="comment"># æœ‰modelå‚æ•°ï¼Œå¯ä»¥æŠŠmodelä¹Ÿè®©collatorçŸ¥é“</span></span><br></pre></td></tr></table></figure><p>å†›ç«å±•ç¤º</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">samples = tokenized_datasets[<span class="string">&quot;train&quot;</span>][:<span class="number">8</span>]</span><br><span class="line">samples = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> samples.items() <span class="keyword">if</span> k <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;idx&quot;</span>, <span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>]&#125;</span><br><span class="line">[<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> samples[<span class="string">&quot;input_ids&quot;</span>]]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[50, 59, 47, 67, 59, 50, 62, 32]&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">batch = data_collator(samples)</span><br><span class="line">&#123;k: v.shape <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;attention_mask&#x27;: torch.Size([8, 67]),</span></span><br><span class="line"><span class="string"> &#x27;input_ids&#x27;: torch.Size([8, 67]),</span></span><br><span class="line"><span class="string"> &#x27;token_type_ids&#x27;: torch.Size([8, 67]),</span></span><br><span class="line"><span class="string"> &#x27;labels&#x27;: torch.Size([8])&#125;&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="Fine-tune"><a href="#Fine-tune" class="headerlink" title="Fine-tune"></a>Fine-tune</h1><h2 id="Trainer"><a href="#Trainer" class="headerlink" title="Trainer"></a>Trainer</h2><p>é¦–å…ˆæ˜¯TrainingArgumentsçš„å®šä¹‰</p><p>The first step before we can define our <code>Trainer</code> is to define a <code>TrainingArguments</code> class that will contain all the hyperparameters the <code>Trainer</code> will use for training and evaluation. The only argument you have to provide is a directory where the trained model will be saved, as well as the checkpoints along the way. For all the rest, you can leave the defaults, which should work pretty well for a basic fine-tuning.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(<span class="string">&quot;test-trainer&quot;</span>)</span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>You will notice that unlike in <a href="https://huggingface.co/course/chapter2">Chapter 2</a>, you get a warning after instantiating this pretrained model. This is because BERT has not been pretrained on classifying pairs of sentences, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead. The warnings indicate that some weights were not used (the ones corresponding to the dropped pretraining head) and that some others were randomly initialized (the ones for the new head). It concludes by encouraging you to train the model, which is exactly what we are going to do now.</p><ul><li>ä½¿ç”¨ç»†åˆ†æ¨¡å‹ (automodeåå¸¦ä»»åŠ¡åç§°çš„)ä¸ä¼šå¾—åˆ°è­¦å‘Šï¼Œæ˜¯å› ä¸ºä»–ä¼šåŠ è½½ æœ€åé¢é‚£ä¸ªå¤šåˆ†ç±»çš„æƒé‡ç»™ä½ ï¼Œè¿™æ ·é¢„è®­ç»ƒå°±åˆå¿«äº†äº›ï¼Œä¸Šé¢å†™çš„head åº”è¯¥æ˜¯æŒ‡classifierçš„é‚£å‡ å±‚å§ã€‚</li></ul><p>æ¥ä¸‹æ¥å¯ä»¥trainäº†</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    training_args,</span><br><span class="line">    train_dataset=tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=tokenized_datasets[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train() <span class="comment"># è°ƒç”¨è®­ç»ƒ</span></span><br></pre></td></tr></table></figure><p>Note that when you pass the <code>tokenizer</code> as we did here, the default <code>data_collator</code> used by the <code>Trainer</code> will be a <code>DataCollatorWithPadding</code> as defined previously, so you can skip the line <code>data_collator=data_collator</code> in this call.</p><p>This will start the fine-tuning (which should take a couple of minutes on a GPU) and report the training loss every 500 steps.</p><ul><li>ä¸å†™collateçš„è¯é»˜è®¤å°±æ˜¯DataCollatorWithPaddingï¼Œä¸è¿‡å£°æ˜ä¸€ä¸‹ï¼Œæ¯”è¾ƒå¥½ï¼Œä¸ºäº†å¯è¯»æ€§</li><li>æ¯500æ­¥ç»™ä½ ä¸€ä¸ªlossè¿”å›ï¼Œ<del>çœ‹çœ‹need lossæœ‰å¤šå¤§</del></li></ul><h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predictions = trainer.predict(tokenized_datasets[<span class="string">&quot;validation&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(predictions.predictions.shape, predictions.label_ids.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># (408, 2) (408,)</span></span><br></pre></td></tr></table></figure><ul><li>predictçš„ç»“æœå°±æ˜¯äºŒåˆ†ç±»çš„logits æ¥ä¸‹æ¥åšä¸ªargmax å–ä½ç½®ä¿¡æ¯å³å¯</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">preds = np.argmax(predictions.predictions, axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">metric.compute(predictions=preds, references=predictions.label_ids)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;accuracy&#x27;: 0.8578431372549019, &#x27;f1&#x27;: 0.8996539792387542&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>The table in the <a href="https://arxiv.org/pdf/1810.04805.pdf">BERT paper</a> reported an F1 score of 88.9 for the base model. That was the <code>uncased</code> model while we are currently using the <code>cased</code> model, which explains the better result.</p><ul><li>ä¸Šé¢è¯´ å¾®è°ƒçš„powerï¼</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">eval_preds</span>):</span><br><span class="line">    metric = evaluate.load(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">    logits, labels = eval_preds</span><br><span class="line">    predictions = np.argmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br></pre></td></tr></table></figure><p>å°è£…ä»£ç </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">training_args = TrainingArguments(<span class="string">&quot;test-trainer&quot;</span>, evaluation_strategy=<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    training_args,</span><br><span class="line">    train_dataset=tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=tokenized_datasets[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train() <span class="comment"># ç‹ ç‹ çš„è®­ç»ƒ</span></span><br></pre></td></tr></table></figure><ul><li>è¿™é‡Œæˆ‘ä»¬è®¾ç½®æ¯ä¸ªepochè¿›è¡Œä¸€æ¬¡evaluationï¼Œè¯„æµ‹æ–¹æ³•ç”¨ä¸Šé¢å°è£…çš„å‡½æ•°</li></ul><p>The <code>Trainer</code> will work out of the box on multiple GPUs or TPUs and provides lots of options, like mixed-precision training (use <code>fp16 = True</code> in your training arguments)</p><ul><li>å¦‚æœä½ çš„æœºå™¨æ”¯æŒfloat 16è®­ç»ƒé€Ÿåº¦ä¼šæ›´å¿«</li></ul><h1 id="å°ç»“"><a href="#å°ç»“" class="headerlink" title="å°ç»“"></a>å°ç»“</h1><p>ä»¥ä¸Šæ˜¯é€šè¿‡trainerå®šä¹‰çš„è®­ç»ƒï¼Œå¯ä»¥ä½œä¸ºæˆ‘ä»¬æ­£å¼å·¥ä½œå‰çš„è®­ç»ƒæµ‹è¯•ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬ä½¿ç”¨pytorchæ¥æ­£å¼å·¥ä½œã€‚</p><h1 id="full-training"><a href="#full-training" class="headerlink" title="full training"></a>full training</h1><h2 id="preprocessing"><a href="#preprocessing" class="headerlink" title="preprocessing"></a>preprocessing</h2><p>we need to apply a bit of postprocessing to our <code>tokenized_datasets</code>, to take care of some things that the <code>Trainer</code> did for us automatically. </p><ul><li><p>Remove the columns corresponding to values the model does not expect (like the <code>sentence1</code> and <code>sentence2</code> columns).</p></li><li><p>Rename the column <code>label</code> to <code>labels</code> (because the model expects the argument to be named <code>labels</code>).</p></li><li><p><strong>Set the format of the datasets</strong> so they return PyTorch tensors instead of lists.</p></li><li><p>åšç‚¹åå¤„ç†ï¼Œåˆ é™¤ã€æ”¹åã€return PyTorch tensors</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tokenized_datasets = tokenized_datasets.remove_columns([<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>, <span class="string">&quot;idx&quot;</span>])</span><br><span class="line">tokenized_datasets = tokenized_datasets.rename_column(<span class="string">&quot;label&quot;</span>, <span class="string">&quot;labels&quot;</span>)</span><br><span class="line">tokenized_datasets.set_format(<span class="string">&quot;torch&quot;</span>)</span><br><span class="line">tokenized_datasets[<span class="string">&quot;train&quot;</span>].column_names</span><br></pre></td></tr></table></figure><p>removeçš„æ“ä½œå¯ä»¥åœ¨<code>dataset.map</code>é‡Œé¢è®¾ç½®<code>remove_columns=split_datasets[&quot;train&quot;].column_names</code>, è®°å¾—æŸ¥çœ‹ä¸€ä¸‹nameåˆ«åˆ é™¤äº†ä¸è¯¥åˆ é™¤çš„ä¸œè¥¿</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">    tokenized_datasets[<span class="string">&quot;train&quot;</span>], shuffle=<span class="literal">True</span>, batch_size=<span class="number">8</span>, collate_fn=data_collator</span><br><span class="line">)</span><br><span class="line">eval_dataloader = DataLoader(</span><br><span class="line">    tokenized_datasets[<span class="string">&quot;validation&quot;</span>], batch_size=<span class="number">8</span>, collate_fn=data_collator</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">&#123;k: v.shape <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;attention_mask&#x27;: torch.Size([8, 65]),</span></span><br><span class="line"><span class="string"> &#x27;input_ids&#x27;: torch.Size([8, 65]),</span></span><br><span class="line"><span class="string"> &#x27;labels&#x27;: torch.Size([8]),</span></span><br><span class="line"><span class="string"> &#x27;token_type_ids&#x27;: torch.Size([8, 65])&#125;&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>åŠ è½½æ•°æ®å¹¶checkä¸€ä¸‹å½¢çŠ¶</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">outputs = model(**batch)</span><br><span class="line"><span class="built_in">print</span>(outputs.loss, outputs.logits.shape)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor(0.5441, grad_fn=&lt;NllLossBackward&gt;) torch.Size([8, 2])&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="optimizer"><a href="#optimizer" class="headerlink" title="optimizer"></a>optimizer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW</span><br><span class="line"></span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">5e-5</span>)</span><br></pre></td></tr></table></figure><p>Finally, the learning rate scheduler used by default is just a linear decay from the <strong>maximum value (5e-5) to 0</strong>. To properly define it, we need to know the number of training steps we will take, which is the number of epochs we want to run multiplied by the number of training batches (which is the length of our training dataloader). </p><ul><li>æˆ‘æ¨è 3e-4 cosineçš„ç»„åˆ</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> get_scheduler</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line">num_training_steps = num_epochs * <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">lr_scheduler = get_scheduler(</span><br><span class="line">    <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">    num_training_steps=num_training_steps,</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(num_training_steps)</span><br><span class="line"><span class="comment"># 1377</span></span><br></pre></td></tr></table></figure><h2 id="loop-amp-evaluation"><a href="#loop-amp-evaluation" class="headerlink" title="loop &amp; evaluation"></a>loop &amp; evaluation</h2><p>train é˜¶æ®µå°±æ˜¯pytorché‚£å‡ æ ·ï¼Œevalæ¢æˆäº†HFçš„api</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line">progress_bar = tqdm(<span class="built_in">range</span>(num_training_steps))</span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        progress_bar.update(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> eval_dataloader:</span><br><span class="line">    batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line"></span><br><span class="line">    logits = outputs.logits</span><br><span class="line">    predictions = torch.argmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line">    metric.add_batch(predictions=predictions, references=batch[<span class="string">&quot;labels&quot;</span>])</span><br><span class="line"></span><br><span class="line">metric.compute()</span><br><span class="line"><span class="comment"># &#123;&#x27;accuracy&#x27;: 0.8431372549019608, &#x27;f1&#x27;: 0.8907849829351535&#125;</span></span><br></pre></td></tr></table></figure><h2 id="Accelerate"><a href="#Accelerate" class="headerlink" title="Accelerate"></a>Accelerate</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">+ <span class="keyword">from</span> accelerate <span class="keyword">import</span> Accelerator</span><br><span class="line">  <span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW, AutoModelForSequenceClassification, get_scheduler</span><br><span class="line"></span><br><span class="line">+ accelerator = Accelerator()</span><br><span class="line"></span><br><span class="line">  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br><span class="line">  optimizer = AdamW(model.parameters(), lr=<span class="number">3e-5</span>)</span><br><span class="line"></span><br><span class="line">- device = torch.device(<span class="string">&quot;cuda&quot;</span>) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">- model.to(device)</span><br><span class="line"></span><br><span class="line">+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(</span><br><span class="line">+     train_dataloader, eval_dataloader, model, optimizer</span><br><span class="line">+ )</span><br><span class="line"></span><br><span class="line">  num_epochs = <span class="number">3</span></span><br><span class="line">  num_training_steps = num_epochs * <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">  lr_scheduler = get_scheduler(</span><br><span class="line">      <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">      optimizer=optimizer,</span><br><span class="line">      num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">      num_training_steps=num_training_steps</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  progress_bar = tqdm(<span class="built_in">range</span>(num_training_steps))</span><br><span class="line"></span><br><span class="line">  model.train()</span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">      <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">-         batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">          outputs = model(**batch)</span><br><span class="line">          loss = outputs.loss</span><br><span class="line">-         loss.backward()</span><br><span class="line">+         accelerator.backward(loss)</span><br><span class="line"></span><br><span class="line">          optimizer.step()</span><br><span class="line">          lr_scheduler.step()</span><br><span class="line">          optimizer.zero_grad()</span><br><span class="line">          progress_bar.update(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>è¿›è¡Œä»¥ä¸Šä»£ç çš„ä¿®æ”¹ï¼Œå‡å·å°±æ˜¯åœ¨åŸå…ˆçš„ä»£ç ä¸Šåˆ å‡çš„ï¼ŒåŠ å·åä¹‹</p><p>The first line to add is the import line. The second line instantiates an <code>Accelerator</code> object that will look at the environment and initialize the proper distributed setup. ğŸ¤— Accelerate handles the device placement for you, so you can remove the lines that put the model on the device (or, if you prefer, change them to use <code>accelerator.device</code> instead of <code>device</code>).</p><p>Then the main bulk of the work is done in the line that <strong>sends the dataloaders, the model, and the optimizer to</strong> <code>accelerator.prepare()</code>. This will wrap those objects in the proper container to make sure your distributed training works as intended. The remaining changes to make are removing the line that puts the batch on the <code>device</code> (again, if you want to keep this you can just change it to use <code>accelerator.device</code>) and replacing <code>loss.backward()</code> with <code>accelerator.backward(loss)</code>.</p><ul><li>å¼•å…¥å¹¶å®ä¾‹åŒ–</li><li>å°† the dataloaders, the model, and the optimizeré€å…¥accelerator</li><li>ä½¿ç”¨accelerator.backward(loss)</li></ul><blockquote><p>In order to benefit from the speed-up offered by Cloud TPUs, we recommend padding your samples to a fixed length with the <code>padding=&quot;max_length&quot;</code> and <code>max_length</code> arguments of the tokenizer.</p><ul><li>å¦‚æœä½ ä½¿ç”¨tpuè®°å¾—ç›´æ¥æ”¾æœ€å¤§é•¿åº¦å°±å¯ä»¥äº†</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> Universe </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Huggingface </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Huggingface Course 02 APIæ¦‚è¦</title>
      <link href="/posts/64185.html"/>
      <url>/posts/64185.html</url>
      
        <content type="html"><![CDATA[<h1 id="outputs"><a href="#outputs" class="headerlink" title="outputs"></a>outputs</h1><p>Note that the outputs of ğŸ¤— Transformers models behave like <code>namedtuple</code>s or dictionaries. You can access the elements by attributes (like we did) or by key (<code>outputs[&quot;last_hidden_state&quot;]</code>), or even by index if you know exactly where the thing you are looking for is (<code>outputs[0]</code>).</p><ul><li>HFçš„è¾“å…¥è¿”å› å¤§å¤šä»¥æ˜¯å…ƒç»„æˆ–å­—å…¸å½¢å¼å‡ºï¼Œå¤„ç†çš„æ—¶å€™è¦æ³¨æ„ã€‚</li></ul><p><strong>ä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»ï¼Œå¤šåˆ†ç±»ä¸­æ¯ä¸ªç±»åˆ«åˆ†åˆ«ä½œäºŒåˆ†ç±»ï¼Œæ˜¯å¦å±äºè¿™ä¸ªç±»åˆ«è¿›è¡Œè¾“å‡º</strong></p><p><code>[[0.2,0.8]ã€[0.4,0.6]ã€[0.7,0.3]]</code>  &#x3D; <code>[[1]ã€[1]ã€[0]]</code></p><h1 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertConfig, BertModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># Building the config</span></span><br><span class="line">config = BertConfig()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Building the model from the config</span></span><br><span class="line">model = BertModel(config)</span><br><span class="line">config</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">BertConfig &#123;</span></span><br><span class="line"><span class="string">  [...]</span></span><br><span class="line"><span class="string">  &quot;hidden_size&quot;: 768,</span></span><br><span class="line"><span class="string">  &quot;intermediate_size&quot;: 3072,</span></span><br><span class="line"><span class="string">  &quot;max_position_embeddings&quot;: 512,</span></span><br><span class="line"><span class="string">  &quot;num_attention_heads&quot;: 12,</span></span><br><span class="line"><span class="string">  &quot;num_hidden_layers&quot;: 12,</span></span><br><span class="line"><span class="string">  [...]</span></span><br><span class="line"><span class="string">&#125;&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="ç¯å¢ƒå˜é‡"><a href="#ç¯å¢ƒå˜é‡" class="headerlink" title="ç¯å¢ƒå˜é‡"></a>ç¯å¢ƒå˜é‡</h1><p>The weights have been downloaded and cached (so future calls to the <code>from_pretrained()</code> method wonâ€™t re-download them) in the cache folder, which defaults to <em>~&#x2F;.cache&#x2F;huggingface&#x2F;transformers</em>. You can customize your cache folder by setting the <code>HF_HOME</code> environment variable.</p><ul><li>é…ç½®ä½ å½“å‰çš„ç¯å¢ƒå˜é‡ <code>os.environ[&#39;HF_HOME&#39;]= &#39;~/.cache/huggingface/transformers&#39; </code></li></ul><h1 id="Saving"><a href="#Saving" class="headerlink" title="Saving"></a>Saving</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model.save_pretrained(<span class="string">&quot;directory_on_my_computer&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">This saves two files to your disk:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ls directory_on_my_computer</span></span><br><span class="line"><span class="string">config.json pytorch_model.bin&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li><p>If you take a look at the <em><strong>config.json</strong></em> file, youâ€™ll recognize the attributes necessary to build the <strong>model architecture</strong>. This file also contains some <strong>metadata</strong>, such as where the <strong>checkpoint originated</strong> and what ğŸ¤— <strong>Transformers version you were using</strong> when you last saved the checkpoint</p></li><li><p>The <em><strong>pytorch_model.bin</strong></em> file is known as the <em><strong>state dictionary</strong></em>; it contains all your <strong>modelâ€™s weights</strong>. The two files go hand in hand; the <strong>configuration is necessary to know your modelâ€™s architecture</strong>, while <strong>the model weights are your modelâ€™s parameters</strong>.</p></li></ul><h1 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h1><h2 id="encode"><a href="#encode" class="headerlink" title="encode"></a>encode</h2><p>é€šè¿‡<code>tokenizer.tokenize(sequence)</code>æŸ¥çœ‹åˆ†è¯åçš„ç»“æœ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;bert-base-cased&quot;</span>)</span><br><span class="line"></span><br><span class="line">sequence = <span class="string">&quot;Using a Transformer network is simple&quot;</span></span><br><span class="line">tokens = tokenizer.tokenize(sequence)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tokens)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&#x27;Using&#x27;, &#x27;a&#x27;, &#x27;transform&#x27;, &#x27;##er&#x27;, &#x27;network&#x27;, &#x27;is&#x27;, &#x27;simple&#x27;]&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>ids = tokenizer.convert_tokens_to_ids(tokens)</code></p><p>è¿˜å¯ä»¥åè¿‡æ¥å¾—åˆ°tokenï¼Œä¹Ÿå°±æ˜¯è·Ÿä¸Šé¢çš„ tokenize(seq) ä¸€æ ·çš„æ•ˆæœ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ids = tokenizer.convert_tokens_to_ids(tokens)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ids)</span><br></pre></td></tr></table></figure><h2 id="decode"><a href="#decode" class="headerlink" title="decode"></a>decode</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">decoded_string = tokenizer.decode([<span class="number">7993</span>, <span class="number">170</span>, <span class="number">11303</span>, <span class="number">1200</span>, <span class="number">2443</span>, <span class="number">1110</span>, <span class="number">3014</span>])</span><br><span class="line"><span class="built_in">print</span>(decoded_string)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;Using a Transformer network is simple&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h2><p>æŸ¥çœ‹<code>tokenizer.pad_token_id</code> padçš„id</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Will pad the sequences up to the maximum sequence length</span></span><br><span class="line">model_inputs = tokenizer(sequences, padding=<span class="string">&quot;longest&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Will pad the sequences up to the model max length</span></span><br><span class="line"><span class="comment"># (512 for BERT or DistilBERT)</span></span><br><span class="line">model_inputs = tokenizer(sequences, padding=<span class="string">&quot;max_length&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Will pad the sequences up to the specified max length</span></span><br><span class="line">model_inputs = tokenizer(sequences, padding=<span class="string">&quot;max_length&quot;</span>, max_length=<span class="number">8</span>)</span><br></pre></td></tr></table></figure><ul><li>ç›´æ¥max_lengthæ˜¯åˆ°æ¨¡å‹çš„æœ€å¤§é•¿åº¦ï¼Œlongestæ˜¯åˆ°æ‰¹æ¬¡é‡Œå¥å­çš„æœ€å¤§é•¿åº¦</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sequence1_ids = [[<span class="number">200</span>, <span class="number">200</span>, <span class="number">200</span>]]</span><br><span class="line">sequence2_ids = [[<span class="number">200</span>, <span class="number">200</span>]]</span><br><span class="line">batched_ids = [</span><br><span class="line">    [<span class="number">200</span>, <span class="number">200</span>, <span class="number">200</span>],</span><br><span class="line">    [<span class="number">200</span>, <span class="number">200</span>, tokenizer.pad_token_id],</span><br><span class="line">]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 1.5694, -1.3895]], grad_fn=&lt;AddmmBackward&gt;)</span></span><br><span class="line"><span class="string">tensor([[ 0.5803, -0.4125]], grad_fn=&lt;AddmmBackward&gt;)</span></span><br><span class="line"><span class="string">tensor([[ 1.5694, -1.3895],</span></span><br><span class="line"><span class="string">        [ 1.3373, -1.2163]], grad_fn=&lt;AddmmBackward&gt;)&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>This is because the key feature of Transformer models is attention layers that <em>contextualize</em> each token. <strong>These will take into account the padding tokens since they attend to all of the tokens of a sequence</strong>. To get the same result when passing individual sentences of different lengths through the model or when passing a batch with the same sentences and padding applied, <strong>we need to tell those attention layers to ignore the padding tokens</strong>. This is done by using an <strong>attention mask.</strong></p><ul><li>è¿™é‡Œä¸¤æ¡å•ç‹¬çš„æ•°æ®çš„ç»“æœè·Ÿç»„åˆèµ·æ¥çš„æ˜¯ä¸åŒçš„ï¼Œæ˜¯å› ä¸ºpadçš„ä½ç½®ä¹Ÿåˆ†æ•£äº†æ¨¡å‹çš„æ³¨æ„åŠ›ï¼Œè¿™ä¸æ˜¯æˆ‘ä»¬å¸Œæœ›æ¨¡å‹å­¦ä¹ çš„åœ°æ–¹</li></ul><h3 id="ATTENTION-MASK"><a href="#ATTENTION-MASK" class="headerlink" title="ATTENTION MASK"></a>ATTENTION MASK</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">batched_ids = [</span><br><span class="line">    [<span class="number">200</span>, <span class="number">200</span>, <span class="number">200</span>],</span><br><span class="line">    [<span class="number">200</span>, <span class="number">200</span>, tokenizer.pad_token_id],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">attention_mask = [</span><br><span class="line">    [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))</span><br><span class="line"><span class="built_in">print</span>(outputs.logits)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 1.5694, -1.3895],</span></span><br><span class="line"><span class="string">        [ 0.5803, -0.4125]], grad_fn=&lt;AddmmBackward&gt;)&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="é•¿å¥å­å¤„ç†"><a href="#é•¿å¥å­å¤„ç†" class="headerlink" title="é•¿å¥å­å¤„ç†"></a>é•¿å¥å­å¤„ç†</h1><p>Models have different supported sequence lengths, and some specialize in handling very long sequences. <strong><a href="https://huggingface.co/transformers/model_doc/longformer.html">Longformer</a> is one example, and another is <a href="https://huggingface.co/transformers/model_doc/led.html">LED</a>. If youâ€™re working on a task that requires very long sequences, we recommend you take a look at those models.</strong></p><p>ä¸€èˆ¬æ˜¯åœ¨tokenizeré‡Œè®¾ç½®truncation max_lenï¼Œè¿™é‡Œæ²¡è®²ï¼Œå¯ä»¥å»çœ‹çœ‹æ¨¡å‹ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> Universe </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Huggingface </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Huggingface Course 01 åŸºç¡€æ¦‚å¿µ</title>
      <link href="/posts/16149.html"/>
      <url>/posts/16149.html</url>
      
        <content type="html"><![CDATA[<p>Some of the currently <a href="https://huggingface.co/transformers/main_classes/pipelines.html">available pipelines</a> are:</p><ul><li><code>feature-extraction</code> (get the vector representation of a text)</li><li><code>fill-mask</code></li><li><code>ner</code> (named entity recognition)</li><li><code>question-answering</code></li><li><code>sentiment-analysis</code></li><li><code>summarization</code></li><li><code>text-generation</code></li><li><code>translation</code></li><li><code>zero-shot-classification</code></li></ul><h1 id="pipeline"><a href="#pipeline" class="headerlink" title="pipeline"></a>pipeline</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">generator = pipeline(<span class="string">&quot;text-generation&quot;</span>, model=<span class="string">&quot;distilgpt2&quot;</span>)</span><br><span class="line">generator(</span><br><span class="line">    <span class="string">&quot;In this course, we will teach you how to&quot;</span>,</span><br><span class="line">    max_length=<span class="number">30</span>,</span><br><span class="line">    num_return_sequences=<span class="number">2</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h1 id="model"><a href="#model" class="headerlink" title="model"></a>model</h1><p>æ¨¡å‹å‘å±•æ—¶é—´å²</p><ul><li><p><strong>June 2018</strong>: <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT</a>, the first pretrained Transformer model, used for fine-tuning on various NLP tasks and obtained state-of-the-art results</p></li><li><p><strong>October 2018</strong>: <a href="https://arxiv.org/abs/1810.04805">BERT</a>, another large pretrained model, this one designed to produce better summaries of sentences (more on this in the next chapter!)</p></li><li><p><strong>February 2019</strong>: <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a>, an improved (and bigger) version of GPT that was not immediately publicly released due to ethical concerns</p></li><li><p><strong>October 2019</strong>: <a href="https://arxiv.org/abs/1910.01108">DistilBERT</a>, a distilled version of BERT that is 60% faster, 40% lighter in memory, and still retains 97% of BERTâ€™s performance</p></li><li><p><strong>October 2019</strong>: <a href="https://arxiv.org/abs/1910.13461">BART</a> and <a href="https://arxiv.org/abs/1910.10683">T5</a>, two large pretrained models using the same architecture as the original Transformer model (the first to do so)</p></li><li><p><strong>May 2020</strong>, <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>, an even bigger version of GPT-2 that is able to perform well on a variety of tasks without the need for fine-tuning (called <em>zero-shot learning</em>)</p></li><li><p>GPT-like (also called <em>auto-regressive</em> Transformer models)</p></li><li><p>BERT-like (also called <em>auto-encoding</em> Transformer models)</p></li><li><p>BART&#x2F;T5-like (also called <em>sequence-to-sequence</em> Transformer models)</p></li></ul><h1 id="encoder-decoder"><a href="#encoder-decoder" class="headerlink" title="encoder-decoder"></a>encoder-decoder</h1><p>ç‰¹æ”»ç±»ç¼–ç å™¨çš„ä¸»è¦ç”¨å¤„</p><ul><li><strong>Encoder-only models</strong>: Good for tasks that require understanding of the input, such as sentence classification and named entity recognition.<ul><li><a href="https://huggingface.co/transformers/model_doc/albert.html">ALBERT</a></li><li><a href="https://huggingface.co/transformers/model_doc/bert.html">BERT</a></li><li><a href="https://huggingface.co/transformers/model_doc/distilbert.html">DistilBERT</a></li><li><a href="https://huggingface.co/transformers/model_doc/electra.html">ELECTRA</a></li><li><a href="https://huggingface.co/transformers/model_doc/roberta.html">RoBERTa</a></li></ul></li><li><strong>Decoder-only models</strong>: Good for generative tasks such as text generation<ul><li><a href="https://huggingface.co/transformers/model_doc/ctrl.html">CTRL</a></li><li><a href="https://huggingface.co/transformers/model_doc/gpt.html">GPT</a></li><li><a href="https://huggingface.co/transformers/model_doc/gpt2.html">GPT-2</a></li><li><a href="https://huggingface.co/transformers/model_doc/transfo-xl.html">Transformer XL</a>.</li></ul></li><li><strong>Encoder-decoder models</strong> or <strong>sequence-to-sequence models</strong>: Good for generative tasks that require an input, such as translation or summarization.<ul><li><a href="https://huggingface.co/transformers/model_doc/bart.html">BART</a></li><li><a href="https://huggingface.co/transformers/model_doc/mbart.html">mBART</a></li><li><a href="https://huggingface.co/transformers/model_doc/marian.html">Marian</a></li><li><a href="https://huggingface.co/transformers/model_doc/t5.html">T5</a></li></ul></li></ul><p>cross-attentionå±‚ä½¿å¾—decoderèƒ½æŸ¥çœ‹æ•´ä¸ªå¥æ„ï¼Œä»¥è°ƒæ•´é¡ºåºç¿»è¯‘è¾“å‡º</p><p>Note that the first attention layer in a decoder block pays attention to all (past) inputs to the decoder, <strong>but the second attention layer uses the output of the encoder. It can thus access the whole input sentence to best predict the current word</strong>. This is very useful as different languages can have grammatical rules that put the words in different orders, or some context provided later in the sentence may be helpful to determine the best translation of a given word.</p><p>æ¶æ„å’Œæ£€æŸ¥ç‚¹</p><ul><li><strong>Architecture</strong>: This is the skeleton of the model â€” the definition of each layer and each operation that happens within the model.</li><li><strong>Checkpoints</strong>: These are the weights that will be loaded in a given architecture.</li><li><strong>Model</strong>: This is an umbrella term that isnâ€™t as precise as â€œarchitectureâ€ or â€œcheckpointâ€: it can mean both. This course will specify <em>architecture</em> or <em>checkpoint</em> when it matters to reduce ambiguity.</li></ul><p>For example, BERT is an architecture while <code>bert-base-cased</code>, a set of weights trained by the Google team for the first release of BERT, is a checkpoint. However, one can say â€œthe BERT modelâ€ and â€œthe <code>bert-base-cased</code> model.â€</p><p>å³ä½¿ä½¿ç”¨å¹²å‡€çš„è¯åº“ï¼Œä¹Ÿå¯èƒ½äº§ç”Ÿæ€§åˆ«æ­§è§†ï¼Œç§æ—æ­§è§†</p><p>When asked to fill in the missing word in these two sentences, the model gives only one gender-free answer (waiter&#x2F;waitress). The others are work occupations usually associated with one specific gender â€” and yes, prostitute ended up in the top 5 possibilities the model associates with â€œwomanâ€ and â€œwork.â€ <strong>This happens even though BERT is one of the rare Transformer models not built by scraping data from all over the internet</strong>, but rather using apparently neutral data (itâ€™s trained on the <a href="https://huggingface.co/datasets/wikipedia">English Wikipedia</a> and <a href="https://huggingface.co/datasets/bookcorpus">BookCorpus</a> datasets).</p><p>When you use these tools, you therefore need to keep in the back of your mind that <strong>the original model you are using could very easily generate sexist, racist, or homophobic content</strong>. Fine-tuning the model on your data wonâ€™t make this intrinsic bias disappear.</p>]]></content>
      
      
      <categories>
          
          <category> Universe </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Huggingface </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP Baseline 01 ç¿»è¯‘</title>
      <link href="/posts/58033.html"/>
      <url>/posts/58033.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>ä»å¤´è®­ç»ƒï¼Œä¸å¦‚fine-tuneï¼Œå¦‚æœä½ æ¯”Google &amp; Mate æœ‰é’±å½“æˆ‘æ²¡è¯´</p></blockquote><h1 id="å¾…å®Œæˆ"><a href="#å¾…å®Œæˆ" class="headerlink" title="å¾…å®Œæˆ"></a>å¾…å®Œæˆ</h1><ul><li>Accelarator</li><li>get_scheduler</li><li>custom_wandb</li></ul><h1 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h1><p>è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨zh-ençš„æ•°æ®é›†å’Œæ¨¡å‹ï¼Œè¿›è¡Œç¿»è¯‘ä»»åŠ¡</p><p>è¿™é‡Œéœ€è¦æ³¨å†Œä¸€ä¸ªwandbçš„è´¦å·ï¼Œè®°å¾—å•Šã€‚</p><h1 id="ç¤ºä¾‹æŸ¥çœ‹"><a href="#ç¤ºä¾‹æŸ¥çœ‹" class="headerlink" title="ç¤ºä¾‹æŸ¥çœ‹"></a>ç¤ºä¾‹æŸ¥çœ‹</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSeq2SeqLM, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">prx = &#123;<span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;http://127.0.0.1:7890&#x27;</span>&#125;</span><br><span class="line">model_name = <span class="string">&quot;Helsinki-NLP/opus-mt-zh-en&quot;</span></span><br><span class="line">save_path = <span class="string">r&#x27;D:\00mydataset\huggingface model&#x27;</span></span><br><span class="line">data_path = <span class="string">r&#x27;D:\00mydataset\huggingface dataset&#x27;</span></span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name, proxies=prx, cache_dir=save_path)</span><br><span class="line">model = AutoModelForSeq2SeqLM.from_pretrained(model_name, proxies=prx, cache_dir=save_path)</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&#x27;news_commentary&#x27;</span>,<span class="string">&#x27;en-fr&#x27;</span>,cache_dir=data_path)</span><br><span class="line">dataset</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">DatasetDict(&#123;</span></span><br><span class="line"><span class="string">    train: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;id&#x27;, &#x27;translation&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 69206</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">&#125;)&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>è¿™ä¸ªæŒ‚ä¸ªä»£ç†åŠ é€Ÿä¸‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tokenizer</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">PreTrainedTokenizer(name_or_path=&#x27;Helsinki-NLP/opus-mt-zh-en&#x27;, vocab_size=65001, model_max_len=512, is_fast=False, padding_side=&#x27;right&#x27;, truncation_side=&#x27;right&#x27;, special_tokens=&#123;&#x27;eos_token&#x27;: &#x27;&lt;/s&gt;&#x27;, &#x27;unk_token&#x27;: &#x27;&lt;unk&gt;&#x27;, &#x27;pad_token&#x27;: &#x27;&lt;pad&gt;&#x27;&#125;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">dataset[&#x27;</span>train<span class="string">&#x27;][1][&#x27;</span>translation<span class="string">&#x27;]</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">&#123;<span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;translation&#x27;</span>: &#123;<span class="string">&#x27;en&#x27;</span>: <span class="string">&#x27;PARIS â€“ As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening. At the start of the crisis, many people likened it to 1982 or 1973, which was reassuring, because both dates refer to classical cyclical downturns.&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;zh&#x27;</span>: <span class="string">&#x27;å·´é»-éšç€ç»æµå±æœºä¸æ–­åŠ æ·±å’Œè”“å»¶ï¼Œæ•´ä¸ªä¸–ç•Œä¸€ç›´åœ¨å¯»æ‰¾å†å²ä¸Šçš„ç±»ä¼¼äº‹ä»¶å¸Œæœ›æœ‰åŠ©äºæˆ‘ä»¬äº†è§£ç›®å‰æ­£åœ¨å‘ç”Ÿçš„æƒ…å†µã€‚ä¸€å¼€å§‹ï¼Œå¾ˆå¤šäººæŠŠè¿™æ¬¡å±æœºæ¯”ä½œ1982å¹´æˆ–1973å¹´æ‰€å‘ç”Ÿçš„æƒ…å†µï¼Œè¿™æ ·å¾—ç±»æ¯”æ˜¯ä»¤äººå®½å¿ƒçš„ï¼Œå› ä¸ºè¿™ä¸¤æ®µæ—¶æœŸæ„å‘³ç€å…¸å‹çš„å‘¨æœŸæ€§è¡°é€€ã€‚&#x27;</span>&#125;&#125;</span><br><span class="line">  <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">  </span></span><br></pre></td></tr></table></figure><p>æŸ¥çœ‹ä¸‹æ•°æ®, å¯ä»¥çœ‹åˆ°è¿”å›çš„æ˜¯å­—å…¸å½¢å¼ï¼Œæˆ‘ä»¬ä¸»è¦ç”¨åˆ°translationä¸‹çš„enã€zh</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">s1 = <span class="string">&#x27;å¤©ä¸‹ç¬¬ä¸€ç¾å°‘å¥³, ç½¢äº†&#x27;</span></span><br><span class="line">inputs = tokenizer(s1, return_tensors=<span class="string">&#x27;pt&#x27;</span>,)</span><br><span class="line">inputs</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(&#123;&#x27;input_ids&#x27;: tensor([[ 9705,   359,  3615,  2797, 14889,     2,     7, 40798,     0]]), &#x27;attention_mask&#x27;: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])&#125;,)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">outputs = model.generate(**inputs)</span><br><span class="line">tokenizer.batch_decode(outputs, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&quot;The most beautiful girl in the world, that&#x27;s all.&quot;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>çœ‹ä¸‹è¾“å‡ºï¼Œè¿˜å¯ä»¥</p><blockquote><p>æ³¨æ„ï¼ŒAutoModelForSeq2SeqLMä¸åŒäºAutoModelçš„å°±æ˜¯åŠ å…¥äº†<code>model.generate</code>è¿™ä¸ªç‰¹æ€§ã€‚</p><p>ä¸ç„¶model(**inputs)æ˜¯è¦ä½ è¡¥å……ç›®æ ‡è¯­è¨€çš„ã€‚</p></blockquote><blockquote><p>If you are using a multilingual tokenizer such as mBART, mBART-50, or M2M100, you will need to set the language codes of your inputs and targets in the tokenizer by setting <code>tokenizer.src_lang</code> and <code>tokenizer.tgt_lang</code> to the right values.</p><ul><li>â€‹å¦‚æœä½ ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼Œä½ å¾—æŒ‡å®šä½ çš„æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€çš„å‚æ•°</li></ul></blockquote><hr><h1 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">split_datasets = raw_datasets[<span class="string">&quot;train&quot;</span>].train_test_split(train_size=<span class="number">0.9</span>, seed=<span class="number">20</span>)</span><br><span class="line">split_datasets</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">DatasetDict(&#123;</span></span><br><span class="line"><span class="string">    train: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;id&#x27;, &#x27;translation&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 189155</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">    test: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;id&#x27;, &#x27;translation&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 21018</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">&#125;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">split_datasets[<span class="string">&quot;validation&quot;</span>] = split_datasets.pop(<span class="string">&quot;test&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>HFçš„datasetå¯ä»¥ç›´æ¥è°ƒç”¨<code>.train_test_split(train_size=0.9, seed=20)</code></p><ul><li>HFçš„datasetå¯ä»¥ç›´æ¥è½¬DataFrameï¼Œè¿™æ ·ä½ ä¹Ÿå¯ä»¥ç›´æ¥é…åˆSklearnä½¿ç”¨</li></ul></li><li><p>ç»™testé‡å‘½åä¸ºvalidation</p></li></ul><h2 id="DataCollatorForSeq2Seq"><a href="#DataCollatorForSeq2Seq" class="headerlink" title="DataCollatorForSeq2Seq"></a>DataCollatorForSeq2Seq</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">max_length = <span class="number">128</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_function</span>(<span class="params">examples</span>):</span><br><span class="line">    inputs = [ex[<span class="string">&quot;en&quot;</span>] <span class="keyword">for</span> ex <span class="keyword">in</span> examples[<span class="string">&quot;translation&quot;</span>]]</span><br><span class="line">    targets = [ex[<span class="string">&quot;fr&quot;</span>] <span class="keyword">for</span> ex <span class="keyword">in</span> examples[<span class="string">&quot;translation&quot;</span>]]</span><br><span class="line">    model_inputs = tokenizer(</span><br><span class="line">        inputs, text_target=targets, max_length=max_length, truncation=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> model_inputs</span><br><span class="line">    </span><br><span class="line">tokenized_datasets = split_datasets.<span class="built_in">map</span>(</span><br><span class="line">    preprocess_function,</span><br><span class="line">    batched=<span class="literal">True</span>,</span><br><span class="line">    remove_columns=split_datasets[<span class="string">&quot;train&quot;</span>].column_names,)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">è¿™é‡Œæœ¬æ¥è¿˜æœ‰[&#x27;id&#x27;, &#x27;translation&#x27;],é€šè¿‡ä¸‹é¢çš„è®¾ç½®å°±åˆ é™¤äº†ã€‚</span></span><br><span class="line"><span class="string">remove_columns:</span></span><br><span class="line"><span class="string">    Remove a selection of columns while doing the mapping.</span></span><br><span class="line"><span class="string">    Columns will be removed before updating the examples with the output of `function`,i.e. </span></span><br><span class="line"><span class="string">    if `function` is adding columns with names in `remove_columns`, these columns will be kept.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p>We donâ€™t pay attention to the attention mask of the targets, as the model wonâ€™t expect it. Instead, <strong>the labels corresponding to a padding token should be set to <code>-100</code> so they are ignored in the loss computatio</strong>n. This will be done by our data collator later on since we are applying dynamic padding, but if you use padding here, you should adapt the preprocessing function to set all labels that correspond to the padding token to <code>-100</code>.</p><p>è¿™é‡Œæˆ‘ä»¬ä¸ä¼šåŠ å…¥paddingï¼Œmaskã€‚ä¹‹åæˆ‘ä»¬çš„maskä¼šè®¾æˆ-100 ä½¿å…¶ä¸ä¼šè®¡ç®—æŸå¤±ã€‚è¿™äº›éƒ½æ˜¯ä¸‹ä¸€æ­¥çš„æ“ä½œ</p></blockquote><p>ps: ä»Šå¤©çœ‹åˆ°ä¸ªbugï¼Œåº”è¯¥æ˜¯æ²¡æœ‰æ›´æ–°åˆ°æœ€æ–°ç‰ˆç‰ˆï¼Œå…·ä½“æ¥è¯´å°±æ˜¯tokenizerä¹‹åæ²¡æœ‰labelï¼Œå¦‚æœbugäº†ï¼Œå¯ä»¥è¿›è¡Œä»¥ä¸‹æ›¿æ¢</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_function</span>(<span class="params">examples</span>):</span><br><span class="line">    inputs = [ex[<span class="string">&quot;zh&quot;</span>] <span class="keyword">for</span> ex <span class="keyword">in</span> examples[<span class="string">&quot;translation&quot;</span>]]</span><br><span class="line">    targets = [ex[<span class="string">&quot;en&quot;</span>] <span class="keyword">for</span> ex <span class="keyword">in</span> examples[<span class="string">&quot;translation&quot;</span>]]</span><br><span class="line">    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set up the tokenizer for targets</span></span><br><span class="line">    <span class="keyword">with</span> tokenizer.as_target_tokenizer():</span><br><span class="line">        labels = tokenizer(targets, max_length=max_target_length, truncation=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model_inputs[<span class="string">&quot;labels&quot;</span>] = labels[<span class="string">&quot;input_ids&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> model_inputs</span><br><span class="line"></span><br><span class="line">tokenized_datasets = split_datasets.<span class="built_in">map</span>(</span><br><span class="line">    preprocess_function,</span><br><span class="line">    batched=<span class="literal">True</span>,</span><br><span class="line">    remove_columns=split_datasets[<span class="string">&quot;train&quot;</span>].column_names,)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorForSeq2Seq</span><br><span class="line"></span><br><span class="line">data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)</span><br><span class="line">batch = data_collator([tokenized_datasets[<span class="string">&quot;train&quot;</span>][i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>)])</span><br><span class="line">batch.keys()</span><br><span class="line"><span class="comment"># dict_keys([&#x27;attention_mask&#x27;, &#x27;input_ids&#x27;, &#x27;labels&#x27;, &#x27;decoder_input_ids&#x27;])</span></span><br><span class="line"></span><br><span class="line">batch[<span class="string">&quot;labels&quot;</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> tensor([[57483,     7,  3241,   403,     3,   289,  1817, 25787,    22,     6,</span></span><br><span class="line"><span class="string">          38697,    22,     2,     3,   426,    64,    72, 27734,    14,  9054,</span></span><br><span class="line"><span class="string">          56467,  6667,     8,   721,   512,  2498,   209,    64,    72, 11468,</span></span><br><span class="line"><span class="string">              5,   393,     3,  2597,     4,     3,  1817,     2,   469,   235,</span></span><br><span class="line"><span class="string">            238, 24898,    39,     8, 13579,    50, 17528,     2,    60,    42,</span></span><br><span class="line"><span class="string">          56548,     2,   695,   443, 10119,  5543,     8, 53617,     7, 38261,</span></span><br><span class="line"><span class="string">          40490,    22,     5,     0],</span></span><br><span class="line"><span class="string">         [   24, 22026,    30,  2329, 10349, 22901,    20, 52813,    17,    50,</span></span><br><span class="line"><span class="string">             12, 29940,     4,     3,  2121,    20,  1843,    45,    67,   243,</span></span><br><span class="line"><span class="string">           1945,    30,   368, 36681,    10,     3,  1796,     4, 14961,  2203,</span></span><br><span class="line"><span class="string">              6, 28291,     3, 22986,     2, 11355,     3,  3368,    64,  8700,</span></span><br><span class="line"><span class="string">             18,   469, 38575,    10,   278,    54,     8,  4291,    57, 22301,</span></span><br><span class="line"><span class="string">           1718,     8,   959, 30229,  1294,  6855,  4298,     5,     0,  -100,</span></span><br><span class="line"><span class="string">           -100,  -100,  -100,  -100]])&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># çœ‹ä¸‹åŸæ¥çš„token</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(tokenized_datasets[<span class="string">&quot;train&quot;</span>][i][<span class="string">&quot;labels&quot;</span>])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[57483, 7, 3241, 403, 3, 289, 1817, 25787, 22, 6, 38697, 22, 2, 3, 426, 64, 72, 27734, 14, 9054, 56467, 6667, 8, 721, 512, 2498, 209, 64, 72, 11468, 5, 393, 3, 2597, 4, 3, 1817, 2, 469, 235, 238, 24898, 39, 8, 13579, 50, 17528, 2, 60, 42, 56548, 2, 695, 443, 10119, 5543, 8, 53617, 7, 38261, 40490, 22, 5, 0]</span></span><br><span class="line"><span class="string">[24, 22026, 30, 2329, 10349, 22901, 20, 52813, 17, 50, 12, 29940, 4, 3, 2121, 20, 1843, 45, 67, 243, 1945, 30, 368, 36681, 10, 3, 1796, 4, 14961, 2203, 6, 28291, 3, 22986, 2, 11355, 3, 3368, 64, 8700, 18, 469, 38575, 10, 278, 54, 8, 4291, 57, 22301, 1718, 8, 959, 30229, 1294, 6855, 4298, 5, 0]&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>å¯ä»¥çœ‹åˆ°paddingçš„ä½ç½®éƒ½å˜æˆ-100äº†ï¼Œ<a href="https://poyone.github.io/posts/13310.html">pytorchä¸­ä¹Ÿæœ‰è¿™ä¸ªè®¾å®šå¯è§æˆ‘ä¹‹å‰è®²Transformerçš„å†…å®¹</a></li></ul><blockquote><p> This is all done by a <a href="https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorforseq2seq"><code>DataCollatorForSeq2Seq</code></a>. Like the <code>DataCollatorWithPadding</code>, it takes the <code>tokenizer</code> used to preprocess the inputs, but it also takes the <code>model</code>. This is because this <strong>data collator will also be responsible for preparing the decoder input IDs</strong>, which are <strong>shifted versions of the labels</strong>ï¼ˆç§»åŠ¨ç‰ˆçš„æ ‡ç­¾ï¼‰ with a special token at the beginning. Since this shift is done slightly differently for different architectures, the <code>DataCollatorForSeq2Seq</code> needs to know the <code>model</code> object<del>æå¾—è¿˜æŒºå¤æ‚</del></p></blockquote><hr><h1 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h1><blockquote><p>One weakness with <strong>BLEU is that it expects the text to already be tokenized</strong>, <strong>which makes it difficult to compare scores</strong> <strong>between models that use different tokenizers</strong>. So instead, the most commonly used metric for <strong>benchmarking translation models today is <a href="https://github.com/mjpost/sacrebleu">SacreBLEU</a>,</strong> which addresses this weakness (and others) by standardizing the tokenization step</p></blockquote><ul><li>è¿™é‡Œæˆ‘ä»¬åŠ å…¥SacreBLEUä½œä¸ºè¯„åˆ†æ ‡å‡†</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">!pip install sacrebleu</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line">metric = evaluate.load(<span class="string">&quot;sacrebleu&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>ç¤ºä¾‹1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">predictions = [</span><br><span class="line">    <span class="string">&quot;This plugin lets you translate web pages between several languages automatically.&quot;</span></span><br><span class="line">]</span><br><span class="line">references = [</span><br><span class="line">    [</span><br><span class="line">        <span class="string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span></span><br><span class="line">    ]</span><br><span class="line">]</span><br><span class="line">metric.compute(predictions=predictions, references=references)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;score&#x27;: 46.750469682990165,</span></span><br><span class="line"><span class="string"> &#x27;counts&#x27;: [11, 6, 4, 3],</span></span><br><span class="line"><span class="string"> &#x27;totals&#x27;: [12, 11, 10, 9],</span></span><br><span class="line"><span class="string"> &#x27;precisions&#x27;: [91.67, 54.54, 40.0, 33.33],</span></span><br><span class="line"><span class="string"> &#x27;bp&#x27;: 0.9200444146293233,</span></span><br><span class="line"><span class="string"> &#x27;sys_len&#x27;: 12,</span></span><br><span class="line"><span class="string"> &#x27;ref_len&#x27;: 13&#125;&#x27;&#x27;&#x27;</span></span><br><span class="line"> </span><br></pre></td></tr></table></figure><p>ç¤ºä¾‹2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">predictions = [<span class="string">&quot;This This This This&quot;</span>]</span><br><span class="line">references = [</span><br><span class="line">    [</span><br><span class="line">        <span class="string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span></span><br><span class="line">    ]</span><br><span class="line">]</span><br><span class="line">metric.compute(predictions=predictions, references=references)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;score&#x27;: 1.683602693167689,</span></span><br><span class="line"><span class="string"> &#x27;counts&#x27;: [1, 0, 0, 0],</span></span><br><span class="line"><span class="string"> &#x27;totals&#x27;: [4, 3, 2, 1],</span></span><br><span class="line"><span class="string"> &#x27;precisions&#x27;: [25.0, 16.67, 12.5, 12.5],</span></span><br><span class="line"><span class="string"> &#x27;bp&#x27;: 0.10539922456186433,</span></span><br><span class="line"><span class="string"> &#x27;sys_len&#x27;: 4,</span></span><br><span class="line"><span class="string"> &#x27;ref_len&#x27;: 13&#125;&#x27;&#x27;&#x27;</span></span><br><span class="line"> </span><br></pre></td></tr></table></figure><blockquote><p>This gets a BLEU score of 46.75, which is rather good â€” for reference, the original Transformer model in the <a href="https://arxiv.org/pdf/1706.03762.pdf">â€œAttention Is All You Needâ€ paper</a> achieved a BLEU score of 41.8 on a similar translation task between English and French! (For more information about the individual metrics, like <code>counts</code> and <code>bp</code>, see the <a href="https://github.com/mjpost/sacrebleu/blob/078c440168c6adc89ba75fe6d63f0d922d42bcfe/sacrebleu/metrics/bleu.py#L74">SacreBLEU repository</a>.) </p><ul><li>å·²ç»æ¯”æ“å¤©æŸ±è¿˜å‰å®³äº†ï¼Œå¦å¤–çš„æ ‡å‡†å¦‚ä¸‹:<ul><li>score: The BLEU score.  </li><li>counts: List of counts of correct ngrams, 1 &lt;&#x3D; n &lt;&#x3D; max_ngram_order  </li><li>totals: List of counts of total ngrams, 1 &lt;&#x3D; n &lt;&#x3D; max_ngram_order </li><li>precisions: List of precisions, 1 &lt;&#x3D; n &lt;&#x3D; max_ngram_order  </li><li>bp: The brevity penalty. </li><li>sys_len: The cumulative system length.</li><li>ref_len: The cumulative reference length.</li></ul></li></ul></blockquote><h2 id="Compute-metrics"><a href="#Compute-metrics" class="headerlink" title="Compute_metrics"></a>Compute_metrics</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">eval_preds</span>):</span><br><span class="line">    preds, labels = eval_preds</span><br><span class="line">    <span class="comment"># In case the model returns more than the prediction logits</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(preds, <span class="built_in">tuple</span>):</span><br><span class="line">        preds = preds[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Replace -100s in the labels as we can&#x27;t decode them</span></span><br><span class="line">    labels = np.where(labels != -<span class="number">100</span>, labels, tokenizer.pad_token_id)</span><br><span class="line">    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Some simple post-processing</span></span><br><span class="line">    decoded_preds = [pred.strip() <span class="keyword">for</span> pred <span class="keyword">in</span> decoded_preds]</span><br><span class="line">    decoded_labels = [[label.strip()] <span class="keyword">for</span> label <span class="keyword">in</span> decoded_labels]</span><br><span class="line"></span><br><span class="line">    result = metric.compute(predictions=decoded_preds, references=decoded_labels)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;bleu&quot;</span>: result[<span class="string">&quot;score&quot;</span>]&#125;</span><br><span class="line">    </span><br></pre></td></tr></table></figure><ul><li>å› ä¸ºdecodeä¼šè‡ªåŠ¨å¤„ç†pad_tokenæ‰€ä»¥ä½¿ç”¨<code>np.where</code>å°†-100éƒ½æ›¿æ¢æˆpad_token<ul><li>numpy.where(condition,  xï¼Œy) ï¼Œxä¸­æ¡ä»¶ä¸æˆç«‹çš„éƒ½ä¼šè¢«å¡«å……y</li></ul></li></ul><hr><h1 id="Training-Loop"><a href="#Training-Loop" class="headerlink" title="Training Loop"></a>Training Loop</h1><p>é¦–å…ˆçœ‹ä¸‹<code>Seq2SeqTrainer</code> ç„¶åå›åˆ°è‡ªå®šä¹‰çš„Loop</p><h2 id="Seq2SeqTrainer"><a href="#Seq2SeqTrainer" class="headerlink" title="Seq2SeqTrainer"></a>Seq2SeqTrainer</h2><p>è¿™é‡Œä¸æ˜¯é‡ç‚¹ï¼Œä½†æ˜¯æœ‰äº›ç»†èŠ‚å¯åœˆå¯ç‚¹ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Seq2SeqTrainingArguments</span><br><span class="line"></span><br><span class="line">args = Seq2SeqTrainingArguments(</span><br><span class="line">    <span class="string">f&quot;marian-finetuned-kde4-en-to-fr&quot;</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">&quot;no&quot;</span>,</span><br><span class="line">    save_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">32</span>,</span><br><span class="line">    per_device_eval_batch_size=<span class="number">64</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">    save_total_limit=<span class="number">3</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    predict_with_generate=<span class="literal">True</span>,</span><br><span class="line">    fp16=<span class="literal">True</span>,</span><br><span class="line">    push_to_hub=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>å®šä¹‰å‚æ•°</p><ul><li>We donâ€™t set any regular evaluation, as evaluation takes a while; we will just evaluate our model once before training and after.<ul><li>ç”±äºæˆ‘ä»¬è‡ªå®šä¹‰è¯„ä»·æ ‡å‡†ï¼Œè¿™é‡Œæˆ‘ä»¬åœ¨æ¨¡å‹è®­ç»ƒå‰æµ‹ä¸€æ¬¡scoresï¼Œè®­ç»ƒå®Œæˆåå†æµ‹ä¸€æ¬¡</li></ul></li><li>We set <code>fp16=True</code>, which speeds up training on modern GPUs.</li><li>We set <code>predict_with_generate=True</code>, as discussed above.<ul><li>the decoder performs inference by predicting tokens one by one â€” something thatâ€™s implemented behind the scenes in ğŸ¤— Transformers by the <code>generate()</code> method. The <code>Seq2SeqTrainer</code> will let us use that method for evaluation if we set <code>predict_with_generate=True</code>.</li></ul></li><li>We use <code>push_to_hub=True</code> to upload the model to the Hub at the end of each epoch</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Seq2SeqTrainer</span><br><span class="line"></span><br><span class="line">trainer = Seq2SeqTrainer(</span><br><span class="line">    model,</span><br><span class="line">    args,</span><br><span class="line">    train_dataset=tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=tokenized_datasets[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.evaluate(max_length=max_length)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;eval_loss&#x27;: 1.6964408159255981,</span></span><br><span class="line"><span class="string"> &#x27;eval_bleu&#x27;: 39.26865061007616,</span></span><br><span class="line"><span class="string"> &#x27;eval_runtime&#x27;: 965.8884,</span></span><br><span class="line"><span class="string"> &#x27;eval_samples_per_second&#x27;: 21.76,</span></span><br><span class="line"><span class="string"> &#x27;eval_steps_per_second&#x27;: 0.341&#125;&#x27;&#x27;&#x27;</span></span><br><span class="line"> </span><br><span class="line"> trainer.train()</span><br><span class="line"> trainer.evaluate(max_length=max_length)</span><br><span class="line"> <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> &#123;&#x27;eval_loss&#x27;: 0.8558505773544312,</span></span><br><span class="line"><span class="string"> &#x27;eval_bleu&#x27;: 52.94161337775576,</span></span><br><span class="line"><span class="string"> &#x27;eval_runtime&#x27;: 714.2576,</span></span><br><span class="line"><span class="string"> &#x27;eval_samples_per_second&#x27;: 29.426,</span></span><br><span class="line"><span class="string"> &#x27;eval_steps_per_second&#x27;: 0.461,</span></span><br><span class="line"><span class="string"> &#x27;epoch&#x27;: 3.0&#125;&#x27;&#x27;&#x27;</span></span><br><span class="line"> </span><br></pre></td></tr></table></figure><p><strong>Thatâ€™s a nearly 14-point improvement, which is great.</strong></p><h2 id="Custom-Training-Loop"><a href="#Custom-Training-Loop" class="headerlink" title="Custom Training Loop"></a>Custom Training Loop</h2><p>æ¥ä¸‹æ¥å°±æ˜¯é‡ç‚¹äº†</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW</span><br><span class="line"></span><br><span class="line">tokenized_datasets.set_format(<span class="string">&quot;torch&quot;</span>)</span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">    tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    collate_fn=data_collator, <span class="comment"># å°±æ˜¯ä¸Šé¢çš„DataCollatorForSeq2Seq(tokenizer, model=model)</span></span><br><span class="line">    batch_size=<span class="number">8</span>,</span><br><span class="line">)</span><br><span class="line">eval_dataloader = DataLoader(</span><br><span class="line">    tokenized_datasets[<span class="string">&quot;validation&quot;</span>], collate_fn=data_collator, batch_size=<span class="number">8</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)</span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">2e-5</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>ä»¥ä¸Šæ˜¯å¸¸è§„å®šä¹‰</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> accelerate <span class="keyword">import</span> Accelerator</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> get_scheduler</span><br><span class="line"></span><br><span class="line">accelerator = Accelerator()</span><br><span class="line">model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(</span><br><span class="line">    model, optimizer, train_dataloader, eval_dataloader)</span><br><span class="line"></span><br><span class="line">num_train_epochs = <span class="number">3</span></span><br><span class="line">num_update_steps_per_epoch = <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">num_training_steps = num_train_epochs * num_update_steps_per_epoch</span><br><span class="line"></span><br><span class="line">lr_scheduler = get_scheduler(</span><br><span class="line">    <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">    num_training_steps=num_training_steps,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>è¿™ä¸¤éƒ¨åˆ†éƒ½éœ€è¦æ³¨æ„</p><ul><li>Once we have all those objects, we can send them to the <code>accelerator.prepare()</code> method. Remember that if you want to train on TPUs in a Colab notebook, you will need to move all of this code into a training function, and that shouldnâ€™t execute any cell that instantiates an <code>Accelerator</code><ul><li>ä¸è¦åœ¨æ²¡æœ‰æŠŠæ‰€æœ‰éƒ¨ä»¶è½¬åˆ°TPUå‰ä½¿ç”¨<code>Accelerator</code></li></ul></li><li>we can use its length to compute the number of training steps. Remember we should always do this after preparing the dataloader, as that method will change the length of the <code>DataLoader</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">postprocess</span>(<span class="params">predictions, labels</span>):</span><br><span class="line">    predictions = predictions.cpu().numpy()</span><br><span class="line">    labels = labels.cpu().numpy()</span><br><span class="line"></span><br><span class="line">    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Replace -100 in the labels as we can&#x27;t decode them.</span></span><br><span class="line">    labels = np.where(labels != -<span class="number">100</span>, labels, tokenizer.pad_token_id)</span><br><span class="line">    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Some simple post-processing</span></span><br><span class="line">    decoded_preds = [pred.strip() <span class="keyword">for</span> pred <span class="keyword">in</span> decoded_preds]</span><br><span class="line">    decoded_labels = [[label.strip()] <span class="keyword">for</span> label <span class="keyword">in</span> decoded_labels]</span><br><span class="line">    <span class="keyword">return</span> decoded_preds, decoded_labels</span><br></pre></td></tr></table></figure><p>æ­£å¼è®­ç»ƒä¹‹å‰ï¼Œå…ˆå®šä¹‰ä¸€ä¸‹åå¤„ç†å‡½æ•°ï¼Œè¾“å‡ºæˆ‘ä»¬é¢„æµ‹çš„æ ‡ç­¾ç»™Sacrebleu</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">progress_bar = tqdm(<span class="built_in">range</span>(num_training_steps))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_train_epochs):</span><br><span class="line">    <span class="comment"># Training</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        accelerator.backward(loss)</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        progress_bar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Evaluation</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(eval_dataloader):</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            generated_tokens = accelerator.unwrap_model(model).generate(</span><br><span class="line">                batch[<span class="string">&quot;input_ids&quot;</span>],</span><br><span class="line">                attention_mask=batch[<span class="string">&quot;attention_mask&quot;</span>],</span><br><span class="line">                max_length=<span class="number">128</span>,</span><br><span class="line">            )</span><br><span class="line">        labels = batch[<span class="string">&quot;labels&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Necessary to pad predictions and labels for being gathered</span></span><br><span class="line">        generated_tokens = accelerator.pad_across_processes(</span><br><span class="line">            generated_tokens, dim=<span class="number">1</span>, pad_index=tokenizer.pad_token_id</span><br><span class="line">        )</span><br><span class="line">        labels = accelerator.pad_across_processes(labels, dim=<span class="number">1</span>, pad_index=-<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">        predictions_gathered = accelerator.gather(generated_tokens)</span><br><span class="line">        labels_gathered = accelerator.gather(labels)</span><br><span class="line"></span><br><span class="line">        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)</span><br><span class="line">        metric.add_batch(predictions=decoded_preds, references=decoded_labels)</span><br><span class="line"></span><br><span class="line">    results = metric.compute()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;epoch <span class="subst">&#123;epoch&#125;</span>, BLEU score: <span class="subst">&#123;results[<span class="string">&#x27;score&#x27;</span>]:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save and upload</span></span><br><span class="line">    <span class="comment"># accelerator.wait_for_everyone()</span></span><br><span class="line"><span class="comment">#     unwrapped_model = accelerator.unwrap_model(model)</span></span><br><span class="line"><span class="comment">#     unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)</span></span><br><span class="line"><span class="comment">#     if accelerator.is_main_process:</span></span><br><span class="line"><span class="comment">#         tokenizer.save_pretrained(output_dir)</span></span><br><span class="line"><span class="comment">#         repo.push_to_hub(</span></span><br><span class="line"><span class="comment">#             commit_message=f&quot;Training in progress epoch &#123;epoch&#125;&quot;, blocking=False</span></span><br><span class="line"><span class="comment">#         )</span></span><br></pre></td></tr></table></figure><hr><p>æœ€åé€šè¿‡pipelineæµ‹è¯•ä¸‹è¾“å‡º</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># Replace this with your own checkpoint</span></span><br><span class="line">model_checkpoint = <span class="string">&quot;huggingface-course/marian-finetuned-kde4-en-to-fr&quot;</span></span><br><span class="line">translator = pipeline(<span class="string">&quot;translation&quot;</span>, model=model_checkpoint)</span><br><span class="line">translator(<span class="string">&quot;Default to expanded threads&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><ul><li>é¦–å…ˆæ˜¯pipeline</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">!pip install sacrebleu</span><br><span class="line">!pip install evaluate</span><br><span class="line">!pip install accelerate</span><br><span class="line">!pip install --upgrade transformers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_metric</span><br><span class="line"><span class="keyword">from</span> accelerate <span class="keyword">import</span> Accelerator</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (AdamW, AutoModelForSeq2SeqLM, AutoTokenizer,</span><br><span class="line">                          DataCollatorForSeq2Seq, Seq2SeqTrainer,</span><br><span class="line">                          Seq2SeqTrainingArguments, get_scheduler,pipeline)</span><br><span class="line">                          </span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">logging.disable(logging.WARNING)</span><br><span class="line">os.environ[<span class="string">&#x27;CUDA_LAUNCH_BLOCKING&#x27;</span>] = <span class="string">&quot;1&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">CONFIG = &#123;<span class="string">&quot;seed&quot;</span>: <span class="number">2021</span>,</span><br><span class="line">          <span class="string">&quot;epochs&quot;</span>: <span class="number">3</span>,</span><br><span class="line">          <span class="string">&quot;model_name&quot;</span>: <span class="string">&quot;roberta-base&quot;</span>,</span><br><span class="line">          <span class="string">&quot;train_batch_size&quot;</span>: <span class="number">32</span>,</span><br><span class="line">          <span class="string">&quot;valid_batch_size&quot;</span>: <span class="number">64</span>,</span><br><span class="line">          <span class="string">&quot;max_length&quot;</span>: <span class="number">128</span>,</span><br><span class="line">          <span class="string">&quot;learning_rate&quot;</span>: <span class="number">1e-4</span>,</span><br><span class="line">          <span class="string">&quot;scheduler&quot;</span>: <span class="string">&#x27;CosineAnnealingLR&#x27;</span>,</span><br><span class="line">          <span class="string">&quot;min_lr&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">          <span class="string">&quot;T_max&quot;</span>: <span class="number">500</span>,</span><br><span class="line">          <span class="string">&quot;weight_decay&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">          <span class="string">&quot;n_fold&quot;</span>: <span class="number">5</span>,</span><br><span class="line">          <span class="string">&quot;n_accumulate&quot;</span>: <span class="number">1</span>,</span><br><span class="line">          <span class="string">&quot;num_classes&quot;</span>: <span class="number">1</span>,</span><br><span class="line">          <span class="string">&quot;margin&quot;</span>: <span class="number">0.5</span>,</span><br><span class="line">          <span class="string">&quot;device&quot;</span>: torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>),</span><br><span class="line">          <span class="string">&quot;hash_name&quot;</span>: HASH_NAME</span><br><span class="line">          &#125;</span><br><span class="line">          </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_seed</span>(<span class="params">seed=<span class="number">42</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Sets the seed of the entire notebook so results are the same every time we run.</span></span><br><span class="line"><span class="string">    This is for REPRODUCIBILITY.&#x27;&#x27;&#x27;</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    <span class="comment"># When running on the CuDNN backend, two further options must be set</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    <span class="comment"># Set a fixed value for the hash seed</span></span><br><span class="line">    os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed)</span><br><span class="line">    </span><br><span class="line">set_seed(CONFIG[<span class="string">&#x27;seed&#x27;</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model_name = <span class="string">&quot;Helsinki-NLP/opus-mt-zh-en&quot;</span></span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">model = AutoModelForSeq2SeqLM.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line">dataset_raw = load_dataset(<span class="string">&#x27;news_commentary&#x27;</span>,<span class="string">&#x27;en-zh&#x27;</span>)</span><br><span class="line">dataset_raw, dataset_raw[<span class="string">&#x27;train&#x27;</span>][<span class="string">&#x27;translation&#x27;</span>][<span class="number">1</span>]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Huggingface </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>22-12-3 e.g etc. è¯¦è§£</title>
      <link href="/posts/2534.html"/>
      <url>/posts/2534.html</url>
      
        <content type="html"><![CDATA[<ul><li><p>â€œe.g.â€æ˜¯æ‹‰ä¸æ–‡â€œexempli gratiaâ€çš„ç¸®å¯«ï¼Œæ„æ€æ˜¯ã€Œä¾‹å¦‚ã€èˆ‰ä¾‹ä¾†èªªã€ï¼Œå°±æ˜¯è‹±æ–‡çš„for exampleæˆ–for instanceã€‚</p></li><li><p>ex.çš„æ„æ€æ˜¯ã€Œç¯„ä¾‹æˆ–ç·´ç¿’ã€ï¼Œä¹Ÿå°±æ˜¯è‹±æ–‡çš„exampleæˆ–exerciseã€‚<br>æ‰€ä»¥åˆ¥å†æŠŠex.æ”¾åˆ°å¥å­è£¡ç•¶ã€Œä¾‹å¦‚ã€ç”¨äº†å–”ã€‚</p></li><li><p>é‚„æœ‰â€œi.e.â€ä¹Ÿæ˜¯éå¸¸è®“äººå›°æƒ‘çš„ç¸®å¯«ï¼Œâ€œi.e.â€å…¶å¯¦æ˜¯æ‹‰ä¸æ–‡â€œid estâ€çš„ç¸®å¯«ï¼Œæ„æŒ‡ã€Œæ›å¥è©±èªªã€ã€‚<br>è‹±æ–‡å°±æ˜¯that is &#x2F; in other wordsï¼Œç›®çš„æ˜¯çµ¦äºˆæ›´å¤šè³‡è¨Šä¾†é—¡è¿°å‰é¢æ‰€èªªçš„è©±ã€‚</p></li><li><p>é™¤æ­¤ä¹‹å¤–ï¼Œåœ¨èˆ‰ä¾‹çš„æ™‚å€™é‚„è¦ç‰¹åˆ¥æ³¨æ„etc.çš„æ­£ç¢ºç”¨æ³•ï¼Œetc.æ˜¯â€œet ceteraâ€çš„ç¸®å¯«ï¼Œæ„æ€æ˜¯ã€Œç­‰ç­‰ã€ï¼Œç›¸ç•¶æ–¼â€œâ€¦and so on.â€ã€‚</p><p>æé†’å¤§å®¶ï¼Œâ€œe.g.â€å’Œâ€œetc.â€ä¸èƒ½å‡ºç¾åœ¨åŒä¸€å€‹å¥å­ä¸­å–”ã€‚<br>å› ç‚ºe.g.æ˜¯èˆ‰ä¾‹ä¾†èªªï¼Œæ„æ—¨èˆ‰å¹¾å€‹ä¾‹å­ï¼Œæ‰€ä»¥å…¶ä¸­å°±å·²ç¶“æœ‰ã€Œç­‰ç­‰ã€çš„å«æ„ï¼Œå› æ­¤è‹¥å†åŠ ä¸Šetc.å°±æ˜¯ç•«è›‡æ·»è¶³äº†ã€‚</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Universe </category>
          
      </categories>
      
      
        <tags>
            
            <tag> è‹±è¯­ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>22-12-4 drill spoiler alert</title>
      <link href="/posts/61418.html"/>
      <url>/posts/61418.html</url>
      
        <content type="html"><![CDATA[<ul><li><p>It will be interesting to see if our fine-tuned model picks up on those <strong>particularities</strong> of the dataset (<strong>spoiler alert</strong>: it will).</p><ul><li>ç‰¹æ®Š n.</li><li>å‰§é€è­¦å‘Š (ä¿šè¯­get)</li></ul></li><li><p><strong>You know the drill</strong></p><ul><li>drillåŒæ—¶ä¹Ÿæœ‰ç»è¿‡ä¸¥æ ¼è®­ç»ƒçš„æ„æ€</li></ul><blockquote><p>æ˜¯ä¸€ä¸ªéå¸¸åœ°é“çš„ç¾è¯­å£è¯­è¡¨è¾¾ï¼ŒYou know the drillçš„æ„æ€æ˜¯â€ä½ çŸ¥é“è¯¥æ€ä¹ˆåšâ€ï¼Œå¥—ç”¨ä¸­æ–‡é‡Œæµè¡Œçš„ä¸€å¥è¯´æ³•â€ä½ æ‡‚çš„â€ï¼ŒåŒ—äº¬è¯é‡Œæœ‰ä¸€ä¸ªéå¸¸è´´åˆ‡çš„è¯´æ³•â€é—¨å„¿æ¸…â€ã€‚è¿™ä¸ªçŸ­è¯­é€šå¸¸æŒ‡:ç”±äºæŸäººå¯¹ç‰¹å®šæƒ…å†µä¸‹çš„åšäº‹æµç¨‹éå¸¸ç†Ÿæ‚‰ï¼Œæ‰€ä»¥ä¸éœ€è¦å¤šè§£é‡Šï¼Œå°±çŸ¥é“è¯¥å¦‚ä½•åº”å¯¹ã€å¤„ç†ã€‚You know the drillçš„è‹±æ–‡è§£é‡Šä¸º: to understand what usually happens in a givenä½ çŸ¥é“é’»æ˜¯ä¸€ä¸ªéå¸¸åœ°é“çš„ç¾è¯­å£è¯­è¡¨è¾¾ï¼Œä½ çŸ¥é“é’»çš„æ„æ€æ˜¯â€œä½ çŸ¥é“è¯¥æ€ä¹ˆåšâ€ï¼Œå¥—ç”¨ä¸­æ–‡é‡Œæµè¡Œçš„ä¸€å¥è¯´æ³•â€œä½ æ‡‚çš„â€ï¼ŒåŒ—äº¬è¯é‡Œæœ‰ä¸€ä¸ªéå¸¸è´´åˆ‡çš„è¯´æ³•â€œé—¨å„¿æ¸…â€ã€‚è¿™ä¸ªçŸ­è¯­é€šå¸¸æŒ‡:ç”±äºæŸäººå¯¹ç‰¹å®šæƒ…å†µä¸‹çš„åšäº‹æµç¨‹éå¸¸ç†Ÿæ‚‰ï¼Œæ‰€ä»¥ä¸éœ€è¦å¤šè§£é‡Šï¼Œå°±çŸ¥é“è¯¥å¦‚ä½•åº”å¯¹ã€å¤„ç†.æ‚¨çŸ¥é“çš„è‹±æ–‡è§£é‡Šä¸ºï¼šè¦äº†è§£åœ¨ç»™å®šçš„<br>situation; an expression meaning â€œyou know what to do, no questions requiredâ€.; to know whatneeds to be done or what usually happens in a situation.æƒ…å†µï¼›æ„æ€æ˜¯â€œä½ çŸ¥é“è¯¥åšä»€ä¹ˆï¼Œä¸éœ€è¦é—®é—®é¢˜â€ï¼›çŸ¥é“éœ€è¦åšä»€ä¹ˆï¼Œæˆ–è€…åœ¨ä¸€ä¸ªæƒ…å†µä¸‹é€šå¸¸ä¼šå‘ç”Ÿä»€ä¹ˆã€‚</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> Universe </category>
          
      </categories>
      
      
        <tags>
            
            <tag> è‹±è¯­ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>huggingface proxy</title>
      <link href="/posts/35234.html"/>
      <url>/posts/35234.html</url>
      
        <content type="html"><![CDATA[<h1 id="huggingface"><a href="#huggingface" class="headerlink" title="huggingface"></a>huggingface</h1><p>åœ¨æœ‰ä»£ç†çš„æƒ…å†µä¸‹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from transformers import AutoModelForSeq2SeqLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line">prx = &#123;&#x27;https&#x27;: &#x27;http://127.0.0.1:7890&#x27;&#125;</span><br><span class="line">model_name = &quot;Helsinki-NLP/opus-mt-zh-en&quot;</span><br><span class="line">save_path = r&#x27;D:\00mydataset\huggingface model&#x27;</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name, proxies=prx, cache_dir=save_path)</span><br></pre></td></tr></table></figure><p>ç›´æ¥è®¾ç½®ä»£ç†å°±å¯ä»¥æ¥åˆ°huggingfaceäº†</p><h1 id="vscode"><a href="#vscode" class="headerlink" title="vscode"></a>vscode</h1><p>åœ¨settingé‡Œé¢çš„proxyçš„ç¬¬ä¸€æ è®¾ç½®<code>http://127.0.0.1:7890</code> åé¢çš„7890å°±æ˜¯ä½ çš„ç«¯å£å·ï¼Œåœ¨ä½ çš„ä»£ç†å¤„å¯ä»¥æŸ¥çœ‹</p><h1 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h1><p>pip æˆ‘æ ¹æ®<a href="https://www.cnblogs.com/bonheur/p/12306108.html">è¿™ç¯‡æ–‡ç« </a>åœ¨ç»ˆç«¯ç›´æ¥è®¾ç½® <code>set http_proxy=&#39;http://127.0.0.1:7890&#39;</code> è¿™å°±å¥½äº†</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># åœ¨pipç›®å½•åˆ›å»ºå¹¶ç¼–è¾‘pip.iniï¼ˆé…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶ï¼‰</span><br><span class="line">cd C:\Users\(ä½ çš„ç”¨æˆ·å)   </span><br><span class="line">mkdir pip                # åˆ›å»ºpipæ–‡ä»¶å¤¹</span><br><span class="line">cd pip                     # è¿›å…¥pipè·¯å¾„ç›®å½•ä¸‹</span><br><span class="line">cd.&gt;pip.ini              # åˆ›å»ºpip.iniæ–‡ä»¶</span><br><span class="line"></span><br><span class="line"># ç„¶åæ‰“å¼€C:\Users(ç”¨æˆ·å)\pip\pip.iniï¼Œæ·»åŠ å¦‚ä¸‹å†…å®¹ï¼š</span><br><span class="line">[global]</span><br><span class="line">proxy=http://10.20.217.2:8080</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> HuggingFace </tag>
            
            <tag> Proxy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HF Course 06 Tokenizerè¯¦è§£</title>
      <link href="/posts/36291.html"/>
      <url>/posts/36291.html</url>
      
        <content type="html"><![CDATA[<h1 id="Main-Types-of-Tokenizers"><a href="#Main-Types-of-Tokenizers" class="headerlink" title="Main Types of Tokenizers"></a>Main Types of Tokenizers</h1><ul><li><p><a href="https://huggingface.co/docs/transformers/main/en/tokenizer_summary#byte-pair-encoding">Byte-Pair Encoding (BPE)</a></p></li><li><p><a href="https://huggingface.co/docs/transformers/main/en/tokenizer_summary#wordpiece">WordPiece</a></p></li><li><p><a href="https://huggingface.co/docs/transformers/main/en/tokenizer_summary#sentencepiece">SentencePiece</a></p></li></ul><blockquote><p><a href="https://spacy.io/">spaCy</a> and <a href="http://www.statmt.org/moses/?n=Development.GetStarted">Moses</a> are two popular rule-based tokenizers.</p></blockquote><hr><h1 id="Subword"><a href="#Subword" class="headerlink" title="Subword"></a>Subword</h1><blockquote><p>word-level å¤ªå¤§ï¼Œcharacter-levelåŒ…å«ä¸äº†å¾ˆå¤šè¯­ä¹‰</p><p>So to get the best of both worlds, transformers models use a hybrid between word-level and character-level tokenization called <strong>subword</strong> tokenization.</p></blockquote><ul><li>Subword tokenization algorithms rely on the principle that frequently used words should not be split into smaller subwords, but rare words should be decomposed into meaningful subwords.<ul><li>å°†ä½é¢‘è¯(ä¸“æœ‰åè¯é‚£äº›) æ‹†è§£ã€åˆ†è¯</li></ul></li></ul><p>ä¾‹å¦‚</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&quot;bert-base-uncased&quot;</span>)</span><br><span class="line">tokenizer.tokenize(<span class="string">&quot;I have a new GPU!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [&quot;i&quot;, &quot;have&quot;, &quot;a&quot;, &quot;new&quot;, &quot;gp&quot;, &quot;##u&quot;, &quot;!&quot;]</span></span><br></pre></td></tr></table></figure><ul><li>æ›´å°çš„è¯æ±‡è¡¨æ„å‘³ç€å¤±å»æ›´å¤šçš„è¯ä¹‰ï¼Œåœ¨è¯ä¹‰å’Œè¿ç®—èµ„æºçš„å¹³è¡¡å¼•å‡ºäº†ä¸‹é¢çš„å‡ ä¸ªç®—æ³•ã€‚</li></ul><hr><h1 id="Byte-Pair-Encoding-BPE"><a href="#Byte-Pair-Encoding-BPE" class="headerlink" title="Byte-Pair Encoding (BPE)"></a>Byte-Pair Encoding (BPE)</h1><p><a href="https://huggingface.co/docs/transformers/main/en/model_doc/gpt2">GPT-2</a>, <a href="https://huggingface.co/docs/transformers/main/en/model_doc/roberta">Roberta</a>,  <a href="https://huggingface.co/docs/transformers/main/en/model_doc/xlm">XLM</a>,  <a href="https://huggingface.co/docs/transformers/main/en/model_doc/flaubert">FlauBERT</a> ,<a href="https://huggingface.co/docs/transformers/main/en/model_doc/gpt">GPT</a> </p><p>BPEåœ¨<a href="https://arxiv.org/abs/1508.07909">Neural Machine Translation of Rare Words with Subword Units</a>ä¸­è¢«æå‡º</p><ul><li>After pre-tokenization, <strong>a set of unique words has been created</strong> and the <strong>frequency</strong> of each word it occurred in the training data has been determined. Next, BPE creates a <strong>base vocabulary</strong> consisting of all symbols that occur in the set of unique words and learns merge rules to form a new symbol from two symbols of the base vocabulary. <strong>It does so until the vocabulary has attained the desired vocabulary size.</strong> Note that the desired vocabulary size is a hyperparameter to define before training the tokenizer.<ul><li>é¦–å…ˆç»Ÿè®¡è¯é¢‘ â€”&gt; å†æ ¹æ®è¯é¢‘åˆ›å»ºè¯æ±‡è¡¨ , åŒæ—¶åŠ å…¥èåˆè§„åˆ™ â€”&gt; ä¾è¯é¢‘mergeå¾—åˆ°æ–°çš„è¯æ±‡è¡¨ â€”&gt; åœ¨æ–°çš„è¯æ±‡è¡¨åŸºç¡€ä¸Šåœ¨æ­¤merge â€”&gt; åšç§ä½¿å¾—è¯æ±‡è¡¨çš„å¤§å°åœ¨ <strong>desired vocabulary size.</strong> è¿™ä¸ªå¤§å°æ˜¯å¯è°ƒçš„è¶…å‚æ•°</li></ul></li></ul><p>ä¾‹å¦‚, æ•°å­—è¡¨ç¤ºé¢‘ç‡</p><p><code>(&quot;hug&quot;, 10), (&quot;pug&quot;, 5), (&quot;pun&quot;, 12), (&quot;bun&quot;, 4), (&quot;hugs&quot;, 5)</code></p><ol><li><p>é¦–å…ˆæˆ‘ä»¬å¾—åˆ° base vocabulary is <code>[&quot;b&quot;, &quot;g&quot;, &quot;h&quot;, &quot;n&quot;, &quot;p&quot;, &quot;s&quot;, &quot;u&quot;]</code>.</p></li><li><p><code>ug</code>çš„ç»„åˆæœ‰20çš„é¢‘ç‡ç¬¬ä¸€ä¸ªè¢«åŠ è¿›å»</p><ul><li><code>(&quot;h&quot; &quot;ug&quot;, 10), (&quot;p&quot; &quot;ug&quot;, 5), (&quot;p&quot; &quot;u&quot; &quot;n&quot;, 12), (&quot;b&quot; &quot;u&quot; &quot;n&quot;, 4), (&quot;h&quot; &quot;ug&quot; &quot;s&quot;, 5)</code></li></ul></li><li><p>æ¬¡é«˜<code>un</code> â€”&gt; <code>hug</code></p><ul><li><code>(&quot;hug&quot;, 10), (&quot;p&quot; &quot;ug&quot;, 5), (&quot;p&quot; &quot;un&quot;, 12), (&quot;b&quot; &quot;un&quot;, 4), (&quot;hug&quot; &quot;s&quot;, 5)</code></li></ul></li></ol><ul><li>å¦å¤– For instance, the word <code>&quot;bug&quot;</code> would be tokenized to <code>[&quot;b&quot;, &quot;ug&quot;]</code> but <code>&quot;mug&quot;</code> would be tokenized as <code>[&quot;&lt;unk&gt;&quot;, &quot;ug&quot;]</code> since the symbol <code>&quot;m&quot;</code> is not in the base vocabulary.</li></ul><blockquote><p>the <strong>vocabulary size</strong>, <em>i.e.</em> the <strong>base vocabulary size + the number of merges</strong></p><p>For instance <a href="https://huggingface.co/docs/transformers/main/en/model_doc/gpt">GPT</a> has a vocabulary size of 40,478 since they have <strong>478 base characters</strong> and chose to stop training after <strong>40,000 merges.</strong></p><p> <a href="https://huggingface.co/docs/transformers/main/en/model_doc/gpt">GPT-2</a> has a vocabulary size of 50,257, which corresponds to the 256 bytes base tokens, a special end-of-text token and the symbols learned with 50,000 merges.</p></blockquote><hr><h1 id="Unigram"><a href="#Unigram" class="headerlink" title="Unigram"></a>Unigram</h1><p>Unigram introduced in <a href="https://arxiv.org/pdf/1804.10959.pdf">Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates (Kudo, 2018)</a>. </p><p>itâ€™s used in conjunction with <a href="https://huggingface.co/docs/transformers/main/en/tokenizer_summary#sentencepiece">SentencePiece</a>. è·ŸSentencePieceé…åˆä½¿ç”¨</p><ul><li><p>In contrast to BPE or WordPiece, Unigram initializes its <strong>base vocabulary to a large number of symbols</strong> and <strong>progressively trims down</strong> each symbol to obtain a smaller vocabulary.</p></li><li><p>At each training step, the Unigram algorithm <strong>defines a loss</strong> (often defined as the <strong>log-likelihood</strong>) over the training data given the current vocabulary and a unigram language model. Then, for each symbol in the vocabulary, the algorithm computes <strong>how much the overall loss would increase if the symbol was to be removed from the vocabulary</strong>. Unigram then <strong>removes p (with p usually being 10% or 20%) percent of the symbols</strong> whose loss increase is the lowest, <em>i.e.</em> those symbols that least affect the overall loss over the training data. This process is <strong>repeated until the vocabulary has reached the desired size</strong>. The Unigram algorithm <strong>always keeps the base characters</strong> so that any word can be tokenized.</p><ul><li>å–å¯¹æ•°ä¼¼ç„¶æŸå¤±ï¼Œå°†æ‰€æœ‰å­—æ¯åµŒå…¥åŸºç¡€è¯æ±‡è¡¨ï¼Œå¼€å§‹mergeï¼Œè®¡ç®—ç§»é™¤æŸäº›è¯æ‰€é™ä½æˆ–æå‡çš„æŸå¤±ï¼Œé‡å¤ä¸æ–­ç§»é™¤ï¼Œç›´åˆ°ç¬¦åˆç†æƒ³çš„è¯æ±‡è¡¨å¤§å°ã€‚</li></ul></li><li><p>Because Unigram is not based on merge rules (in contrast to BPE and WordPiece), the algorithm has several ways of <strong>tokenizing new text after training</strong></p></li></ul><hr><h1 id="WordPiece"><a href="#WordPiece" class="headerlink" title="WordPiece"></a>WordPiece</h1><p><a href="https://huggingface.co/docs/transformers/main/en/model_doc/bert">BERT</a>, <a href="https://huggingface.co/docs/transformers/main/en/model_doc/distilbert">DistilBERT</a>, and <a href="https://huggingface.co/docs/transformers/main/en/model_doc/electra">Electra</a>. <del>æ»¡æ»¡çš„å«é‡‘é‡</del></p><p>WordPiece was outlined in <a href="https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf">Japanese and Korean Voice Search (Schuster et al., 2012)</a></p><ul><li>WordPiece first initializes the <strong>vocabulary</strong> to include <strong>every character</strong> present in the training data and <strong>progressively learns a given number of merge rules</strong>. In contrast to BPE, WordPiece does <strong>not</strong> choose the most frequent symbol pair, <strong>but the one that maximizes the likelihood of the training data once added to the vocabulary.</strong><ul><li>WordPieceä½¿ç”¨é¢‘ç‡è®°å½•characteråšåŸºç¡€è¯æ±‡è¡¨ï¼Œç„¶åä½¿ç”¨æœ€å¤§ä¼¼ç„¶åšè¯„åˆ¤æ ‡å‡† mergeè¯æ±‡ã€‚æ˜¯BPEå’ŒUnigramçš„ç»“åˆä½¿ç”¨æ¡ˆä¾‹ã€‚</li></ul></li></ul><hr><h1 id="SentencePiece"><a href="#SentencePiece" class="headerlink" title="SentencePiece"></a>SentencePiece</h1><p><a href="https://huggingface.co/docs/transformers/main/en/model_doc/xlm">XLM</a>,  <a href="https://huggingface.co/docs/transformers/main/en/model_doc/albert">ALBERT</a>, <a href="https://huggingface.co/docs/transformers/main/en/model_doc/xlnet">XLNet</a>, <a href="https://huggingface.co/docs/transformers/main/en/model_doc/marian">Marian</a>, and <a href="https://huggingface.co/docs/transformers/main/en/model_doc/t5">T5</a>.</p><p><a href="https://arxiv.org/pdf/1808.06226.pdf">SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing (Kudo et al., 2018)</a> treats the input as a raw input stream, thus including the space in the set of characters to use. It then uses the BPE or unigram algorithm to construct the appropriate vocabulary.</p><ul><li>All transformers models in the library that use SentencePiece use it in combination with unigram<ul><li>å°±æ˜¯ä½¿ç”¨Unicodeç ç¼–ç æ‰€æœ‰å­—ç¬¦</li></ul></li></ul><hr><h1 id="Customizing-Tokenizer"><a href="#Customizing-Tokenizer" class="headerlink" title="Customizing Tokenizer"></a>Customizing Tokenizer</h1><p>å¦‚åŒä¸Šé¢çœ‹åˆ°çš„ä¸åŒæ¨¡å‹é€‰æ‹©äº†ä¸åŒç®—æ³•çš„åˆ†è¯æ–¹å¼ï¼Œæ ¹æ®ä½ çš„éœ€æ±‚é€‰æ‹©ä¸åŒçš„åˆ†è¯å™¨ã€‚</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tokenizers <span class="keyword">import</span> models, Tokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># å½“ç„¶è¿™é‡Œå¯ä»¥ç›´æ¥ ä½¿ç”¨æ¨¡å‹åå­—å¾—åˆ°ä¸€ä¸ªå¯¹åº”æ¨¡å‹çš„åˆ†è¯å™¨ï¼Œé‚£å°±æ˜¯é€šå¸¸ä½¿ç”¨çš„æ–¹æ³•</span></span><br><span class="line">tokenizer = Tokenizer(models.WordPiece()) <span class="comment"># models.BPE() models.Unigram()</span></span><br></pre></td></tr></table></figure><p>ä»¥ä¸Šå³å¯å¼•å‡ºä½ çš„åˆ†è¯å™¨è¿›è¡Œä¸‹é¢çš„å®¢åˆ¶åŒ–ã€‚</p><ul><li><code>Normalization</code>: Executes all the initial transformations over the initial input string. For example when you need to <strong>lowercase some text</strong>, maybe strip it, or even apply one of the common unicode normalization process, you will add a Normalizer.<ul><li>å¯¹ä½ çš„æ–‡æœ¬è¿›è¡Œä¿®ç¼®ï¼Œè½¬å°å†™å­—æ¯ï¼Œåˆ é™¤æŸäº›ç¬¦å·ç­‰</li></ul></li><li><code>Pre-tokenization</code>: In charge of splitting the initial input string. Thatâ€™s the component that decides where and how to pre-segment the origin string. The simplest example would be to simply split on spaces.<ul><li>å®šåˆ¶ä¸€äº›åˆ†è¯è§„åˆ™</li></ul></li><li><code>Model</code>: Handles all the sub-token discovery and generation, this is the part that is trainable and really dependent of your input data.<ul><li>å¾ªç¯å¤„ç†</li></ul></li><li><code>Post-Processing</code>: Provides advanced construction features to be compatible with some of the Transformers-based SoTA models. For instance, for BERT it would wrap the tokenized sentence around [CLS] and [SEP] tokens.</li></ul><hr><ul><li>é¦–å…ˆè®¾å®šä¸€ä¸‹æ•°æ®é›†å’Œæ•°æ®å‘ç”Ÿå™¨</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;wikitext&quot;</span>, name=<span class="string">&quot;wikitext-2-raw-v1&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">1000</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batch_iterator</span>():</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(dataset), batch_size): <span class="comment"># 0åˆ°æ•°æ®é›†çš„é•¿åº¦, æ­¥é•¿ä¸ºbatch_size</span></span><br><span class="line">        <span class="keyword">yield</span> dataset[i : i + batch_size][<span class="string">&quot;text&quot;</span>]</span><br></pre></td></tr></table></figure><ol><li>WordPiece</li></ol><p><strong>pre-processing</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tokenizers <span class="keyword">import</span> decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(models.WordPiece(unl_token=<span class="string">&quot;[UNK]&quot;</span>))</span><br><span class="line"></span><br><span class="line">tokenizer.normalizer = normalizers.<span class="type">Sequence</span>(</span><br><span class="line">    [normalizers.NFD(), normalizers.Lowercase(), normalizers.StripAccents()])</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿™é‡Œè®¾å®šbertçš„å‰å¤„ç†åˆ†è¯å™¨</span></span><br><span class="line">tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()</span><br><span class="line">tokenizer.pre_tokenizer.pre_tokenize_str(<span class="string">&quot;This is an example!&quot;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[(&#x27;This&#x27;, (0, 4)),</span></span><br><span class="line"><span class="string"> (&#x27;is&#x27;, (5, 7)),</span></span><br><span class="line"><span class="string"> (&#x27;an&#x27;, (8, 10)),</span></span><br><span class="line"><span class="string"> (&#x27;example&#x27;, (11, 18)),</span></span><br><span class="line"><span class="string"> (&#x27;!&#x27;, (18, 19))]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>Note that the pre-tokenizer not only split the text into words but keeps the <strong>offsets</strong><ul><li>that is the <strong>beginning and start of each of those words inside the original text.</strong>  è¿™é‡Œæ˜¯ä¸ºQAåšçš„åç§»é‡ç‰¹æ€§</li></ul></li></ul><p><strong>processing</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">special_tokens = [<span class="string">&quot;[UNK]&quot;</span>, <span class="string">&quot;[PAD]&quot;</span>, <span class="string">&quot;[CLS]&quot;</span>, <span class="string">&quot;[SEP]&quot;</span>, <span class="string">&quot;[MASK]&quot;</span>]</span><br><span class="line"><span class="comment"># å¼•å…¥ trainerä¸æ˜¯ç¼–è¾‘å¥½äº†ï¼Œè€Œæ˜¯å€ŸåŠ©å·²ç»å®Œæˆçš„trainerç»“æ„åŠ å…¥special_tokens</span></span><br><span class="line">trainer = trainers.WordPieceTrainer(vocab_size=<span class="number">25000</span>, special_tokens=special_tokens)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿™é‡Œæ˜¯å¼€å§‹è®­ç»ƒäº†</span></span><br><span class="line">tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)</span><br></pre></td></tr></table></figure><ul><li>è¿™é‡Œæˆ‘ä»¬å°±å¾—åˆ°äº†åŸºæœ¬å¤„ç†çš„æ•°æ®ï¼Œä¸‹é¢è¿›è¡Œåå¤„ç†ã€‚</li></ul><p><strong>post-processing</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.post_processor = processors.TemplateProcessing(</span><br><span class="line">    single=<span class="string">f&quot;[CLS]:0 $A:0 [SEP]:0&quot;</span>,</span><br><span class="line">    pair=<span class="string">f&quot;[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1&quot;</span>,</span><br><span class="line">    special_tokens=[</span><br><span class="line">        (<span class="string">&quot;[CLS]&quot;</span>, cls_token_id),</span><br><span class="line">        (<span class="string">&quot;[SEP]&quot;</span>, sep_token_id),</span><br><span class="line">    ],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#æŸ¥çœ‹æ•°æ®</span></span><br><span class="line">encoder = tokenizer.encode(<span class="string">&quot;This is one sentence.&quot;</span>, <span class="string">&quot;With this one we have a pair.&quot;</span>)</span><br><span class="line">encoding.tokens</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&#x27;[CLS]&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;this&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;is&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;one&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;sentence&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;.&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;[SEP]&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;with&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;this&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;one&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;we&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;have&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;a&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;pair&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;.&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;[SEP]&#x27;]</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line"> </span><br><span class="line"> encoding.type_ids</span><br><span class="line"> <span class="comment"># [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>We have to indicate in the template how to organize the special tokens with one sentence (<code>$A</code>) or two sentences (<code>$A</code> and <code>$B</code>). The <code>:</code> followed by a number indicates the token type ID to give to each part.<ul><li>processé˜¶æ®µå¤„ç†å¥½çš„å¥å­è¿›è¡ŒåŒ…è£… å•ä¸ªå¥å­singleå°±æ˜¯00ï¼Œpairå°±æ˜¯01</li></ul></li></ul><p><strong>wrap your tokenizer to transformer object</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> PreTrainedTokenizerFast</span><br><span class="line"></span><br><span class="line">new_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)</span><br><span class="line"><span class="comment"># åŸç¤ºä¾‹æ˜¯ new_tokenizer = BertTokenizerFast(tokenizer_object=tokenizer)</span></span><br></pre></td></tr></table></figure><ol start="2"><li>BPE</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = Tokenizer(models.BPE())</span><br><span class="line"></span><br><span class="line">tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">tokenizer.pre_tokenizer.pre_tokenize_str(<span class="string">&quot;This is an example!&quot;</span>)</span><br><span class="line"></span><br><span class="line">trainer = trainers.BpeTrainer(vocab_size=<span class="number">25000</span>, special_tokens=[<span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>])</span><br><span class="line">tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)</span><br><span class="line"></span><br><span class="line">tokenizer.post_processor = processors.ByteLevel(trim_offsets=<span class="literal">False</span>)</span><br><span class="line">tokenizer.decoder = decoders.ByteLevel()</span><br><span class="line">encode2= tokenizer.encode(<span class="string">&quot;This is one sentence.&quot;</span>, <span class="string">&quot;With this one we have a pair.&quot;</span>)</span><br><span class="line">encode2</span><br><span class="line"><span class="comment"># Encoding(num_tokens=13, </span></span><br><span class="line">attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŒæ ·è¿›è¡Œå°è£…</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> PreTrainedTokenizerFast</span><br><span class="line">new_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)</span><br></pre></td></tr></table></figure><ul><li>ä¸ä¹‹å‰ä¸åŒçš„æ˜¯æˆ‘ä»¬åœ¨ç¬¬ä¸‰è¡Œç›´æ¥ä½¿ç”¨<code>pre_tokenizers.ByteLevel</code>çš„åˆ†è¯å™¨ï¼Œè€Œä¸æ˜¯è°ƒç”¨bertçš„åˆ†è¯å™¨</li><li>åŒæ ·<code>trainers.BpeTrainer</code>æˆ‘ä»¬ä½¿ç”¨çš„ä¹Ÿæ˜¯bpeçš„</li><li><code>trim_offsets=False</code> <em>Whether the post processing step should trim offsets to avoid including whitespaces.</em><ul><li>æ˜¯å¦å°†ç©ºç™½æ ¼ è®¡ç®—åœ¨åç§»é‡é‡Œ</li></ul></li></ul><ol start="3"><li>Unigram</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = Tokenizer(models.Unigram())</span><br><span class="line"></span><br><span class="line">tokenizer.normalizer = normalizers.<span class="type">Sequence</span>(</span><br><span class="line">    [normalizers.Replace(<span class="string">&quot;``&quot;</span>, <span class="string">&#x27;&quot;&#x27;</span>), normalizers.Replace(<span class="string">&quot;&#x27;&#x27;&quot;</span>, <span class="string">&#x27;&quot;&#x27;</span>), normalizers.Lowercase()]</span><br><span class="line">)</span><br><span class="line">tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()</span><br><span class="line"></span><br><span class="line">tokenizer.pre_tokenizer.pre_tokenize_str(<span class="string">&quot;This is an example!&quot;</span>)</span><br><span class="line"><span class="comment"># [(&#x27;â–This&#x27;, (0, 4)), (&#x27;â–is&#x27;, (4, 7)), (&#x27;â–an&#x27;, (7, 10)), (&#x27;â–example!&#x27;, (10, 19))]</span></span><br><span class="line"></span><br><span class="line">trainer = trainers.UnigramTrainer(vocab_size=<span class="number">25000</span>, special_tokens=[<span class="string">&quot;[CLS]&quot;</span>, <span class="string">&quot;[SEP]&quot;</span>, <span class="string">&quot;&lt;unk&gt;&quot;</span>, <span class="string">&quot;&lt;pad&gt;&quot;</span>, <span class="string">&quot;[MASK]&quot;</span>], unk_token=<span class="string">&quot;&lt;unk&gt;&quot;</span>)</span><br><span class="line">tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)</span><br><span class="line"></span><br><span class="line">tokenizer.post_processor = processors.TemplateProcessing(</span><br><span class="line">    single=<span class="string">&quot;[CLS]:0 $A:0 [SEP]:0&quot;</span>,</span><br><span class="line">    pair=<span class="string">&quot;[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1&quot;</span>,</span><br><span class="line">    special_tokens=[</span><br><span class="line">        (<span class="string">&quot;[CLS]&quot;</span>, cls_token_id),</span><br><span class="line">        (<span class="string">&quot;[SEP]&quot;</span>, sep_token_id),</span><br><span class="line">    ],</span><br><span class="line">)</span><br><span class="line">tokenizer.decoder = decoders.Metaspace()</span><br><span class="line"></span><br><span class="line">tokenizer.encode(<span class="string">&quot;This is one sentence.&quot;</span>, <span class="string">&quot;With this one we have a pair.&quot;</span>).tokens</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&#x27;[CLS]&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–this&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–is&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–one&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–sentence&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;.&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;[SEP]&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–with&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–this&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–one&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–we&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–have&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–a&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;â–pair&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;.&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;[SEP]&#x27;]</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å°è£…</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AlbertTokenizerFast</span><br><span class="line">new_tokenizer = AlbertTokenizerFast(tokenizer_object=tokenizer)</span><br></pre></td></tr></table></figure><ul><li><code>pre_tokenizers.Metaspace()</code></li></ul><h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><ul><li>ä»one-hot-ketåˆ°subword åœ¨subwordçš„åŸºç¡€ä¸Š</li><li>ä¼˜åŒ–vocab-sizeå¾—åˆ°BPEå’ŒUnigram</li><li>ç»¼åˆä¸¤è€…æœ‰ç‚¹å¾—åˆ°WordPiece å’Œç‰¹æ”»ä¸æ–¹ä¾¿è¯ä¸­æ—¥éŸ©è¯­çš„SentencePiece</li><li>æœ€åå°±æ˜¯apiä¸Šçš„ä¸€äº›ç»†èŠ‚äº†</li></ul><blockquote><p>å‚è€ƒ</p><p><a href="https://huggingface.co/docs/tokenizers/main/en/api/models#tokenizers.models.BPE">BPE model</a>ã€<a href="https://github.com/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb">notebook</a>ã€<a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb#scrollTo=PjgSkSlYviy8">COLAB</a>ã€<a href="https://huggingface.co/docs/transformers/main/en/tokenizer_summary#bytepair-encoding-bpe">Conceptual Guide</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Universe </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HuggingFace </tag>
            
            <tag> Preprocessing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pandas å·¥ä½œæµ</title>
      <link href="/posts/38639.html"/>
      <url>/posts/38639.html</url>
      
        <content type="html"><![CDATA[<h1 id="å¾…å®Œæˆ"><a href="#å¾…å®Œæˆ" class="headerlink" title="å¾…å®Œæˆ"></a>å¾…å®Œæˆ</h1><ul><li>ç¤ºä¾‹å¼•å…¥</li></ul><h1 id="map-applymap-apply"><a href="#map-applymap-apply" class="headerlink" title="map applymap apply"></a>map applymap apply</h1><ul><li>map applyéƒ½æ˜¯å¯¹seriesæ“ä½œ<ul><li>mapåªèƒ½æ“ä½œ len count åŸºç¡€å‡½æ•°</li><li>apply èƒ½ä¼ å…¥è‡ªå®šä¹‰å‡½æ•° ä»¥axis&#x3D;1æˆ–è€…0åˆ†åˆ«æŒ‰ä¸€ä¸ªseriesæ“ä½œ</li></ul></li><li>applymap å¯¹DataFrameçš„åœ°å›¾ç‚®<ul><li>applymapå¯¹æ‰€æœ‰å…ƒç´ ç»Ÿä¸€æ“ä½œ</li></ul></li></ul><h1 id="str-apply"><a href="#str-apply" class="headerlink" title="str + apply"></a>str + apply</h1><ul><li>pandaså¯¹è±¡å¸¦çš„å¯¹å­—ç¬¦ä¸²å‡½æ•°</li><li>applyè‡ªå®šä¹‰å¤„ç†å­—ç¬¦ä¸²å‡½æ•°</li></ul><h1 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h1><ul><li>sort_values<ul><li>by å“ªä¸€åˆ—</li><li>key + lambda å¯¹å€¼å¤„ç†åçš„æ’åº<ul><li>Apply the key function to the values before sorting. This is similar to the key argument in the builtin <code>sorted()</code> function, with the notable difference that this key function should be <em>vectorized</em>. It should expect a <code>Series</code> and return a Series with the same shape as the input. It will be applied to each column in by independently.</li></ul></li></ul></li></ul><h1 id="groupby-apply"><a href="#groupby-apply" class="headerlink" title="groupby + apply"></a>groupby + apply</h1><ul><li>groupbyåˆ†ç»„ï¼Œè¿”å›ä¸€ä¸ªgroupå¯¹è±¡ é…åˆapplyä½¿ç”¨</li><li>transform åˆ†ç»„å¤„ç†è¿”å›å€¼ï¼Œå¹¶ä¿æŒè¡¨æ ¼ä¸å˜</li></ul><h1 id="æ‹¼æ¥"><a href="#æ‹¼æ¥" class="headerlink" title="æ‹¼æ¥"></a>æ‹¼æ¥</h1><ul><li>merge</li><li>join <ul><li>how&#x3D; inner left right outer</li></ul></li><li>cat</li></ul>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformer From Scratch</title>
      <link href="/posts/13310.html"/>
      <url>/posts/13310.html</url>
      
        <content type="html"><![CDATA[<h1 id="å¾…å®Œæˆ"><a href="#å¾…å®Œæˆ" class="headerlink" title="å¾…å®Œæˆ"></a>å¾…å®Œæˆ</h1><ul><li>å¢åŠ decoder inferenceæ¨¡å—</li><li>å‰è¨€</li></ul><p>æ¶æ„åˆ†å››ä¸ªå¤§å—</p><ul><li>encoder <ul><li>encoder-layer</li></ul></li><li>decoder<ul><li>decoder-layer</li></ul></li></ul><p>ç»†èŠ‚ä¸‰ç§mask</p><ul><li>encoder-mask</li><li>decoder-mask</li><li>cross-mask</li></ul><h1 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h1><p>å¥å­è¡¨ç¤ºä¸º [token1ï¼Œ token2, â€¦tokens]</p><p>å¥å­1 &#x3D; [token_1ï¼Œ token_2, â€¦token_x]</p><p>å¥å­2 &#x3D; [token_1ï¼Œ token_2, â€¦token_y]   x ä¸ä¸€å®šç­‰äº y</p><h2 id="token-æ„é€ "><a href="#token-æ„é€ " class="headerlink" title="token æ„é€ "></a>token æ„é€ </h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">src_vocab_size = <span class="number">16</span></span><br><span class="line">tgt_vocab_size = <span class="number">16</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">max_len = <span class="number">6</span></span><br><span class="line"></span><br><span class="line">src_len = torch.randint(<span class="number">2</span>,<span class="number">7</span>, (batch_size,))</span><br><span class="line">tgt_len = torch.randint(<span class="number">2</span>,<span class="number">7</span>, (batch_size,))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">ç»“æœå¦‚ä¸‹</span></span><br><span class="line"><span class="string">tensor([8, 6, 5, 9]) æ­¤batchçš„ç¬¬ä¸€ä¸ªå¥å­é•¿8ï¼Œç¬¬äºŒä¸ª6</span></span><br><span class="line"><span class="string">tensor([6, 5, 9, 5])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ¥ä¸‹æ¥æˆ‘ä»¬æŠŠä¸å®šé•¿çš„å¥å­padding</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">randint ç”Ÿæˆ(i,)å½¢çŠ¶çš„æ•°æ®</span></span><br><span class="line"><span class="string">padding 0æ¬¡æˆ–è€… max_len - len(i) çš„æ¬¡æ•°</span></span><br><span class="line"><span class="string">unsqueeze å¢åŠ ä¸€ä¸ªç»´åº¦</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">src_seq = [F.pad(torch.randint(<span class="number">1</span>, src_vocab_size, (i,)), (<span class="number">0</span>, max_len-i)).unsqueeze(<span class="number">0</span>) <span class="keyword">for</span> i <span class="keyword">in</span> src_len]</span><br><span class="line">tgt_seq = [F.pad(torch.randint(<span class="number">1</span>, tgt_vocab_size, (i,)), (<span class="number">0</span>, max_len-i)).unsqueeze(<span class="number">0</span>) <span class="keyword">for</span> i <span class="keyword">in</span> tgt_len]</span><br><span class="line"></span><br><span class="line"><span class="comment"># å°†æ•´ä¸ªbatchçš„å¥å­æ•´åˆ</span></span><br><span class="line">src_seq = torch.cat(src_seq)</span><br><span class="line">tgt_seq = torch.cat(tgt_seq)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">å¦‚ä¸‹</span></span><br><span class="line"><span class="string">tensor([[12, 15, 10,  5,  3, 14],</span></span><br><span class="line"><span class="string">        [ 5,  7,  9,  3, 12,  1],</span></span><br><span class="line"><span class="string">        [ 3,  1,  1,  9,  3,  4],</span></span><br><span class="line"><span class="string">        [ 9,  6,  0,  0,  0,  0]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([[11, 12, 11,  3,  5, 15],</span></span><br><span class="line"><span class="string">        [ 7,  9, 11,  0,  0,  0],</span></span><br><span class="line"><span class="string">        [12,  6, 13, 11,  0,  0],</span></span><br><span class="line"><span class="string">        [13,  3,  0,  0,  0,  0]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="è¯å‘é‡ç©ºé—´-æ˜ å°„"><a href="#è¯å‘é‡ç©ºé—´-æ˜ å°„" class="headerlink" title="è¯å‘é‡ç©ºé—´ æ˜ å°„"></a>è¯å‘é‡ç©ºé—´ æ˜ å°„</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">d_model = <span class="number">8</span></span><br><span class="line"></span><br><span class="line">src_embedding = nn.Embedding(src_vocab_size+<span class="number">1</span>, d_model)</span><br><span class="line">tgt_embedding = nn.Embedding(tgt_vocab_size+<span class="number">1</span>, d_model)</span><br><span class="line"></span><br><span class="line">src_embedding.weight <span class="comment"># shapeä¸º(17, 8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">ç¬¬é›¶è¡Œä¸ºpadçš„æ•°æ®</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([[ 2.4606,  1.7139, -0.2859, -0.5058,  0.6229, -0.0470,  2.1517,  0.2996],</span></span><br><span class="line"><span class="string">        [ 0.0077, -0.4292, -0.2397,  1.2366, -0.3061,  0.9196, -1.4222, -1.6431],</span></span><br><span class="line"><span class="string">        [-0.6378, -0.7809, -0.4206,  0.5759, -1.4899,  1.2241,  0.9220, -0.6333],</span></span><br><span class="line"><span class="string">        [ 0.0303, -1.4113,  0.9164, -0.1200,  1.7224, -0.4996, -1.6708, -1.8563],</span></span><br><span class="line"><span class="string">        [ 0.0235,  0.0155, -0.1292, -0.9274, -1.1351, -0.9155,  0.4391, -0.0437],</span></span><br><span class="line"><span class="string">        [ 0.8498,  0.4709, -0.9168, -2.1307,  0.1840,  0.3554, -0.3986,  1.2806],</span></span><br><span class="line"><span class="string">        [ 0.7256,  1.2303, -0.8280, -0.2173,  0.8939,  2.4122,  0.4820, -1.9615],</span></span><br><span class="line"><span class="string">        [-0.8607,  2.4886, -0.8877, -0.8852,  0.3905,  0.9511, -0.3732,  0.4872],</span></span><br><span class="line"><span class="string">        [ 0.4882, -0.4518, -0.1945,  0.2857, -0.6832, -0.4870, -1.7165, -2.0987],</span></span><br><span class="line"><span class="string">        [-0.0512,  0.2692, -1.0003,  0.7896,  0.5004,  0.3594, -1.5923, -1.5618],</span></span><br><span class="line"><span class="string">        [ 0.4012,  0.1614,  1.8939,  0.3862, -0.6733, -1.2442, -0.6540, -1.6772],</span></span><br><span class="line"><span class="string">        [ 1.4784,  2.7430,  0.0159,  0.5944, -1.0025,  1.0843,  0.4580, -0.6515],</span></span><br><span class="line"><span class="string">        [ 0.3905,  0.6118, -0.1256, -0.6725,  1.2366,  0.8272,  0.0838, -1.5124],</span></span><br><span class="line"><span class="string">        [-0.1470,  0.2149, -1.4561,  1.8008,  0.7764, -0.8517, -0.3204, -0.2550],</span></span><br><span class="line"><span class="string">        [-1.1534, -0.6837, -1.7165, -1.7905, -1.5423,  1.8812, -0.1794, -0.2357],</span></span><br><span class="line"><span class="string">        [ 1.3046,  1.5021,  1.4846,  1.0622,  1.4066,  0.7299,  0.7929, -1.0107],</span></span><br><span class="line"><span class="string">        [-0.3920,  0.7482,  1.5976,  1.7429, -0.4683,  0.2286,  0.1320, -0.5826]],</span></span><br><span class="line"><span class="string">       requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">scr_embedding(scr_seq[<span class="number">0</span>]) <span class="comment"># å°†å–å‡ºå¯¹åº”çš„[12, 15, 10,  5,  3, 14]è¡Œ</span></span><br></pre></td></tr></table></figure><h2 id="Key-mask"><a href="#Key-mask" class="headerlink" title="Key_mask"></a>Key_mask</h2><p>ç”±äºåœ¨encoder_layer padçš„ä½ç½®ç»è¿‡softmax ä¹Ÿä¼šåˆ†å¾—æˆ–å¤šæˆ–å°‘æ³¨æ„åŠ›åˆ†æ•°ï¼Œè¿™äº›padä¸æ˜¯æˆ‘ä»¬å¸Œæœ›æ¨¡å‹ä»æ•°æ®ä¸­å­¦åˆ°çš„ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬å¼•å…¥<strong>Key_mask</strong> å¸®åŠ©encoderæ›´å¥½çš„å…³æ³¨åœ¨éœ€è¦å…³æ³¨çš„ä½ç½®ä¸Šã€‚ <strong>ä¹Ÿæ˜¯ç‰¹åˆ«é‡è¦çš„ä¸€ä¸ªç»†èŠ‚</strong>ã€‚</p><ul><li>å‰ç½®</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">max_len = <span class="number">6</span></span><br><span class="line">embed_dim = <span class="number">8</span></span><br><span class="line">vacab_max = <span class="number">5</span></span><br><span class="line">token_ids = [torch.randint(<span class="number">1</span>,<span class="number">6</span>, (<span class="built_in">len</span>,)) <span class="keyword">for</span> <span class="built_in">len</span> <span class="keyword">in</span> torch.randint(<span class="number">1</span>,<span class="number">7</span>, (max_len,))]</span><br><span class="line">token_ids</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[tensor([2, 3, 5, 2, 4]),</span></span><br><span class="line"><span class="string"> tensor([3, 3, 4, 4, 5, 4]),</span></span><br><span class="line"><span class="string"> tensor([4, 5, 3]),</span></span><br><span class="line"><span class="string"> tensor([5, 1, 4]),</span></span><br><span class="line"><span class="string"> tensor([2, 1, 5, 3]),</span></span><br><span class="line"><span class="string"> tensor([1, 3, 3, 1])]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>pad</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">token_pad_ids = [F.pad(x, (<span class="number">0</span>, max_len-x.shape[<span class="number">0</span>])).unsqueeze(<span class="number">0</span>) <span class="keyword">for</span> x <span class="keyword">in</span> token_ids]</span><br><span class="line">token_pad_ids = torch.cat(token_pad_ids)</span><br><span class="line">token_pad_ids</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[2, 3, 5, 2, 4, 0],</span></span><br><span class="line"><span class="string">        [3, 3, 4, 4, 5, 4],</span></span><br><span class="line"><span class="string">        [4, 5, 3, 0, 0, 0],</span></span><br><span class="line"><span class="string">        [5, 1, 4, 0, 0, 0],</span></span><br><span class="line"><span class="string">        [2, 1, 5, 3, 0, 0],</span></span><br><span class="line"><span class="string">        [1, 3, 3, 1, 0, 0]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>å–å¾—embedding</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">src_embedding = nn.Embedding(vacab_max+<span class="number">1</span>, embed_dim)</span><br><span class="line">tgt_embedding = nn.Embedding(vacab_max+<span class="number">1</span>, embed_dim)</span><br><span class="line">src_embedding.weight, tgt_embedding.weight</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(Parameter containing:</span></span><br><span class="line"><span class="string"> tensor([[-1.4019, -0.3245,  0.8569, -1.6555,  1.3478,  0.0979, -1.7458,  1.3138],</span></span><br><span class="line"><span class="string">         [-0.9099, -0.6957,  0.4430,  0.6305,  0.1099,  0.3213,  0.0841,  0.0786],</span></span><br><span class="line"><span class="string">         [-0.1215, -1.4141,  0.8802, -0.3444,  0.3444, -1.4063, -0.5057,  0.1506],</span></span><br><span class="line"><span class="string">         [ 0.9491,  1.7888,  0.3075, -0.6642,  0.3368,  0.3388, -1.2543, -0.8096],</span></span><br><span class="line"><span class="string">         [ 0.7723, -1.2258, -0.4963,  1.4007, -0.8048, -0.1338,  0.0199,  0.4295],</span></span><br><span class="line"><span class="string">         [ 1.3789, -0.9537,  0.3421,  0.0658, -0.7578, -0.7217, -1.3124,  1.6017]],</span></span><br><span class="line"><span class="string">        requires_grad=True),</span></span><br><span class="line"><span class="string"> Parameter containing:</span></span><br><span class="line"><span class="string"> tensor([[ 2.0609,  0.7302,  0.9811,  0.7390,  0.7475,  0.2903,  0.0735,  0.3407],</span></span><br><span class="line"><span class="string">         [ 1.5477, -0.5033,  1.3758, -1.5225,  0.8236,  0.6329, -0.2301,  1.2352],</span></span><br><span class="line"><span class="string">         [-0.2906, -1.8842, -0.9998,  1.6752,  0.7286, -0.4089, -0.0515,  0.5763],</span></span><br><span class="line"><span class="string">         [ 0.2128,  0.7354, -0.4248,  0.7142,  0.4635,  1.1675,  0.7193,  1.3474],</span></span><br><span class="line"><span class="string">         [ 0.3543,  1.2881, -0.8270,  0.6220, -1.6282,  0.1802, -0.9306, -0.2407],</span></span><br><span class="line"><span class="string">         [-1.3339, -0.4192, -0.0800,  0.1614,  0.7026, -0.6851,  0.2386, -0.4954]],</span></span><br><span class="line"><span class="string">        requires_grad=True))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>æŸ¥çœ‹True False ï¼Œè¿™é‡Œæˆ‘ä»¬å»src_ids çš„ç¬¬å››ä¸ªï¼Œå› ä¸ºé›¶æ¯”è¾ƒå¤šï¼Œ(embeddingçš„é›¶è¡Œæ˜¯padçš„è¯å‘é‡)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pad = src_embedding.weight[<span class="number">0</span>]</span><br><span class="line">src_embedding(token_pad_ids[<span class="number">3</span>]) == pad, token_pad_ids[<span class="number">3</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([[False, False, False, False, False, False, False, False],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False, False, False, False],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False, False, False, False],</span></span><br><span class="line"><span class="string">         [ True,  True,  True,  True,  True,  True,  True,  True],</span></span><br><span class="line"><span class="string">         [ True,  True,  True,  True,  True,  True,  True,  True],</span></span><br><span class="line"><span class="string">         [ True,  True,  True,  True,  True,  True,  True,  True]]),</span></span><br><span class="line"><span class="string"> tensor([5, 1, 4, 0, 0, 0]))</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li><strong>ç”±äºencoderçš„è¾“å…¥éƒ½æ˜¯src æ‰€ä»¥Q*K.T çš„ç»´åº¦ä¸ºï¼ˆbs, src_len, src_len)</strong>,  maskå°±ç›´æ¥å¯ä»¥å†™äº†</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = token_pad_ids[<span class="number">3</span>].unsqueeze(-<span class="number">1</span>)</span><br><span class="line">b = token_pad_ids[<span class="number">3</span>].unsqueeze(<span class="number">0</span>)</span><br><span class="line">torch.matmul(a,b), a.shape, b.shape</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([[25,  5, 20,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [ 5,  1,  4,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [20,  4, 16,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [ 0,  0,  0,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [ 0,  0,  0,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [ 0,  0,  0,  0,  0,  0]]),</span></span><br><span class="line"><span class="string"> torch.Size([6, 1]),</span></span><br><span class="line"><span class="string"> torch.Size([1, 6]))</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>ä¸€æ‰¹é‡æŸ¥çœ‹mask</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">mask = torch.matmul(token_pad_ids.unsqueeze(-<span class="number">1</span>),token_pad_ids.unsqueeze(<span class="number">1</span>)) ==<span class="number">0</span></span><br><span class="line">mask</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">åªçœ‹å‰ä¸‰ä¸ª</span></span><br><span class="line"><span class="string">tensor([[[False, False, False, False, False,  True],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False,  True],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False,  True],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False,  True],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False,  True],</span></span><br><span class="line"><span class="string">         [ True,  True,  True,  True,  True,  True]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[False, False, False, False, False, False],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False, False],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False, False],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False, False],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False, False],</span></span><br><span class="line"><span class="string">         [False, False, False, False, False, False]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[False, False, False,  True,  True,  True],</span></span><br><span class="line"><span class="string">         [False, False, False,  True,  True,  True],</span></span><br><span class="line"><span class="string">         [False, False, False,  True,  True,  True],</span></span><br><span class="line"><span class="string">         [ True,  True,  True,  True,  True,  True],</span></span><br><span class="line"><span class="string">         [ True,  True,  True,  True,  True,  True],</span></span><br><span class="line"><span class="string">         [ True,  True,  True,  True,  True,  True]], ã€‚ã€‚ã€‚</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>ä¸Šåˆºåˆ€</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">scores = torch.randn(<span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">mask = torch.matmul(token_pad_ids.unsqueeze(-<span class="number">1</span>),token_pad_ids.unsqueeze(<span class="number">1</span>))</span><br><span class="line">scores= scores.masked_fill(mask==<span class="number">0</span>, -<span class="number">1e9</span>)</span><br><span class="line">scores.softmax(-<span class="number">1</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">ä¾æ—§åªçœ‹å‰ä¸‰ä¸ª</span></span><br><span class="line"><span class="string">tensor([[[0.0356, 0.0985, 0.6987, 0.0902, 0.0770, 0.0000],</span></span><br><span class="line"><span class="string">         [0.4661, 0.0397, 0.3546, 0.0931, 0.0464, 0.0000],</span></span><br><span class="line"><span class="string">         [0.1917, 0.0149, 0.1564, 0.4113, 0.2259, 0.0000],</span></span><br><span class="line"><span class="string">         [0.4269, 0.0352, 0.1605, 0.1334, 0.2441, 0.0000],</span></span><br><span class="line"><span class="string">         [0.0515, 0.4421, 0.0705, 0.2934, 0.1426, 0.0000],</span></span><br><span class="line"><span class="string">         [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[0.0803, 0.0330, 0.3310, 0.0243, 0.3612, 0.1701],</span></span><br><span class="line"><span class="string">         [0.2160, 0.1483, 0.0312, 0.1804, 0.3861, 0.0380],</span></span><br><span class="line"><span class="string">         [0.2151, 0.0807, 0.1072, 0.4335, 0.1200, 0.0435],</span></span><br><span class="line"><span class="string">         [0.0285, 0.2684, 0.1558, 0.2210, 0.1880, 0.1383],</span></span><br><span class="line"><span class="string">         [0.0889, 0.4485, 0.1067, 0.1028, 0.1901, 0.0630],</span></span><br><span class="line"><span class="string">         [0.2885, 0.1682, 0.0935, 0.0179, 0.0289, 0.4031]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[0.2862, 0.3934, 0.3204, 0.0000, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">         [0.2426, 0.2206, 0.5369, 0.0000, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">         [0.1487, 0.2483, 0.6030, 0.0000, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">         [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],</span></span><br><span class="line"><span class="string">         [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],</span></span><br><span class="line"><span class="string">         [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]],ã€‚ã€‚ã€‚</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>åŒæ—¶æˆ‘ä»¬å¯ä»¥çœ‹è§ å…¨éƒ½æ˜¯padè‡ªèº«çš„æ³¨æ„åŠ›åˆ†æ•°æ˜¯å¹³å‡çš„ï¼Œä¹Ÿå°±æ˜¯è·Ÿä¹±çŒœä¸€æ ·ï¼Œæ²¡æœ‰æ„ä¹‰ã€‚</p><h2 id="Position-Embedding"><a href="#Position-Embedding" class="headerlink" title="Position Embedding"></a>Position Embedding</h2><p>æŒ‰å…¬å¼å†™å°±è¡Œ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pe = torch.zeros(max_len, d_model)</span><br><span class="line">pos = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>) <span class="comment"># å½¢çŠ¶ä¸º(max_len, 1)</span></span><br><span class="line">idx = torch.<span class="built_in">pow</span>(<span class="number">10000</span>, torch.arange(<span class="number">0</span>, <span class="number">8</span>, <span class="number">2</span>).unsqueeze(<span class="number">0</span>)/ d_model )  <span class="comment"># å½¢çŠ¶ä¸º (1, 4)</span></span><br><span class="line">pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(pos / idx)<span class="comment"># è§¦å‘å¹¿æ’­ (max_len, 4)</span></span><br><span class="line">pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.sin(pos / idx)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">æ­¤å¤„æ¼”ç¤ºåªåŠ å¥‡æ•°åˆ—çš„æ•ˆæœ</span></span><br><span class="line"><span class="string">tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span></span><br><span class="line"><span class="string">        [ 0.8415,  0.0000,  0.0998,  0.0000,  0.0100,  0.0000,  0.0010,  0.0000],</span></span><br><span class="line"><span class="string">        [ 0.9093,  0.0000,  0.1987,  0.0000,  0.0200,  0.0000,  0.0020,  0.0000],</span></span><br><span class="line"><span class="string">        [ 0.1411,  0.0000,  0.2955,  0.0000,  0.0300,  0.0000,  0.0030,  0.0000],</span></span><br><span class="line"><span class="string">        [-0.7568,  0.0000,  0.3894,  0.0000,  0.0400,  0.0000,  0.0040,  0.0000],</span></span><br><span class="line"><span class="string">        [-0.9589,  0.0000,  0.4794,  0.0000,  0.0500,  0.0000,  0.0050,  0.0000]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="emb-pe"><a href="#emb-pe" class="headerlink" title="emb+pe"></a>emb+pe</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Embeddings</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab, d_model </span>):</span><br><span class="line">        <span class="built_in">super</span>(Embeddings, self).__init__()</span><br><span class="line">        self.emb = nn.Embedding(vocab, d_model)</span><br><span class="line">        self.d_model = d_model</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.emb(x) * math.sqrt(self.d_model) <span class="comment"># å¯¹embeddingçš„å€¼ç¼©æ”¾ åˆ¶positionæ•°å€¼çš„å½±å“</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_len, d_model , dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        </span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len, dtype=torch.<span class="built_in">float</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() * (-math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        </span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term) <span class="comment"># æ‰€æœ‰è¡Œï¼Œåˆ—èµ·å§‹ä½ä¸º1ï¼Œæ­¥é•¿ä¸º2</span></span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        </span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>).transpose(<span class="number">0</span>, <span class="number">1</span>)    <span class="comment"># ä»(batch_size, seq_len) --&gt; (1.)</span></span><br><span class="line"></span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)  <span class="comment"># è®¾ç½®ç¼“å†²åŒºï¼Œè¡¨ç¤ºå‚æ•°ä¸æ›´æ–°</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x + self.pe[:x.size(<span class="number">0</span>), :]</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    x = torch.randint(<span class="number">1</span>,<span class="number">40</span>, (<span class="number">2</span>, <span class="number">28</span>))</span><br><span class="line">    emb = Embeddings(<span class="number">40</span>, <span class="number">784</span>)</span><br><span class="line">    pe = PositionalEncoding(<span class="number">40</span>, <span class="number">784</span>)</span><br><span class="line">    <span class="built_in">print</span>((pe(emb(x))).shape)</span><br></pre></td></tr></table></figure><h1 id="Multi-head-Attention"><a href="#Multi-head-Attention" class="headerlink" title="Multi-head Attention"></a>Multi-head Attention</h1><h2 id="Query-mask-amp-Scaled-Attention"><a href="#Query-mask-amp-Scaled-Attention" class="headerlink" title="Query_mask &amp; Scaled_Attention"></a>Query_mask &amp; Scaled_Attention</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ScaledAttention</span>(<span class="params">query, key, value, d_k, mask=<span class="literal">None</span>, dropout=<span class="literal">None</span></span>):</span><br><span class="line">    scores = torch.matmul(query, key.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(d_k)  <span class="comment"># (batch_size, channel, head, d_k)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        scores = scores.masked_fill(mask == <span class="number">0</span>, -<span class="number">1e9</span>)</span><br><span class="line">    scores = scores.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        scores = dropout(scores)</span><br><span class="line"></span><br><span class="line">    value = torch.matmul(scores, value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> value, scores</span><br></pre></td></tr></table></figure><ul><li>ç¬¬ä¸€æ¬¡matmulï¼š ç»´åº¦å˜åŒ–ä¸º <a href="mailto:&#81;&#64;&#x4b;&#46;&#x54;">&#81;&#64;&#x4b;&#46;&#x54;</a> â€”&gt; (batch_size * n_head, tgt_len, src_len)   <ul><li>ä¸­é—´çš„<code>scores.masked_fill(mask, -1e9)</code> æ ¹æ®ä¸åŒçš„maskåšæ©ç å¡«å……</li></ul></li><li>ç¬¬äºŒæ¬¡matmulï¼š ç»´åº¦å˜åŒ–ä¸º scores@V â€”&gt; (batch_size, tgt_len, embed_dim) ä¸”æœ‰æ³¨æ„åŠ›åˆ†æ•°åˆ†é…æƒé‡<ul><li>è¿™æ ·å°±æ˜¯decoderä¸­çš„ç›®æ ‡åºåˆ—é•¿åº¦</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> clones</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiheadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, n_head, QKV_O_linear = <span class="number">4</span>, drop_rate=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">assert</span> d_model % n_head == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.n_head = n_head</span><br><span class="line"></span><br><span class="line">        self.dropout = nn.Dropout(p=drop_rate)</span><br><span class="line">        self.linear = clones(nn.Linear(d_model, d_model) ,QKV_O_linear)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, Q, K, V, mask=<span class="literal">None</span></span>):</span><br><span class="line">        batch_size, _, emb_dim = Q.shape    <span class="comment"># (batch_size, seq_len, emb_dim)</span></span><br><span class="line">        d_k = emb_dim // self.n_head</span><br><span class="line"></span><br><span class="line">        Q_heads = self.linear[<span class="number">0</span>](Q).view(batch_size, self.n_head, -<span class="number">1</span>, d_k).transpose(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">        K_heads = self.linear[<span class="number">1</span>](K).view(batch_size, self.n_head, -<span class="number">1</span>, d_k).transpose(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">        V_heads = self.linear[<span class="number">2</span>](V).view(batch_size, self.n_head, -<span class="number">1</span>, d_k).transpose(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        V_att, scores_att= ScaledAttention(Q_heads, K_heads, V_heads, d_k,  mask, self.dropout)</span><br><span class="line">        V_att = V_att.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>).contiguous().view(batch_size, -<span class="number">1</span>, self.n_head * d_k)</span><br><span class="line">        V_att = self.linear[<span class="number">3</span>](V_att)</span><br><span class="line">        K_lin = K_heads.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>).contiguous().view(batch_size, -<span class="number">1</span>, self.n_head * d_k)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span>  K_lin, V_att, <span class="comment"># scores_att</span></span><br></pre></td></tr></table></figure><h2 id="å…³äºcontiguous"><a href="#å…³äºcontiguous" class="headerlink" title="å…³äºcontiguous"></a>å…³äºcontiguous</h2><ul><li><p>clonesä¹‹åçš„linearåˆ—è¡¨æœ‰4ä¸ªlayer</p><ul><li><p>zipå‡½æ•° å¯¹ä¸é€šé•¿åº¦çš„å¯¹è±¡ç›´æ¥ä»¥æœ€å°é•¿åº¦è¿›è¡Œæˆªæ–­ï¼Œæ‰€ä»¥returné‚£é‡Œå¯ä»¥ç”¨linearåˆ—è¡¨çš„æœ€åä¸€ä¸ªè¿”å›è¾“å‡º</p></li><li><p>&#96;&#96;&#96;python<br>a &#x3D; list(range(6))  # 0 - 5 å…­ä¸ªæ•°<br>b &#x3D; list(â€˜asdfgâ€™)  # 5ä¸ªå­—æ¯<br>list(zip(a,b))</p><p>â€˜â€™â€™<br>[(0, â€˜aâ€™), (1, â€˜sâ€™), (2, â€˜dâ€™), (3, â€˜fâ€™), (4, â€˜gâ€™)]<br>â€˜â€™â€™</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">+ contiguous()å¯ä»¥å¼€è¾Ÿæ–°çš„å†…å­˜å­˜å‚¨æ•°æ®ï¼Œis_contiguous()å¯ä»¥åˆ¤æ–­æ•°æ®çš„åº•å±‚å†…å­˜æ˜¯å¦è¿ç»­å­˜å–ï¼Œè¿™é‡Œé…åˆviewä½¿ç”¨</span><br><span class="line"></span><br><span class="line">  + ```python</span><br><span class="line">    t = torch.arange(12).reshape(3,4)</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    tensor([[ 0,  1,  2,  3],</span><br><span class="line">            [ 4,  5,  6,  7],</span><br><span class="line">            [ 8,  9, 10, 11]])&#x27;&#x27;&#x27;</span><br><span class="line">    </span><br><span class="line">    t.stride()</span><br><span class="line">    # (4, 1)</span><br><span class="line">    t2 = t.transpose(0,1)</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    tensor([[ 0,  4,  8],</span><br><span class="line">            [ 1,  5,  9],</span><br><span class="line">            [ 2,  6, 10],</span><br><span class="line">            [ 3,  7, 11]])&#x27;&#x27;&#x27;</span><br><span class="line">    </span><br><span class="line">    t2.stride()</span><br><span class="line">    # (1, 4)</span><br><span class="line">    t.data_ptr() == t2.data_ptr() # åº•å±‚æ•°æ®æ˜¯åŒä¸€ä¸ªä¸€ç»´æ•°ç»„</span><br><span class="line">    # True</span><br><span class="line">    t.is_contiguous(),t2.is_contiguous() # tè¿ç»­ï¼Œt2ä¸è¿ç»­</span><br><span class="line">    # (True, False)</span><br></pre></td></tr></table></figure><p>strideï¼ˆd1ï¼Œd2ï¼‰è¡¨ç¤ºè¿™ä¸ªç»´åº¦ä¸Šçš„å•ä½å…ƒç´ ä¹‹é—´çš„å†…å­˜è·ç¦»ã€‚å¦‚åŸæœ¬0-11æ˜¯è¿ç»­çš„ï¼Œä»–ä»¬åœ¨ã€0ã€‘ç»´ä¸Šçš„è·ç¦»æ˜¯4ã€‚</p></li></ul></li><li><p>view(b,  -1,  self.h * self.d_k) è¦æ±‚å…¶å¯¹è±¡åœ¨å†…å­˜ä¸Šæ˜¯è¿ç»­çš„</p><ul><li>å³ä¸Šé¢çš„æ•°ç»„<code>[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]</code>å¦‚æ­¤åœ¨å†…å­˜ä¸Šæ’åˆ—</li><li>å³ä½¿viewä¸æŠ¥é”™ï¼Œç›´æ¥åœ¨t2ä¸Šåšviewè¿”å›çš„ä¹Ÿä¸ä¼šæ˜¯<code>[ 0,  4,  8,  1,  5,  9,  2,  6, 10,  3,  7, 11]</code></li></ul></li></ul><h1 id="ADD-amp-Norm"><a href="#ADD-amp-Norm" class="headerlink" title="ADD &amp; Norm"></a>ADD &amp; Norm</h1><ul><li>å±•ç¤ºä¸€ä¸‹å®ç°æ–¹å¼ï¼Œå…·ä½“åªè°ƒç”¨Pytorchçš„æ¥å£</li></ul><p>layer_norm åšå±‚çº§åˆ«çš„å½’ä¸€åŒ–ï¼Œå¦‚æœè¯´Batch_normæ˜¯åœ¨ <code>[B, C, H, W]</code>çš„channelä¸Šå¾—åˆ°RGBçš„å‡å€¼æ–¹å·®ï¼Œåšå½’ä¸€åŒ–ï¼›</p><p>layer_normå°±æ˜¯åœ¨ <code>[B, C, H, W]</code>çš„batchä¸Šå¾—åˆ°å½’ä¸€åŒ–ï¼Œæ¯”å¦‚æœ‰3ä¸ªæ‰¹æ¬¡ï¼Œå°±åˆ†åˆ«å¾—åˆ°ã€0ã€‘ã€1ã€‘ã€2ã€‘çš„å‡å€¼æ–¹å·®ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LayerNorm</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;æ„é€ ä¸€ä¸ªlayernormæ¨¡å—&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, eps=<span class="number">1e-6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(LayerNorm, self).__init__()</span><br><span class="line">        self.a_2 = nn.Parameter(torch.ones(features))</span><br><span class="line">        self.b_2 = nn.Parameter(torch.zeros(features))</span><br><span class="line">        self.eps = eps</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;Norm&quot;</span></span><br><span class="line">        mean = x.mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        std = x.std(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SublayerConnection</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Add+Norm&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size, dropout</span>):</span><br><span class="line">        <span class="built_in">super</span>(SublayerConnection, self).__init__()</span><br><span class="line">        self.norm = LayerNorm(size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, sublayer</span>):</span><br><span class="line">        <span class="string">&quot;add norm&quot;</span></span><br><span class="line">        <span class="keyword">return</span> x + self.dropout(sublayer(self.norm(x)))</span><br></pre></td></tr></table></figure><h1 id="Encoder-Layer"><a href="#Encoder-Layer" class="headerlink" title="Encoder Layer"></a>Encoder Layer</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> multihead_attention <span class="keyword">import</span> MultiheadAttention </span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> clones</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">encoder_layerçš„æµç¨‹ä¸ºqkvé€å…¥Multihead_Attention</span></span><br><span class="line"><span class="string">å°†å¾—å‡ºçš„kvè¿›è¡Œadd_norm</span></span><br><span class="line"><span class="string">æœ€ç»ˆè¾“é€ç»™decoder</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, n_head, drop_rate=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.mul = MultiheadAttention(d_model, n_head, drop_rate=drop_rate)</span><br><span class="line">        self.norm = nn.LayerNorm(d_model)</span><br><span class="line">        self.ff = nn.Sequential( nn.Linear(d_model, d_model*<span class="number">4</span>),</span><br><span class="line">                                 nn.ReLU(),</span><br><span class="line">                                 nn.Linear(d_model*<span class="number">4</span>, d_model)) </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, Q, K, V, MASK</span>):</span><br><span class="line">        K, V = self.mul(Q, K, V, MASK)</span><br><span class="line">        V_1 = self.norm(V + Q)</span><br><span class="line">        K_1 = self.norm(K + Q)</span><br><span class="line"></span><br><span class="line">        V_2= self.ff(V_1)</span><br><span class="line">        K_2= self.ff(K_1)</span><br><span class="line">        V_2 = self.norm(V_1 + V_2)</span><br><span class="line">        K_2 = self.norm(K_1 + K_2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> K_2, V_2</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">encoderä¸»è¦æ˜¯å®ç°å¤šä¸ªlayerçš„å †å ä¼ è¾“</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, N</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layers = clones(model, N)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, q,k,v, mask</span>):</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            K, V = layer(q,k,v,mask)</span><br><span class="line">        <span class="keyword">return</span> K, V</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    source = torch.randn(<span class="number">4</span>, <span class="number">2</span>, <span class="number">28</span>)</span><br><span class="line">    ecd_layer = EncoderLayer(<span class="number">784</span>, <span class="number">7</span>)</span><br><span class="line">    ecd = Encoder(ecd_layer, <span class="number">2</span>)</span><br><span class="line">    ecd(source)</span><br></pre></td></tr></table></figure><h1 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> multihead_attention <span class="keyword">import</span> MultiheadAttention, clones</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, n_head, drop_rate=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.mmul = MultiheadAttention(d_model, n_head, drop_rate=drop_rate)</span><br><span class="line">        self.norm = nn.LayerNorm(d_model)</span><br><span class="line">        self.ff = nn.Sequential( nn.Linear(d_model, d_model*<span class="number">4</span>),</span><br><span class="line">                                 nn.ReLU(),</span><br><span class="line">                                 nn.Linear(d_model*<span class="number">4</span>, d_model)) </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, q, k, v, dec_mask, cro_mask</span>):</span><br><span class="line"></span><br><span class="line">        _, V = self.mmul(q, q, q, mask=dec_mask)</span><br><span class="line">        Q_1 = self.norm(V + q)</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        è¿™é‡Œå†™V_2_æ˜¯å› ä¸ºè¿˜è¦ä¼ å…¥ä¸‹ä¸€å±‚,</span></span><br><span class="line"><span class="string">        ä¸Šé¢å†™Qæ˜¯å› ä¸º decoderåœ¨ä¸Šä¸€æ­¥åªæä¾›Qä¸ä¸‹ä¸€å±‚çš„å¤šå¤´å±‚è®¡ç®—</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        _, V_2_ = self.mmul(Q_1, k, v, mask=cro_mask)</span><br><span class="line">        V_2 = self.norm(V_2_ + Q_1)</span><br><span class="line"></span><br><span class="line">        V_2= self.ff(V_2)</span><br><span class="line">        V= self.norm(V_2 + V_2_) <span class="comment"># è‡³æ­¤decoderçš„ä¸€è½®è®¡ç®—å®Œæˆ</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> V</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, N</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layers = clones(model, N)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, k, v, dec_mask, cro_mask</span>):</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            V = layer(x, k, v, dec_mask, cro_mask)</span><br><span class="line">        <span class="keyword">return</span> V</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    x = torch.randn(<span class="number">4</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    k = torch.randn(<span class="number">4</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    v = torch.randn(<span class="number">4</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    dcd_layer = DecoderLayer(<span class="number">784</span>, <span class="number">7</span>)</span><br><span class="line">    dcd = Decoder(dcd_layer, <span class="number">2</span>)</span><br><span class="line">    dcd(x, k, v)</span><br></pre></td></tr></table></figure><h1 id="mask"><a href="#mask" class="headerlink" title="mask"></a>mask</h1><p>ç›®çš„æ˜¯æƒ³æ¨¡ä»¿çœŸå®åœºæ™¯ä¸­ï¼Œæ¯æ¬¡ç¿»è¯‘ä¸‹ä¸ªè¯åªèƒ½åœ¨å‰é¢äº§ç”Ÿç­”æ¡ˆçš„åŸºç¡€ä¸Šï¼Œæ‰€ä»¥ä¸ä¼šä¸€æ¬¡äº§ç”Ÿæ‰€æœ‰loss</p><p>ä½¿ç”¨<code>torch.functional.cross_entropy</code>çš„<code>ignore_index</code>å‚æ•°å°†æƒ³è¦maskçš„ä½ç½®å¡«ä¸º-100å³å¯å°†loss maskæ‰</p><blockquote><p>ä½¿ç”¨ignore_indexå‚æ•° è¦é…åˆ reduction &#x3D; â€˜noneâ€™ å‚æ•°</p><p>è¿”å›æ‰€æœ‰æŸå¤±ï¼Œè€Œä¸æ˜¯å¹³å‡æˆ–è€…åŠ å’Œåçš„æŸå¤±</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clones</span>(<span class="params">module, N</span>):</span><br><span class="line">    <span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(N)])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">attn_mask</span>(<span class="params">src_ids=<span class="literal">None</span>, tgt_ids=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># encoderçš„æ©ç  æ­£æ–¹å½¢</span></span><br><span class="line">    <span class="keyword">if</span> tgt_ids == <span class="literal">None</span>:</span><br><span class="line">        mask = torch.matmul(src_ids.unsqueeze(-<span class="number">1</span>), src_ids.unsqueeze(<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> mask</span><br><span class="line"></span><br><span class="line">    <span class="comment"># decoderç¬¬ä¸€å±‚çš„æ©ç ï¼Œè¿”å›çš„æ˜¯ä¸€ä¸ªä¸Šä¸‰è§’ä¸º1çš„çŸ©é˜µ(å¯¹è§’çº¿ä¸Šçš„æ²¡æœ‰æ“ä½œä¸º1)\</span></span><br><span class="line">    <span class="comment"># å› ä¸ºç»Ÿä¸€æ˜¯mask==0 è¿›è¡Œå¡«å……æ‰€ä»¥è¿™é‡Œåä¸€ä¸‹ è¿”å›çš„åœ°æ–¹è®© ä¸Šä¸‰è§’=falseï¼Œ\</span></span><br><span class="line">    <span class="comment"># è¿™æ ·å°±ç­‰äº0 å°†åœ¨self-attentionå¡«å……ï¼Œæ­£æ–¹å½¢</span></span><br><span class="line">    <span class="keyword">elif</span> src_ids == <span class="literal">None</span>:</span><br><span class="line">        mask = torch.triu(torch.ones((tgt_ids.shape[-<span class="number">1</span>], tgt_ids.shape[-<span class="number">1</span>])), diagonal=<span class="number">1</span>).<span class="built_in">type</span>(torch.uint8)</span><br><span class="line">        <span class="keyword">return</span> mask == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># decoderç¬¬äºŒå±‚cro_maskçš„æ©ç ï¼Œkvæ¥è‡ªencoderï¼Œqå’Œkvçš„å½¢çŠ¶å¯èƒ½ä¸åŒï¼Œé•¿æ–¹å½¢</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Q= tgt_ids</span><br><span class="line">        KV = src_ids</span><br><span class="line">        mask = torch.matmul(Q.unsqueeze(-<span class="number">1</span>), KV.unsqueeze(<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> mask</span><br></pre></td></tr></table></figure><h1 id="æ±½è½¦äººå˜å½¢ï¼"><a href="#æ±½è½¦äººå˜å½¢ï¼" class="headerlink" title="æ±½è½¦äººå˜å½¢ï¼"></a>æ±½è½¦äººå˜å½¢ï¼</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> attn_mask</span><br><span class="line"><span class="keyword">from</span> embedding <span class="keyword">import</span> Embeddings, PositionalEncoding</span><br><span class="line"><span class="keyword">from</span> encoder <span class="keyword">import</span> Encoder, EncoderLayer</span><br><span class="line"><span class="keyword">from</span> decoder <span class="keyword">import</span> Decoder, DecoderLayer</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,enc_vocab_size, dec_vocab_size, d_model, n_head, num_layer</span>):</span><br><span class="line">        <span class="built_in">super</span>(Transformer,self).__init__()</span><br><span class="line"></span><br><span class="line">        self.encoder_emb = Embeddings(enc_vocab_size, d_model)</span><br><span class="line">        self.decoder_emb = Embeddings(dec_vocab_size, d_model)</span><br><span class="line">        self.encoder_pos = PositionalEncoding(enc_vocab_size, d_model)</span><br><span class="line">        self.decoder_pos = PositionalEncoding(dec_vocab_size, d_model)</span><br><span class="line"></span><br><span class="line">        self.encoder = Encoder(EncoderLayer(d_model=d_model,n_head= n_head), N=num_layer)</span><br><span class="line">        self.decoder = Decoder(DecoderLayer(d_model=d_model,n_head= n_head), N=num_layer)</span><br><span class="line">        self.answer = nn.Linear(d_model, dec_vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, src_q, tgt_q</span>):</span><br><span class="line">        <span class="comment"># ç”Ÿæˆæ©ç </span></span><br><span class="line">        encoder_mask = attn_mask(src_ids=src_q)</span><br><span class="line">        decoder_mask = attn_mask(tgt_ids=tgt_q)</span><br><span class="line">        cross_mask = attn_mask(src_q, tgt_q)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># encoderéƒ¨åˆ†   ä¸€ç§mask</span></span><br><span class="line">        src_q = self.encoder_emb(src_q) </span><br><span class="line">        src_q = self.encoder_pos(src_q)</span><br><span class="line">        k, v = self.encoder(src_q, src_q, src_q, encoder_mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># decoderéƒ¨åˆ†   è¦ä¼ å…¥ä¸¤ç§mask</span></span><br><span class="line">        tgt_q = self.decoder_emb(tgt_q)</span><br><span class="line">        tgt_q = self.decoder_pos(tgt_q)</span><br><span class="line">        output = self.decoder(tgt_q, k, v, decoder_mask, cross_mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># è½¬æ¢åˆ°tgt_vocab åšä¸ªargmaxè¿›è¡Œè¾“å‡º</span></span><br><span class="line">        output = self.answer(output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    x = torch.randint(<span class="number">1</span>,<span class="number">40</span>, (<span class="number">4</span>, <span class="number">23</span>))</span><br><span class="line">    y = torch.randint(<span class="number">1</span>,<span class="number">40</span>, (<span class="number">4</span>, <span class="number">17</span>))</span><br><span class="line">    trs = Transformer(<span class="number">40</span>, <span class="number">41</span>, <span class="number">784</span>, <span class="number">7</span>, <span class="number">2</span>)</span><br><span class="line">    output = trs(x, y)</span><br><span class="line">    <span class="built_in">print</span>(output.argmax(-<span class="number">1</span>).shape)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><a href="http://nlp.seas.harvard.edu/annotated-transformer/">å‚è€ƒ</a></p>]]></content>
      
      
      <categories>
          
          <category> Dive Into Paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matplotlib æ¦‚è¿°</title>
      <link href="/posts/15638.html"/>
      <url>/posts/15638.html</url>
      
        <content type="html"><![CDATA[<h1 id="å¾…å®Œæˆ"><a href="#å¾…å®Œæˆ" class="headerlink" title="å¾…å®Œæˆ"></a>å¾…å®Œæˆ</h1><p>æœ¬æ–‡ç®€å•æ¦‚è¿°Matplotlibç»˜å›¾åº“ä¸‰ä¸ªä¸»è¦çš„ç±»</p><ul><li>Axes</li><li>Figure</li><li>Artist</li></ul><p>é€šè¿‡ä»¥ä¸Šä¸‰ä¸ªç±»æ¥äº†è§£ä½œå›¾çš„é€»è¾‘ã€‚<a href="https://matplotlib.org/stable/tutorials/index.html">æ¨èå­¦ä¹ å®˜ç½‘çš„ç¤ºä¾‹</a></p><h1 id="Axes"><a href="#Axes" class="headerlink" title="Axes"></a>Axes</h1><p>é¦–å…ˆä»‹ç»Axesï¼Œä»–å¯ä»¥ç†è§£ä¸ºåæ ‡ç³»ï¼Œä»–çš„å­ç±»æ˜¯aixsåæ ‡è½´(è§åçŸ¥æ„å¾ˆå¥½ç†è§£)ã€‚ä¸€ä¸‹æˆ‘ä»¬é€šè¿‡ä¸€ä¸ª<a href="https://matplotlib.org/stable/tutorials/introductory/quick_start.html#sphx-glr-tutorials-introductory-quick-start-py">ç¤ºä¾‹</a>ç†è§£</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplots()  </span><br><span class="line">axs.plot([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><img src="https://matplotlib.org/stable/_images/sphx_glr_quick_start_001.png" style="zoom:67%;" /><p>ä»¥ä¸Šæˆ‘ä»¬å¼•å…¥matplotlibä¸­çš„pyplotåˆ«åä¸ºplt</p><p>é€šè¿‡è°ƒç”¨<code>plt.subplots() </code>è¿”å›ä¸¤ä¸ªå¯¹è±¡ fig( figure)ï¼Œaxs( axes)ã€‚</p><h2 id="Axis"><a href="#Axis" class="headerlink" title="Axis"></a>Axis</h2><p>Axisé¡¾åæ€ä¹‰æ•°è½´ï¼Œå¯ä»¥å®šä¹‰åˆ»åº¦ï¼Œå•ä½ç­‰</p><h1 id="Figure"><a href="#Figure" class="headerlink" title="Figure"></a>Figure</h1><p>æ•´ä½“ç”»å¸ƒ</p><h1 id="Artist"><a href="#Artist" class="headerlink" title="Artist"></a>Artist</h1><p>å›¾ç”»å…ƒç´ , çº¿æ¡çš„å½¢çŠ¶ç­‰</p><h1 id="é¢å‘å¯¹è±¡è¯­æ³•"><a href="#é¢å‘å¯¹è±¡è¯­æ³•" class="headerlink" title="é¢å‘å¯¹è±¡è¯­æ³•"></a>é¢å‘å¯¹è±¡è¯­æ³•</h1><h2 id="axes"><a href="#axes" class="headerlink" title="axes"></a>axes</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.subplot() <span class="comment"># åˆå§‹åŒ–ä¸€ä¸ªaxes</span></span><br><span class="line"></span><br><span class="line">plt.subplots(m, n) <span class="comment"># mè¡Œnåˆ—axes</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig , axes = plt.subplots(<span class="number">2</span>,<span class="number">1</span>, figsize=(<span class="number">6</span>,<span class="number">6</span>))  <span class="comment"># ä¸¤è¡Œä¸€åˆ—ï¼Œ</span></span><br><span class="line"></span><br><span class="line">axes[<span class="number">0</span>].bar(sm1, sm2)  <span class="comment"># æŸ±çŠ¶å›¾</span></span><br><span class="line"></span><br><span class="line">axes[<span class="number">1</span>].plot(sm1, sm2) <span class="comment"># æŠ˜çº¿å›¾</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig , axes = plt.subplots(<span class="number">2</span>,<span class="number">2</span>, figsize=(<span class="number">6</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">axes[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">axes[<span class="number">0</span>, <span class="number">1</span>] <span class="comment"># ä»¥åæ ‡è°ƒç”¨</span></span><br></pre></td></tr></table></figure><h2 id="Figure-1"><a href="#Figure-1" class="headerlink" title="Figure"></a>Figure</h2><p>plt.figure()è¿”å›ä¸€ä¸ªç”»å¸ƒ</p><p>å¯ä»¥è®¾å®šå¾ˆå¤šå‚æ•°</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">figure</span>(<span class="params">num=<span class="literal">None</span>,  <span class="comment"># autoincrement if None, else integer from 1-N</span></span></span><br><span class="line"><span class="params">           figsize=<span class="literal">None</span>,  <span class="comment"># defaults to rc figure.figsize #å¤šå°‘è‹±å¯¸</span></span></span><br><span class="line"><span class="params">           dpi=<span class="literal">None</span>,  <span class="comment"># defaults to rc figure.dpi #æ¸…æ™°åº¦</span></span></span><br><span class="line"><span class="params">           facecolor=<span class="literal">None</span>,  <span class="comment"># defaults to rc figure.facecolor #èƒŒæ™¯è‰²</span></span></span><br><span class="line"><span class="params">           edgecolor=<span class="literal">None</span>,  <span class="comment"># defaults to rc figure.edgecolor # è¾¹ç¼˜è‰²</span></span></span><br><span class="line"><span class="params">           frameon=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">           FigureClass=Figure,</span></span><br><span class="line"><span class="params">           clear=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">           **kwargs</span></span><br><span class="line"><span class="params">           </span>):</span><br></pre></td></tr></table></figure><h1 id="å…¨å±€å‚æ•°"><a href="#å…¨å±€å‚æ•°" class="headerlink" title="å…¨å±€å‚æ•°"></a>å…¨å±€å‚æ•°</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mpl.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = [<span class="string">&#x27;Heiti SC&#x27;</span>] <span class="comment"># å­—ä½“</span></span><br><span class="line"></span><br><span class="line">mpl.rcParams[<span class="string">&#x27;figure.dpi&#x27;</span>] = <span class="number">300</span> <span class="comment"># æ¸…æ™°åº¦</span></span><br><span class="line"></span><br><span class="line">mpl.rcParams.get(<span class="string">&#x27;figure.figsize&#x27;</span>) <span class="comment"># è·å¾—ç”»å¸ƒå°ºå¯¸</span></span><br><span class="line"></span><br><span class="line">para = &#123;<span class="string">&#x27;figure.dpi&#x27;</span>: <span class="number">500</span>, <span class="string">&#x27;figure.figsize&#x27;</span>: [<span class="number">10</span>, <span class="number">10</span>]&#125; </span><br><span class="line"></span><br><span class="line">mpl.rcParams.update(para) <span class="comment"># é€šè¿‡ä¸Šé¢çš„å‚æ•°è¿›è¡Œä¸€æ¬¡æ›´æ–°</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> matplotlib </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å¥æ„ç›¸ä¼¼åº¦ PipeLineæ€»ç»“</title>
      <link href="/posts/10656.html"/>
      <url>/posts/10656.html</url>
      
        <content type="html"><![CDATA[<p><strong>ä¸»è¦è¿›è¡Œè®­ç»ƒæ¡†æ¶ä¼˜åŒ–</strong></p><ul><li>ç«¯åˆ°ç«¯ ML å®æ–½ï¼ˆè®­ç»ƒã€éªŒè¯ã€é¢„æµ‹ã€è¯„ä¼°ï¼‰</li><li>è½»æ¾é€‚åº”æ‚¨è‡ªå·±çš„æ•°æ®é›†</li><li>ä¿ƒè¿›å…¶ä»–åŸºäº BERT çš„æ¨¡å‹ï¼ˆBERTã€ALBERTã€â€¦ï¼‰çš„å¿«é€Ÿå®éªŒ</li><li>ä½¿ç”¨æœ‰é™çš„è®¡ç®—èµ„æºè¿›è¡Œå¿«é€Ÿè®­ç»ƒï¼ˆæ··åˆç²¾åº¦ã€æ¢¯åº¦ç´¯ç§¯â€¦â€¦ï¼‰</li><li>å¤š GPU æ‰§è¡Œ</li><li>åˆ†ç±»å†³ç­–çš„é˜ˆå€¼é€‰æ‹©ï¼ˆä¸ä¸€å®šæ˜¯ 0.5ï¼‰</li><li>å†»ç»“ BERT å±‚ï¼Œåªæ›´æ–°åˆ†ç±»å±‚æƒé‡æˆ–æ›´æ–°æ‰€æœ‰æƒé‡</li><li>ç§å­è®¾ç½®ï¼Œå¯å¤ç°ç»“æœ</li></ul><h1 id="PipeLine"><a href="#PipeLine" class="headerlink" title="PipeLine"></a>PipeLine</h1><h3 id="å¯¼åŒ…"><a href="#å¯¼åŒ…" class="headerlink" title="å¯¼åŒ…"></a>å¯¼åŒ…</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> torch.cuda.amp <span class="keyword">import</span> autocast, GradScaler</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset, load_metric</span><br></pre></td></tr></table></figure><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CustomDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data, maxlen, with_labels=<span class="literal">True</span>, bert_model=<span class="string">&#x27;albert-base-v2&#x27;</span></span>):</span><br><span class="line"></span><br><span class="line">        self.data = data  <span class="comment"># pandas dataframe</span></span><br><span class="line">        <span class="comment">#Initialize the tokenizer</span></span><br><span class="line">        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)  </span><br><span class="line"></span><br><span class="line">        self.maxlen = maxlen</span><br><span class="line">        self.with_labels = with_labels </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment">#æ ¹æ®ç´¢å¼•ç´¢å–DataFrameä¸­å¥å­1ä½™å¥å­2</span></span><br><span class="line">        sent1 = <span class="built_in">str</span>(self.data.loc[index, <span class="string">&#x27;sentence1&#x27;</span>])</span><br><span class="line">        sent2 = <span class="built_in">str</span>(self.data.loc[index, <span class="string">&#x27;sentence2&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># å¯¹å¥å­å¯¹åˆ†è¯ï¼Œå¾—åˆ°input_idsã€attention_maskå’Œtoken_type_ids</span></span><br><span class="line">        encoded_pair = self.tokenizer(sent1, sent2, </span><br><span class="line">                                      padding=<span class="string">&#x27;max_length&#x27;</span>,  <span class="comment"># å¡«å……åˆ°æœ€å¤§é•¿åº¦</span></span><br><span class="line">                                      truncation=<span class="literal">True</span>,  <span class="comment"># æ ¹æ®æœ€å¤§é•¿åº¦è¿›è¡Œæˆªæ–­</span></span><br><span class="line">                                      max_length=self.maxlen,  </span><br><span class="line">                                      return_tensors=<span class="string">&#x27;pt&#x27;</span>)  <span class="comment"># è¿”å›torch.Tensorå¼ é‡</span></span><br><span class="line">        </span><br><span class="line">        token_ids = encoded_pair[<span class="string">&#x27;input_ids&#x27;</span>].squeeze(<span class="number">0</span>)  <span class="comment"># tensor token ids</span></span><br><span class="line">        attn_masks = encoded_pair[<span class="string">&#x27;attention_mask&#x27;</span>].squeeze(<span class="number">0</span>)  <span class="comment"># padded valueså¯¹åº”ä¸º &quot;0&quot; ï¼Œå…¶ä»–tokenä¸º1</span></span><br><span class="line">        token_type_ids = encoded_pair[<span class="string">&#x27;token_type_ids&#x27;</span>].squeeze(<span class="number">0</span>)  <span class="comment">#ç¬¬ä¸€ä¸ªå¥å­çš„å€¼ä¸º0ï¼Œç¬¬äºŒä¸ªå¥å­çš„å€¼ä¸º1 # åªæœ‰ä¸€å¥å…¨ä¸º0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.with_labels:  <span class="comment"># True if the dataset has labels</span></span><br><span class="line">            label = self.data.loc[index, <span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">            <span class="keyword">return</span> token_ids, attn_masks, token_type_ids, label  </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> token_ids, attn_masks, token_type_ids</span><br></pre></td></tr></table></figure><p>å»ºè®®ï¼Œè¿›è¡Œæµ‹è¯•</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(DataLoader(tr_dataset, batch_size=<span class="number">2</span>)))</span><br><span class="line">sample</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tr_model = SentencePairClassifier(freeze_bert=True)</span><br><span class="line">tr_model(sample[0], sample[1], sample[2])</span><br></pre></td></tr></table></figure><p>å°±æ˜¯æ–¹ä¾¿æœ€åçš„ç»´åº¦è½¬æ¢ï¼Œsqueezeã€flattenã€viewï¼›ç”šè‡³å¯ä»¥ç”¨reshapeæ–¹æ³•</p><h3 id="æ¨¡å‹å®šä¹‰"><a href="#æ¨¡å‹å®šä¹‰" class="headerlink" title="æ¨¡å‹å®šä¹‰"></a>æ¨¡å‹å®šä¹‰</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SentencePairClassifier</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, bert_model=<span class="string">&quot;albert-base-v2&quot;</span>, freeze_bert=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SentencePairClassifier, self).__init__()</span><br><span class="line">        <span class="comment">#  åˆå§‹åŒ–é¢„è®­ç»ƒæ¨¡å‹Bert xxx</span></span><br><span class="line">        self.bert_layer = AutoModel.from_pretrained(bert_model)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#  encoder éšè—å±‚å¤§å°</span></span><br><span class="line">        <span class="keyword">if</span> bert_model == <span class="string">&quot;albert-base-v2&quot;</span>:  <span class="comment"># 12M å‚æ•°</span></span><br><span class="line">            hidden_size = <span class="number">768</span></span><br><span class="line">        <span class="keyword">elif</span> bert_model == <span class="string">&quot;albert-large-v2&quot;</span>:  <span class="comment"># 18M å‚æ•°</span></span><br><span class="line">            hidden_size = <span class="number">1024</span></span><br><span class="line">        <span class="keyword">elif</span> bert_model == <span class="string">&quot;albert-xlarge-v2&quot;</span>:  <span class="comment"># 60M å‚æ•°</span></span><br><span class="line">            hidden_size = <span class="number">2048</span></span><br><span class="line">        <span class="keyword">elif</span> bert_model == <span class="string">&quot;albert-xxlarge-v2&quot;</span>:  <span class="comment"># 235M å‚æ•°</span></span><br><span class="line">            hidden_size = <span class="number">4096</span></span><br><span class="line">        <span class="keyword">elif</span> bert_model == <span class="string">&quot;bert-base-uncased&quot;</span>: <span class="comment"># 110M å‚æ•°</span></span><br><span class="line">            hidden_size = <span class="number">768</span></span><br><span class="line">        <span class="keyword">elif</span> bert_model == <span class="string">&quot;roberta-base&quot;</span>: <span class="comment"># </span></span><br><span class="line">            hidden_size = <span class="number">768</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># å›ºå®šBertå±‚ æ›´æ–°åˆ†ç±»è¾“å‡ºå±‚</span></span><br><span class="line">        <span class="keyword">if</span> freeze_bert:</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> self.bert_layer.parameters():</span><br><span class="line">                p.requires_grad = <span class="literal">False</span></span><br><span class="line">                </span><br><span class="line">        self.dropout = nn.Dropout(p=<span class="number">0.1</span>)</span><br><span class="line">        <span class="comment"># åˆ†ç±»è¾“å‡º</span></span><br><span class="line">        self.cls_layer = nn.Linear(hidden_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @autocast()  </span><span class="comment"># æ··åˆç²¾åº¦è®­ç»ƒ</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attn_masks, token_type_ids</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">            -input_ids : Tensor  containing token ids</span></span><br><span class="line"><span class="string">            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values</span></span><br><span class="line"><span class="string">            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># è¾“å…¥ç»™Bertï¼Œè·å–ä¸Šä¸‹æ–‡è¡¨ç¤º</span></span><br><span class="line">        <span class="comment"># cont_reps, pooler_output = self.bert_layer(input_ids, attn_masks, token_type_ids)</span></span><br><span class="line">        outputs = self.bert_layer(input_ids, attn_masks, token_type_ids)</span><br><span class="line">        <span class="comment"># last_hidden_state,pooler_output,all_hidden_states 12å±‚</span></span><br><span class="line">        <span class="comment"># å°†last layer hidden-state of the [CLS] è¾“å…¥åˆ° classifier layer</span></span><br><span class="line">        <span class="comment"># - last_hidden_state çš„å‘é‡å¹³å‡</span></span><br><span class="line">        <span class="comment"># - å–all_hidden_statesæœ€åå››å±‚ï¼Œç„¶ååšå¹³å‡ weighted å¹³å‡</span></span><br><span class="line">        <span class="comment"># - last_hidden_state+lstm</span></span><br><span class="line">        <span class="comment"># è·å–è¾“å‡º</span></span><br><span class="line">        logits = self.cls_layer(self.dropout(outputs[<span class="string">&#x27;pooler_output&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure><h3 id="å›ºå®šéšæœºç§å­"><a href="#å›ºå®šéšæœºç§å­" class="headerlink" title="å›ºå®šéšæœºç§å­"></a>å›ºå®šéšæœºç§å­</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">set_seed</span>(<span class="params">seed</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; å›ºå®šéšæœºç§å­ï¼Œä¿è¯ç»“æœå¤ç°</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed)</span><br></pre></td></tr></table></figure><h3 id="è®­ç»ƒå’Œè¯„ä¼°"><a href="#è®­ç»ƒå’Œè¯„ä¼°" class="headerlink" title="è®­ç»ƒå’Œè¯„ä¼°"></a>è®­ç»ƒå’Œè¯„ä¼°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!mkdir models <span class="comment">#å¯ä»¥åœ¨ä¹‹å‰è¡¥å……ç»å¯¹è·¯å¾„</span></span><br><span class="line">!mkdir results</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_bert</span>(<span class="params">net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate</span>):</span><br><span class="line"></span><br><span class="line">    best_loss = np.Inf</span><br><span class="line">    best_ep = <span class="number">1</span></span><br><span class="line">    nb_iterations = <span class="built_in">len</span>(train_loader)</span><br><span class="line">    print_every = nb_iterations // <span class="number">5</span>  <span class="comment"># æ‰“å°é¢‘ç‡</span></span><br><span class="line">    iters = []</span><br><span class="line">    train_losses = []</span><br><span class="line">    val_losses = []</span><br><span class="line"></span><br><span class="line">    scaler = GradScaler()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line"></span><br><span class="line">        net.train()</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> it, (seq, attn_masks, token_type_ids, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(train_loader)):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># è½¬ä¸ºcudaå¼ é‡</span></span><br><span class="line">            seq, attn_masks, token_type_ids, labels = \</span><br><span class="line">                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># æ··åˆç²¾åº¦åŠ é€Ÿè®­ç»ƒ</span></span><br><span class="line">            <span class="keyword">with</span> autocast():</span><br><span class="line">                <span class="comment"># Obtaining the logits from the model</span></span><br><span class="line">                logits = net(seq, attn_masks, token_type_ids)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Computing loss</span></span><br><span class="line">                loss = criterion(logits.squeeze(-<span class="number">1</span>), labels.<span class="built_in">float</span>())</span><br><span class="line">                loss = loss / iters_to_accumulate  <span class="comment"># Normalize the loss because it is averaged</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Backpropagating the gradients</span></span><br><span class="line">            <span class="comment"># Scales loss.  Calls backward() on scaled loss to create scaled gradients.</span></span><br><span class="line">            scaler.scale(loss).backward()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (it + <span class="number">1</span>) % iters_to_accumulate == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># Optimization step</span></span><br><span class="line">                <span class="comment"># scaler.step() first unscales the gradients of the optimizer&#x27;s assigned params.</span></span><br><span class="line">                <span class="comment"># If these gradients do not contain infs or NaNs, opti.step() is then called,</span></span><br><span class="line">                <span class="comment"># otherwise, opti.step() is skipped.</span></span><br><span class="line">                scaler.step(opti)</span><br><span class="line">                <span class="comment"># Updates the scale for next iteration.</span></span><br><span class="line">                scaler.update()</span><br><span class="line">                <span class="comment"># æ ¹æ®è¿­ä»£æ¬¡æ•°è°ƒæ•´å­¦ä¹ ç‡ã€‚</span></span><br><span class="line">                lr_scheduler.step()</span><br><span class="line">                <span class="comment"># æ¢¯åº¦æ¸…é›¶</span></span><br><span class="line">                opti.zero_grad()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (it + <span class="number">1</span>) % print_every == <span class="number">0</span>:  <span class="comment"># Print training loss information</span></span><br><span class="line">                <span class="built_in">print</span>()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Iteration <span class="subst">&#123;it+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;nb_iterations&#125;</span> of epoch <span class="subst">&#123;ep+<span class="number">1</span>&#125;</span> complete. \</span></span><br><span class="line"><span class="string">                Loss : <span class="subst">&#123;running_loss / print_every&#125;</span> &quot;</span>)</span><br><span class="line"></span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        val_loss = evaluate_loss(net, device, criterion, val_loader)  <span class="comment"># Compute validation loss</span></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;ep+<span class="number">1</span>&#125;</span> complete! Validation Loss : <span class="subst">&#123;val_loss&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> val_loss &lt; best_loss:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Best validation loss improved from &#123;&#125; to &#123;&#125;&quot;</span>.<span class="built_in">format</span>(best_loss, val_loss))</span><br><span class="line">            <span class="built_in">print</span>()</span><br><span class="line">            net_copy = copy.deepcopy(net)  <span class="comment"># # ä¿å­˜æœ€ä¼˜æ¨¡å‹</span></span><br><span class="line">            best_loss = val_loss</span><br><span class="line">            best_ep = ep + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ä¿å­˜æ¨¡å‹</span></span><br><span class="line">    path_to_model=<span class="string">f&#x27;models/<span class="subst">&#123;bert_model&#125;</span>_lr_<span class="subst">&#123;lr&#125;</span>_val_loss_<span class="subst">&#123;<span class="built_in">round</span>(best_loss, <span class="number">5</span>)&#125;</span>_ep_<span class="subst">&#123;best_ep&#125;</span>.pt&#x27;</span></span><br><span class="line">    torch.save(net_copy.state_dict(), path_to_model)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The model has been saved in &#123;&#125;&quot;</span>.<span class="built_in">format</span>(path_to_model))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">del</span> loss</span><br><span class="line">    torch.cuda.empty_cache() <span class="comment"># æ¸…ç©ºæ˜¾å­˜</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_loss</span>(<span class="params">net, device, criterion, dataloader</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    è¯„ä¼°è¾“å‡º</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    mean_loss = <span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> it, (seq, attn_masks, token_type_ids, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(dataloader)):</span><br><span class="line">            seq, attn_masks, token_type_ids, labels = \</span><br><span class="line">                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)</span><br><span class="line">            logits = net(seq, attn_masks, token_type_ids)</span><br><span class="line">            mean_loss += criterion(logits.squeeze(-<span class="number">1</span>), labels.<span class="built_in">float</span>()).item()</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mean_loss / count</span><br></pre></td></tr></table></figure><ol><li><p>æ³¨æ„autocastå’Œç´¯è®¡æ¢¯åº¦ è¿™ä¸¤ç§åŠ é€Ÿè®¡ç®—çš„æ–¹æ³•</p></li><li><p>evaluateçš„æ—¶å€™è¦æ³¨æ„æ•°æ®çš„ç»´åº¦ï¼Œæ ‡ç­¾çš„ç±»å‹</p></li></ol><h3 id="è¶…å‚æ•°-amp-å¼€å§‹è®­ç»ƒ"><a href="#è¶…å‚æ•°-amp-å¼€å§‹è®­ç»ƒ" class="headerlink" title="è¶…å‚æ•° &amp; å¼€å§‹è®­ç»ƒ"></a>è¶…å‚æ•° &amp; å¼€å§‹è®­ç»ƒ</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bert_model = <span class="string">&quot;albert-base-v2&quot;</span>  <span class="comment"># &#x27;albert-base-v2&#x27;, &#x27;albert-large-v2&#x27;</span></span><br><span class="line">freeze_bert = <span class="literal">False</span>  <span class="comment"># æ˜¯å¦å†»ç»“Bert</span></span><br><span class="line">maxlen = <span class="number">128</span>  <span class="comment"># æœ€å¤§é•¿åº¦</span></span><br><span class="line">bs = <span class="number">16</span>  <span class="comment"># batch size</span></span><br><span class="line">iters_to_accumulate = <span class="number">2</span>  <span class="comment"># æ¢¯åº¦ç´¯åŠ </span></span><br><span class="line">lr = <span class="number">2e-5</span>  <span class="comment"># learning rate</span></span><br><span class="line">epochs = <span class="number">2</span>  <span class="comment"># è®­ç»ƒè½®æ•°</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  å›ºå®šéšæœºç§å­ ä¾¿äºå¤ç°</span></span><br><span class="line">set_seed(<span class="number">1</span>) <span class="comment"># 2022 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºè®­ç»ƒé›†ä¸éªŒè¯é›†</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Reading training data...&quot;</span>)</span><br><span class="line">train_set = CustomDataset(df_train, maxlen, bert_model)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Reading validation data...&quot;</span>)</span><br><span class="line">val_set = CustomDataset(df_val, maxlen, bert_model)</span><br><span class="line"><span class="comment"># å¸¸è§è®­ç»ƒé›†ä¸éªŒè¯é›†DataLoader</span></span><br><span class="line">train_loader = DataLoader(train_set, batch_size=bs, num_workers=<span class="number">0</span>)</span><br><span class="line">val_loader = DataLoader(val_set, batch_size=bs, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">net = SentencePairClassifier(bert_model, freeze_bert=freeze_bert)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:  <span class="comment"># if multiple GPUs</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Let&#x27;s use&quot;</span>, torch.cuda.device_count(), <span class="string">&quot;GPUs!&quot;</span>)</span><br><span class="line">    net = nn.DataParallel(net)</span><br><span class="line"></span><br><span class="line">net.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.BCEWithLogitsLoss()</span><br><span class="line">opti = AdamW(net.parameters(), lr=lr, weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">num_warmup_steps = <span class="number">0</span> <span class="comment"># The number of steps for the warmup phase.</span></span><br><span class="line">num_training_steps = epochs * <span class="built_in">len</span>(train_loader)  <span class="comment"># The total number of training steps</span></span><br><span class="line">t_total = (<span class="built_in">len</span>(train_loader) // iters_to_accumulate) * epochs  <span class="comment"># Necessary to take into account Gradient accumulation</span></span><br><span class="line">lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)</span><br><span class="line"></span><br><span class="line">train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)</span><br></pre></td></tr></table></figure><ol><li>æ³¨æ„å¤šgpuè®­ç»ƒ <code>torch.cuda.device_count() &gt; 1</code>, <code>net = nn.DataParallel(net)</code>çš„ä½¿ç”¨</li></ol><h3 id="æµ‹è¯•"><a href="#æµ‹è¯•" class="headerlink" title="æµ‹è¯•"></a>æµ‹è¯•</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_probs_from_logits</span>(<span class="params">logits</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Converts a tensor of logits into an array of probabilities by applying the sigmoid function</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    probs = torch.sigmoid(logits.unsqueeze(-<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> probs.detach().cpu().numpy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_prediction</span>(<span class="params">net, device, dataloader, with_labels=<span class="literal">True</span>, result_file=<span class="string">&quot;results/output.txt&quot;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Predict the probabilities on a dataset with or without labels and print the result in a file</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    w = <span class="built_in">open</span>(result_file, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    probs_all = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">if</span> with_labels:</span><br><span class="line">            <span class="keyword">for</span> seq, attn_masks, token_type_ids, _ <span class="keyword">in</span> tqdm(dataloader):<span class="comment"># è®­ç»ƒé›†ã€éªŒè¯é›†</span></span><br><span class="line">                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)</span><br><span class="line">                logits = net(seq, attn_masks, token_type_ids)</span><br><span class="line">                probs = get_probs_from_logits(logits.squeeze(-<span class="number">1</span>)).squeeze(-<span class="number">1</span>)</span><br><span class="line">                probs_all += probs.tolist()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> seq, attn_masks, token_type_ids <span class="keyword">in</span> tqdm(dataloader): <span class="comment"># æ²¡æœ‰æ ‡ç­¾çš„æµ‹è¯•é›†</span></span><br><span class="line">                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)</span><br><span class="line">                logits = net(seq, attn_masks, token_type_ids)</span><br><span class="line">                probs = get_probs_from_logits(logits.squeeze(-<span class="number">1</span>)).squeeze(-<span class="number">1</span>)</span><br><span class="line">                probs_all += probs.tolist()</span><br><span class="line"></span><br><span class="line">    w.writelines(<span class="built_in">str</span>(prob)+<span class="string">&#x27;\n&#x27;</span> <span class="keyword">for</span> prob <span class="keyword">in</span> probs_all)</span><br><span class="line">    w.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">path_to_model = <span class="string">&#x27;./model&#x27;</span>  </span><br><span class="line"><span class="comment"># path_to_model = &#x27;/content/models/...&#x27;  # You can add here your trained model</span></span><br><span class="line"></span><br><span class="line">path_to_output_file = <span class="string">&#x27;./results&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Reading test data...&quot;</span>)</span><br><span class="line">test_set = CustomDataset(df_test, maxlen, bert_model)</span><br><span class="line">test_loader = DataLoader(test_set, batch_size=bs, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">model = SentencePairClassifier(bert_model)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:  <span class="comment"># if multiple GPUs</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Let&#x27;s use&quot;</span>, torch.cuda.device_count(), <span class="string">&quot;GPUs!&quot;</span>)</span><br><span class="line">    model = nn.DataParallel(model)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Loading the weights of the model...&quot;</span>)</span><br><span class="line">model.load_state_dict(torch.load(path_to_model))</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predicting on test data...&quot;</span>)</span><br><span class="line">test_prediction(net=model, device=device, dataloader=test_loader, with_labels=<span class="literal">True</span>,  <span class="comment"># set the with_labels parameter to False if your want to get predictions on a dataset without labels</span></span><br><span class="line">                result_file=path_to_output_file)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predictions are available in : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(path_to_output_file))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">path_to_output_file = <span class="string">&#x27;results/output.txt&#x27;</span>  <span class="comment"># é¢„æµ‹ç»“æœæ¦‚ç‡æ–‡ä»¶</span></span><br><span class="line"></span><br><span class="line">labels_test = df_test[<span class="string">&#x27;label&#x27;</span>]  <span class="comment"># true labels</span></span><br><span class="line"></span><br><span class="line">probs_test = pd.read_csv(path_to_output_file, header=<span class="literal">None</span>)[<span class="number">0</span>]  <span class="comment"># é¢„æµ‹æ¦‚ç‡</span></span><br><span class="line">threshold = <span class="number">0.6</span>   <span class="comment"># you can adjust this threshold for your own dataset</span></span><br><span class="line">preds_test=(probs_test&gt;=threshold).astype(<span class="string">&#x27;uint8&#x27;</span>) <span class="comment"># predicted labels using the above fixed threshold</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># metric = load_metric(&quot;glue&quot;, &quot;mrpc&quot;)</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¥æ„ç›¸ä¼¼åº¦ </tag>
            
            <tag> Pipeline </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weight &amp; Bias</title>
      <link href="/posts/26087.html"/>
      <url>/posts/26087.html</url>
      
        <content type="html"><![CDATA[<h1 id="å¾…å®Œæˆ"><a href="#å¾…å®Œæˆ" class="headerlink" title="å¾…å®Œæˆ"></a>å¾…å®Œæˆ</h1><ol><li>æºç ç»†èŠ‚æ•´ç†</li></ol><h1 id="torch-inference-mode"><a href="#torch-inference-mode" class="headerlink" title="torch.inference_mode()"></a><code>torch.inference_mode()</code></h1><p>with no_gradientçš„ä¸€ç§åŠ é€Ÿ  <a href="https://pytorch.org/docs/stable/generated/torch.inference_mode.html">å‚è€ƒæ–‡æ¡£</a></p><h1 id="nn-MarginRankingLoss"><a href="#nn-MarginRankingLoss" class="headerlink" title=" nn.MarginRankingLoss()"></a><code> nn.MarginRankingLoss()</code></h1><p><a href="https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html">æ–‡æ¡£</a> margin &#x3D; 0  x1å¤§äºx2 åˆ™å»-yï¼Œviceversa å– y</p><p>*<em>loss(<em>x</em>1,<em>x</em>2,<em>y</em>)&#x3D;max(0,âˆ’</em>y<em>âˆ—(<em>x</em>1âˆ’</em>x<em>2)+margin)</em>*</p><p>è¿™é‡Œæœ€åçš„lossæ˜¯å¹³å‡åçš„</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MarginRankingLoss()</span><br><span class="line">input1 = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">input2 = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>).sign()</span><br><span class="line">output = loss(input1, input2, target)</span><br><span class="line">output.backward()</span><br><span class="line"></span><br><span class="line">```</span><br><span class="line">input1, input2, target, output</span><br><span class="line"></span><br><span class="line">(tensor([ <span class="number">0.0277</span>, -<span class="number">0.3806</span>,  <span class="number">1.0405</span>], requires_grad=<span class="literal">True</span>),</span><br><span class="line"> tensor([-<span class="number">0.9075</span>,  <span class="number">0.3271</span>,  <span class="number">0.1156</span>], requires_grad=<span class="literal">True</span>),</span><br><span class="line"> tensor([ <span class="number">1.</span>, -<span class="number">1.</span>, -<span class="number">1.</span>]),</span><br><span class="line"> tensor(<span class="number">0.3083</span>, grad_fn=&lt;MeanBackward0&gt;))</span><br><span class="line"> </span><br><span class="line">input1 - input2 , (input1 - input2) * (-target)</span><br><span class="line"></span><br><span class="line">(tensor([ <span class="number">0.9352</span>, -<span class="number">0.7077</span>,  <span class="number">0.9249</span>], grad_fn=&lt;SubBackward0&gt;),</span><br><span class="line"> tensor([-<span class="number">0.9352</span>, -<span class="number">0.7077</span>,  <span class="number">0.9249</span>], grad_fn=&lt;MulBackward0&gt;),</span><br><span class="line"> </span><br><span class="line">loss = <span class="number">0.9249</span>/<span class="number">3</span> </span><br><span class="line"></span><br><span class="line">```</span><br></pre></td></tr></table></figure><h1 id="gc-collect"><a href="#gc-collect" class="headerlink" title="gc.collect()"></a><code>gc.collect()</code></h1><p>æ¸…é™¤å†…å­˜</p><h1 id="defaultdict"><a href="#defaultdict" class="headerlink" title="defaultdict"></a><code>defaultdict</code></h1><p>è·å¾—åˆ›å»ºkeyä¸ç»™valueä¹Ÿä¸æŠ¥é”™çš„dict</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from collections import defaultdict</span><br><span class="line"></span><br><span class="line">history = defaultdict(list)</span><br><span class="line"></span><br><span class="line">history[&#x27;Train Loss&#x27;].append(1.1)</span><br></pre></td></tr></table></figure><h1 id="StratifiedKFold"><a href="#StratifiedKFold" class="headerlink" title="StratifiedKFold()"></a><code>StratifiedKFold()</code></h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold, KFold</span><br><span class="line"></span><br><span class="line">skf = StratifiedKFold(n_splits=CONFIG[<span class="string">&#x27;n_fold&#x27;</span>], shuffle=<span class="literal">True</span>, random_state=CONFIG[<span class="string">&#x27;seed&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fold, ( _, val_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(skf.split(X=df, y=df.worker)):</span><br><span class="line">    df.loc[val_ , <span class="string">&quot;kfold&quot;</span>] = <span class="built_in">int</span>(fold)</span><br><span class="line">    </span><br><span class="line">df[<span class="string">&quot;kfold&quot;</span>] = df[<span class="string">&quot;kfold&quot;</span>].astype(<span class="built_in">int</span>)</span><br></pre></td></tr></table></figure><p>ç¬¬äº”è¡Œ å°†Xåˆ†kæŠ˜ï¼Œyæ ‡ç­¾ä¸ºæ ·æœ¬å¯¹åº”indexï¼Œfold åœ¨ 0~5</p><p>å¾—åˆ°df[â€œkfoldâ€] åˆ—åŒ…å« å±äºç¬¬å‡ æŠ˜çš„ validæ•°æ®</p><p>é€šè¿‡ä¸‹é¢çš„å‡½æ•°ç›´æ¥é€‰æ‹©<strong>éæœ¬æŠ˜çš„æ•°æ®ä½œä¸ºtrain</strong>ï¼Œå…¶ä»–çš„å°±æ˜¯valid</p><p><code>df_train = df[df.kfold != fold].reset_index(drop=True) df_valid = df[df.kfold == fold].reset_index(drop=True)</code></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_loaders</span>(<span class="params">fold</span>):</span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    train_dataset = JigsawDataset(df_train, tokenizer=CONFIG[<span class="string">&#x27;tokenizer&#x27;</span>], max_length=CONFIG[<span class="string">&#x27;max_length&#x27;</span>])</span><br><span class="line">    valid_dataset = JigsawDataset(df_valid, tokenizer=CONFIG[<span class="string">&#x27;tokenizer&#x27;</span>], max_length=CONFIG[<span class="string">&#x27;max_length&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(train_dataset, batch_size=CONFIG[<span class="string">&#x27;train_batch_size&#x27;</span>], </span><br><span class="line">                              num_workers=<span class="number">2</span>, shuffle=<span class="literal">True</span>, pin_memory=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line">    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG[<span class="string">&#x27;valid_batch_size&#x27;</span>], </span><br><span class="line">                              num_workers=<span class="number">2</span>, shuffle=<span class="literal">False</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> train_loader, valid_loade</span><br></pre></td></tr></table></figure><h1 id="tqdm"><a href="#tqdm" class="headerlink" title="tqdm"></a><code>tqdm</code></h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bar = tqdm(enumerate(dataloader), total=len(dataloader))</span><br></pre></td></tr></table></figure><p>å•ä¸ªepochä¸‹é¢å¯¹baråšå¦‚ä¸‹è®¾ç½®</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,</span><br><span class="line">                        LR=optimizer.param_groups[0][&#x27;lr&#x27;])  </span><br></pre></td></tr></table></figure><h1 id="Weights-amp-Biases-W-amp-B"><a href="#Weights-amp-Biases-W-amp-B" class="headerlink" title="Weights &amp; Biases (W&amp;B) "></a><code>Weights &amp; Biases (W&amp;B) </code></h1><ul><li><p>hash ä¸€ä¸ªé¡¹ç›®id</p></li><li><p>train valid å®šä¹‰ä¸€ä¸ª 1ä¸ªepoch çš„å‡½æ•° è¿”å› åˆ†åˆ«å…¶ä¸­çš„loss</p></li><li><p>wandb.log({â€œTrain Lossâ€: train_epoch_loss}) ä½¿ç”¨ log æ–¹å¼è®°å½• æŸå¤±å‡½æ•°</p></li><li><pre><code class="py">run = wandb.init(project=&#39;Jigsaw&#39;,                      config=CONFIG,                     job_type=&#39;Train&#39;,                     group=CONFIG[&#39;group&#39;],                     tags=[&#39;roberta-base&#39;, f&#39;&#123;HASH_NAME&#125;&#39;, &#39;margin-loss&#39;],                     name=f&#39;&#123;HASH_NAME&#125;-fold-&#123;fold&#125;&#39;,                     anonymous=&#39;must&#39;)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TRAIN PART</span><br></pre></td></tr></table></figure>run.finish()<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">æ˜¾ç¤ºå¦‚ä¸‹</span><br><span class="line">&#x27;hash--------name&#x27;</span><br><span class="line">Syncing run k5nu8k69390a-fold-0 to Weights &amp; Biases (docs).</span><br><span class="line"></span><br></pre></td></tr></table></figure></code></pre></li></ul><h1 id="æµç¨‹è®­ç»ƒæç‚¼"><a href="#æµç¨‹è®­ç»ƒæç‚¼" class="headerlink" title="æµç¨‹è®­ç»ƒæç‚¼"></a>æµç¨‹è®­ç»ƒæç‚¼</h1><ul><li>for fold in range(0, CONFIG[â€˜n_foldâ€™])</li><li>wandb.init</li><li>prepare_loadersã€fetch_scheduler</li><li>run_training<ul><li>train_one_epochã€valid_one_epoch â€”-&gt; to got model, loss for wandb</li></ul></li></ul><p>ä¸­é—´æºæ‚ W&amp;B çš„æ•°æ®å®æ—¶è½½å…¥åˆ†æå³å¯</p><p>df[â€˜yâ€™].value_counts(normalize&#x3D;True) to got the percentage of each values</p><p><a href="https://www.kaggle.com/code/debarshichanda/pytorch-w-b-jigsaw-starter">åŸæ–‡é“¾æ¥</a></p>]]></content>
      
      
      <categories>
          
          <category> Trick </category>
          
      </categories>
      
      
        <tags>
            
            <tag> wandb </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CV 02 Vit å¶å­å›¾ç‰‡åˆ†ç±»</title>
      <link href="/posts/28702.html"/>
      <url>/posts/28702.html</url>
      
        <content type="html"><![CDATA[<h1 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h1><p>Vitâ€”â€”Vision Transformer</p><p>è¿™é‡Œé€šè¿‡<a href="https://www.kaggle.com/competitions/classify-leaves/data">kaggleçš„å¶å­åˆ†ç±»ä»»åŠ¡</a>æ¥ä½¿ç”¨é¢„è®­ç»ƒ(Pre-train)æ¨¡å‹Vitæ¥æå‡æˆ‘ä»¬çš„ä»»åŠ¡è¡¨ç¤º</p><h1 id="1-è§‚å¯Ÿæ¨¡å‹-amp-å¤„ç†æ•°æ®"><a href="#1-è§‚å¯Ÿæ¨¡å‹-amp-å¤„ç†æ•°æ®" class="headerlink" title="1.è§‚å¯Ÿæ¨¡å‹&amp;å¤„ç†æ•°æ®"></a>1.è§‚å¯Ÿæ¨¡å‹&amp;å¤„ç†æ•°æ®</h1><h2 id="1-1-æ¨¡å‹æ¢ç´¢"><a href="#1-1-æ¨¡å‹æ¢ç´¢" class="headerlink" title="1.1 æ¨¡å‹æ¢ç´¢"></a>1.1 æ¨¡å‹æ¢ç´¢</h2><p>æ— è®ºæ˜¯åŸºäºpythonçš„ç‰¹æ€§(é€‚é…å„ä¸ªé¢†åŸŸçš„åŒ…)ï¼Œè¿˜æ˜¯NLPé‡Œå¤§è¡Œå…¶é“çš„Pre-trainèŒƒå¼ï¼Œæ‹¥æœ‰å¿«é€Ÿäº†è§£ä¸€ä¸ªåŒ…çš„ç‰¹æ€§ä»¥é€‚ç”¨äºæˆ‘ä»¬å·¥ä½œçš„èƒ½åŠ›ï¼Œå°†æå¤§çš„æå‡æˆ‘ä»¬å·¥ä½œçš„æ•ˆç‡å’Œç»“æœã€‚æ‰€ä»¥ä¸‹é¢æˆ‘ä»¬æ¥å¿«é€Ÿä½“éªŒä¸€ä¸‹<a href="https://huggingface.co/google/vit-base-patch16-224">HuggingFaceç»™å‡ºçš„æ¨¡å‹èŒƒä¾‹</a>ï¼Œå¹¶é’ˆå¯¹æˆ‘ä»¬çš„ä»»åŠ¡è¿›è¡Œç›¸åº”çš„æ•°æ®å¤„ç†ã€‚</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> ViTFeatureExtractor, ViTForImageClassification</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://images.cocodataset.org/val2017/000000039769.jpg&#x27;</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(requests.get(url, stream=<span class="literal">True</span>).raw)</span><br><span class="line"></span><br><span class="line">feature_extractor = ViTFeatureExtractor.from_pretrained(<span class="string">&#x27;google/vit-base-patch16-224&#x27;</span>)</span><br><span class="line">model = ViTForImageClassification.from_pretrained(<span class="string">&#x27;google/vit-base-patch16-224&#x27;</span>)</span><br><span class="line"></span><br><span class="line">inputs = feature_extractor(images=image, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">outputs = model(**inputs)</span><br><span class="line">logits = outputs.logits</span><br><span class="line"><span class="comment"># model predicts one of the 1000 ImageNet classes</span></span><br><span class="line">predicted_class_idx = logits.argmax(-<span class="number">1</span>).item()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predicted class:&quot;</span>, model.config.id2label[predicted_class_idx])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„ä»£ç å¯ä»¥è‡ªè¡Œè¿è¡Œ</p><h3 id="1-1-1-ç¤ºä¾‹è§£è¯»"><a href="#1-1-1-ç¤ºä¾‹è§£è¯»" class="headerlink" title="1.1.1 ç¤ºä¾‹è§£è¯»"></a>1.1.1 ç¤ºä¾‹è§£è¯»</h3><ul><li><p>ä¸Šåè¡Œä»£ç : é¦–å…ˆé€šè¿‡requestsåº“æ‹¿åˆ°ä¸€å¼ å›¾ç‰‡å¹¶ç”¨imageç”Ÿæˆå›¾ç‰‡å½¢å¼ï¼Œä¸‹é¢ä¸¤è¡ŒåŠ è½½äº†Vit16çš„ç‰¹å¾æå–å™¨å’ŒHFç‰¹ä¾›çš„å›¾ç‰‡åˆ†ç±»é€‚é…æ¨¡å‹</p></li><li><p>ä¸‹é¢æˆ‘ä»¬çœ‹çœ‹ ç‰¹å¾æå–åçš„è¾“å…¥(inputs)</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inputs è¾“å‡ºå¦‚ä¸‹</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;pixel_values&#x27;: tensor([[[[ 0.1137,  0.1686,  0.1843,  ..., -0.1922, -0.1843, -0.1843],</span></span><br><span class="line"><span class="string">          [ 0.1373,  0.1686,  0.1843,  ..., -0.1922, -0.1922, -0.2078],</span></span><br><span class="line"><span class="string">          [ 0.1137,  0.1529,  0.1608,  ..., -0.2314, -0.2235, -0.2157],</span></span><br><span class="line"><span class="string">          ...,</span></span><br><span class="line"><span class="string">          [ 0.8353,  0.7882,  0.7333,  ...,  0.7020,  0.6471,  0.6157],</span></span><br><span class="line"><span class="string">          [ 0.8275,  0.7961,  0.7725,  ...,  0.5843,  0.4667,  0.3961],</span></span><br><span class="line"><span class="string">          [ 0.8196,  0.7569,  0.7569,  ...,  0.0745, -0.0510, -0.1922]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         [[-0.8039, -0.8118, -0.8118,  ..., -0.8902, -0.8902, -0.8980],</span></span><br><span class="line"><span class="string">          [-0.7882, -0.7882, -0.7882,  ..., -0.8745, -0.8745, -0.8824],</span></span><br><span class="line"><span class="string">          [-0.8118, -0.8039, -0.7882,  ..., -0.8902, -0.8902, -0.8902],</span></span><br><span class="line"><span class="string">          ...,</span></span><br><span class="line"><span class="string">          [-0.2706, -0.3176, -0.3647,  ..., -0.4275, -0.4588, -0.4824],</span></span><br><span class="line"><span class="string">          [-0.2706, -0.2941, -0.3412,  ..., -0.4824, -0.5451, -0.5765],</span></span><br><span class="line"><span class="string">          [-0.2784, -0.3412, -0.3490,  ..., -0.7333, -0.7804, -0.8353]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         [[-0.5451, -0.4667, -0.4824,  ..., -0.7412, -0.6941, -0.7176],</span></span><br><span class="line"><span class="string">          [-0.5529, -0.5137, -0.4902,  ..., -0.7412, -0.7098, -0.7412],</span></span><br><span class="line"><span class="string">          [-0.5216, -0.4824, -0.4667,  ..., -0.7490, -0.7490, -0.7647],</span></span><br><span class="line"><span class="string">          ...,</span></span><br><span class="line"><span class="string">          [ 0.5686,  0.5529,  0.4510,  ...,  0.4431,  0.3882,  0.3255],</span></span><br><span class="line"><span class="string">          [ 0.5451,  0.4902,  0.5137,  ...,  0.3020,  0.2078,  0.1294],</span></span><br><span class="line"><span class="string">          [ 0.5686,  0.5608,  0.5137,  ..., -0.2000, -0.4275, -0.5294]]]])&#125;</span></span><br><span class="line"><span class="string">          &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">inputs[<span class="string">&#x27;pixel_values&#x27;</span>].size()</span><br><span class="line"><span class="comment"># torch.Size([1, 3, 224, 224])</span></span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°æ˜¯ä¸€ä¸ªå­—å…¸ç±»å‹çš„tensoræ•°æ®ï¼Œå…¶ç»´åº¦ä¸º(b, C, W, H)</p><p><strong>å› æ­¤æˆ‘ä»¬å–‚ç»™æ¨¡å‹çš„æ•°æ®ä¹Ÿå¾—æ˜¯å››ç»´çš„ç»“æ„</strong></p></li><li><p>æ¥ä¸‹æ¥çœ‹çœ‹æ¨¡å‹åå‡ºæ¥çš„ç»“æœ</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># outputs è¾“å…¥å¦‚ä¸‹</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">MaskedLMOutput(loss=tensor(0.4776, grad_fn=&lt;DivBackward0&gt;), logits=tensor([[[[-0.0630, -0.0475, -0.1557,  ...,  0.0950,  0.0216, -0.0084],</span></span><br><span class="line"><span class="string">          [-0.1219, -0.0329, -0.0849,  ..., -0.0152, -0.0143, -0.0663],</span></span><br><span class="line"><span class="string">          [-0.1063, -0.0925, -0.0350,  ...,  0.0238, -0.0206, -0.2159],</span></span><br><span class="line"><span class="string">          ...,</span></span><br><span class="line"><span class="string">          [ 0.2204,  0.0593, -0.2771,  ...,  0.0819,  0.0535, -0.1783],</span></span><br><span class="line"><span class="string">          [-0.0302, -0.1537, -0.1370,  ..., -0.1245, -0.1181, -0.0070],</span></span><br><span class="line"><span class="string">          [ 0.0875,  0.0626, -0.0693,  ...,  0.1331,  0.1088, -0.0835]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         [[ 0.1977, -0.2163,  0.0469,  ...,  0.0802, -0.0414,  0.0552],</span></span><br><span class="line"><span class="string">          [ 0.1125, -0.0369,  0.0175,  ...,  0.0598, -0.0843,  0.0774],</span></span><br><span class="line"><span class="string">          [ 0.1559, -0.0994, -0.0055,  ..., -0.0215,  0.2452, -0.0603],</span></span><br><span class="line"><span class="string">          ...,</span></span><br><span class="line"><span class="string">          [ 0.0603,  0.1887,  0.2060,  ...,  0.0415, -0.0383,  0.0990],</span></span><br><span class="line"><span class="string">          [ 0.2106,  0.0992, -0.1562,  ..., -0.1254, -0.0603,  0.0685],</span></span><br><span class="line"><span class="string">          [ 0.0256,  0.1578,  0.0304,  ..., -0.0894,  0.0659,  0.1493]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         [[-0.0348, -0.0362, -0.1617,  ...,  0.0527,  0.1927,  0.1431],</span></span><br><span class="line"><span class="string">          [-0.0447,  0.0137, -0.0798,  ...,  0.1057, -0.0299, -0.0742],</span></span><br><span class="line"><span class="string">          [-0.0725,  0.1473, -0.0118,  ..., -0.1284,  0.0010, -0.0773],</span></span><br><span class="line"><span class="string">          ...,</span></span><br><span class="line"><span class="string">          [-0.0315,  0.1065, -0.1130,  ...,  0.0091, -0.0650,  0.0688],</span></span><br><span class="line"><span class="string">          [ 0.0314,  0.1034, -0.0964,  ...,  0.0144,  0.0532, -0.0415],</span></span><br><span class="line"><span class="string">          [-0.0205,  0.0046, -0.0987,  ...,  0.1317, -0.0065, -0.1617]]]],</span></span><br><span class="line"><span class="string">       grad_fn=&lt;UnsafeViewBackward0&gt;), hidden_states=None, attentions=None) &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°æœ‰lossã€logitsã€hidden_statesã€attentionsï¼Œè€Œæˆ‘ä»¬çš„èŒƒä¾‹åªå–äº†logitsä½œä¸ºç»“æœè¾“å‡ºã€‚è¿™é‡Œå¹¶ä¸æ˜¯è¯´å…¶ä»–çš„éƒ¨åˆ†æ²¡ç”¨ï¼Œæ˜¯åªå–é€‚é…ä¸‹æ¸¸ä»»åŠ¡çš„è¾“å‡ºå³å¯ã€‚<a href="https://arxiv.org/abs/2010.11929">è¯¦æƒ…å¯ç ”ç©¶Vitçš„è®ºæ–‡</a></p></li><li><p>æœ€åé€šè¿‡<code>argmax</code>å‡½æ•°å’Œ<code>model.config.id2label</code>å¾—å‡ºæ ‡ç­¾ç›¸å¯¹åº”çš„æ–‡å­—</p><p>argmaxå°±æ˜¯è¿”å›æœ€å¤§å€¼çš„ä½ç½®ä¸‹æ ‡ã€model.config.id2labelé…ç½®äº†å¯¹åº”æ ‡ç­¾çš„åç§°ï¼Œä¹ŸçŸ¥é“äº†æœ€åçš„classifierå±‚æ˜¯1000ç»´çš„</p></li></ul><h3 id="1-1-2-å°ç»“"><a href="#1-1-2-å°ç»“" class="headerlink" title="1.1.2 å°ç»“"></a>1.1.2 å°ç»“</h3><p>é€šè¿‡ä»¥ä¸Šæ¢ç´¢ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºï¼š</p><ol><li>è¾“å…¥çš„ç»´åº¦ä¸º(batch_size, 3, 224, 224)</li><li>æœ€åçš„classifieréœ€ç”±1000æ”¹æˆæˆ‘ä»¬å¶å­çš„ç±»åˆ«æ•°</li></ol><h2 id="1-2-æ•°æ®å¤„ç†"><a href="#1-2-æ•°æ®å¤„ç†" class="headerlink" title="1.2 æ•°æ®å¤„ç†"></a>1.2 æ•°æ®å¤„ç†</h2><p>æ¥ä¸‹æ¥æˆ‘ä»¬å°†æ¢ç´¢æ•°æ®çš„ç‰¹æ€§ï¼Œå¹¶ä¿®æ”¹ä»¥é€‚åº”æˆ‘ä»¬çš„æ¨¡å‹</p><h3 id="1-2-1-EDA"><a href="#1-2-1-EDA" class="headerlink" title="1.2.1 EDA"></a>1.2.1 EDA</h3><p>å³Exploratory Data Analysis</p><p>é¦–å…ˆå¯¼å…¥æ‰€éœ€åŒ…</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¯¼å…¥å„ç§åŒ…</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fastprogress.fastprogress <span class="keyword">import</span> master_bar, progress_bar</span><br><span class="line"><span class="keyword">from</span> torch.cuda.amp <span class="keyword">import</span> autocast</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader, TensorDataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> CosineAnnealingLR</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (AdamW, get_scheduler)</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> ViTFeatureExtractor, ViTForImageClassification</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>æŸ¥çœ‹åˆå§‹æ•°æ®</p><p><code>train_df = pd.read_csv(&#39;/kaggle/input/classify-leaves/train.csv&#39;)</code></p><img src="../../article_img/leaves classifier df 01.png" style="zoom:80%;" /><p>ä½¿ç”¨ä¸‹é¢ä»£ç ç»™åˆ†ç±»é…ä¸Šåºå·</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">num_map</span>(<span class="params">file_path</span>):</span><br><span class="line">    data_df = pd.read_csv(<span class="string">&#x27;/kaggle/input/classify-leaves/train.csv&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    categories = data_df.label.unique().tolist()</span><br><span class="line">    categories_zip = <span class="built_in">list</span>(<span class="built_in">zip</span>( <span class="built_in">range</span>(<span class="built_in">len</span>(categories)) , categories))</span><br><span class="line">    categories_dict = &#123;v:k <span class="keyword">for</span> k, v <span class="keyword">in</span> categories_zip&#125;</span><br><span class="line">    </span><br><span class="line">    data_df[<span class="string">&#x27;num_label&#x27;</span>] = data_df.label.<span class="built_in">map</span>(categories_dict)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> data_df</span><br><span class="line">show_df = num_map(<span class="string">&#x27;/kaggle/input/classify-leaves/train.csv&#x27;</span>)</span><br><span class="line">show_df.to_csv(<span class="string">&#x27;train_valid_dataset.csv&#x27;</span>)</span><br></pre></td></tr></table></figure><img src="../../article_img/leaves classifier df 02.png" style="zoom:80%;" /><h3 id="1-2-2-å›¾ç‰‡æ•°æ®æŸ¥çœ‹"><a href="#1-2-2-å›¾ç‰‡æ•°æ®æŸ¥çœ‹" class="headerlink" title="1.2.2 å›¾ç‰‡æ•°æ®æŸ¥çœ‹"></a>1.2.2 å›¾ç‰‡æ•°æ®æŸ¥çœ‹</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">&#x27;/kaggle/input/classify-leaves/&#x27;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(path+train_df.image[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.figure(&quot;Image&quot;) # å›¾åƒçª—å£åç§°</span></span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>) <span class="comment"># å…³æ‰åæ ‡è½´ä¸º off</span></span><br><span class="line">plt.title(<span class="string">&#x27;image&#x27;</span>) <span class="comment"># å›¾åƒé¢˜ç›®</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="../../article_img/leaves classifier df 03 .png" style="zoom:80%;" /><p>è¿™é‡Œæˆ‘ä»¬åšä¸€ä¸‹ç»´åº¦è½¬æ¢ å³ [0, 1, 2]  æ¢æˆ [2, 1, 0], å¹¶åªå–æŸä¸€ä¸ªé€šé“ çœ‹çœ‹</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># np.asarray(img).shape</span></span><br><span class="line"><span class="comment"># å¯ä»¥çœ‹åˆ°å›¾ç‰‡åäº†ï¼Œæ­£ç¡®çš„é¡ºåºæ˜¯.transpose([2, 0, 1])</span></span><br><span class="line">img_trans = np.asarray(img).transpose([<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">plt.imshow(img_trans[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="../../article_img/leaves classifier df 04 .png" style="zoom:80%;" /><h1 id="2-Preprocessing"><a href="#2-Preprocessing" class="headerlink" title="2.Preprocessing"></a>2.Preprocessing</h1><p>æ¥ä¸‹æ¥æˆ‘ä»¬åˆ†åˆ«è¦åš æ•°æ®å¢å¼ºã€æ•°æ®ç±»å®šä¹‰ã€æ•°æ®åŠ è½½å™¨æµ‹è¯•</p><h3 id="2-1-1-å…ˆæ¥ç®—ä¸ªå¹³å‡å€¼æ ‡å‡†å·®"><a href="#2-1-1-å…ˆæ¥ç®—ä¸ªå¹³å‡å€¼æ ‡å‡†å·®" class="headerlink" title="2.1.1 å…ˆæ¥ç®—ä¸ªå¹³å‡å€¼æ ‡å‡†å·®"></a>2.1.1 å…ˆæ¥ç®—ä¸ªå¹³å‡å€¼æ ‡å‡†å·®</h3><p>è¿™é‡Œç®—çš„meanè·Ÿstdæ˜¯ä¸ºäº†Normalizeæˆ‘ä»¬çš„æ•°æ®ä½¿è®­ç»ƒæ›´ç¨³å®š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_image_list</span>(<span class="params">img_dir, isclasses=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;å°†å›¾åƒçš„åç§°åˆ—è¡¨</span></span><br><span class="line"><span class="string">    args: img_dir:å­˜æ”¾å›¾ç‰‡çš„ç›®å½•</span></span><br><span class="line"><span class="string">          isclasses:å›¾ç‰‡æ˜¯å¦æŒ‰ç±»åˆ«å­˜æ”¾æ ‡å¿—</span></span><br><span class="line"><span class="string">    return: å›¾ç‰‡æ–‡ä»¶åç§°åˆ—è¡¨</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    img_list = []</span><br><span class="line">    <span class="comment"># è·¯å¾„ä¸‹å›¾åƒæ˜¯å¦æŒ‰ç±»åˆ«åˆ†ç±»å­˜æ”¾</span></span><br><span class="line">    <span class="keyword">if</span> isclasses:</span><br><span class="line">        img_file = os.listdir(img_dir)</span><br><span class="line">        <span class="keyword">for</span> class_name <span class="keyword">in</span> img_file:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(os.path.join(img_dir, class_name)):     </span><br><span class="line">                class_img_list = os.listdir(os.path.join(img_dir, class_name))</span><br><span class="line">                img_list.extend(class_img_list)         </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        img_list = os.listdir(img_dir)</span><br><span class="line">    <span class="built_in">print</span>(img_list)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;image numbers: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(img_list)))</span><br><span class="line">    <span class="keyword">return</span> img_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_image_pixel_mean</span>(<span class="params">img_dir, img_list, img_size</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;æ±‚æ•°æ®é›†å›¾åƒçš„Rã€Gã€Bå‡å€¼</span></span><br><span class="line"><span class="string">    args: img_dir:</span></span><br><span class="line"><span class="string">          img_list:</span></span><br><span class="line"><span class="string">          img_size:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    R_sum = <span class="number">0</span></span><br><span class="line">    G_sum = <span class="number">0</span></span><br><span class="line">    B_sum = <span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="comment"># å¾ªç¯è¯»å–æ‰€æœ‰å›¾ç‰‡</span></span><br><span class="line">    <span class="keyword">for</span> img_name <span class="keyword">in</span> img_list:</span><br><span class="line">        img_path = os.path.join(img_dir, img_name)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(img_path):</span><br><span class="line">            image = cv2.imread(img_path)</span><br><span class="line">            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)</span><br><span class="line">            image = cv2.resize(image, (img_size, img_size))      <span class="comment"># &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line">            R_sum += image[:, :, <span class="number">0</span>].mean()</span><br><span class="line">            G_sum += image[:, :, <span class="number">1</span>].mean()</span><br><span class="line">            B_sum += image[:, :, <span class="number">2</span>].mean()</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    R_mean = R_sum / count</span><br><span class="line">    G_mean = G_sum / count</span><br><span class="line">    B_mean = B_sum / count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;R_mean:&#123;&#125;, G_mean:&#123;&#125;, B_mean:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(R_mean,G_mean,B_mean))</span><br><span class="line">    RGB_mean = [R_mean, G_mean, B_mean]</span><br><span class="line">    <span class="keyword">return</span> RGB_mean</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_image_pixel_std</span>(<span class="params">img_dir, img_mean, img_list, img_size</span>):</span><br><span class="line">    R_squared_mean = <span class="number">0</span></span><br><span class="line">    G_squared_mean = <span class="number">0</span></span><br><span class="line">    B_squared_mean = <span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    image_mean = np.array(img_mean)</span><br><span class="line">    <span class="comment"># å¾ªç¯è¯»å–æ‰€æœ‰å›¾ç‰‡</span></span><br><span class="line">    <span class="keyword">for</span> img_name <span class="keyword">in</span> img_list:</span><br><span class="line">        img_path = os.path.join(img_dir, img_name)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(img_path):</span><br><span class="line">            image = cv2.imread(img_path)    <span class="comment"># è¯»å–å›¾ç‰‡</span></span><br><span class="line">            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)</span><br><span class="line">            image = cv2.resize(image, (img_size, img_size))      <span class="comment"># &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line">            image = image - image_mean    <span class="comment"># é›¶å‡å€¼</span></span><br><span class="line">            <span class="comment"># æ±‚å•å¼ å›¾ç‰‡çš„æ–¹å·®</span></span><br><span class="line">            R_squared_mean += np.mean(np.square(image[:, :, <span class="number">0</span>]).flatten())</span><br><span class="line">            G_squared_mean += np.mean(np.square(image[:, :, <span class="number">1</span>]).flatten())</span><br><span class="line">            B_squared_mean += np.mean(np.square(image[:, :, <span class="number">2</span>]).flatten())</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    R_std = math.sqrt(R_squared_mean / count)</span><br><span class="line">    G_std = math.sqrt(G_squared_mean / count)</span><br><span class="line">    B_std = math.sqrt(B_squared_mean / count)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;R_std:&#123;&#125;, G_std:&#123;&#125;, B_std:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(R_std, G_std, B_std))</span><br><span class="line">    RGB_std = [R_std, G_std, B_std]</span><br><span class="line">    <span class="keyword">return</span> RGB_std</span><br><span class="line"></span><br><span class="line">```</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    image_dir = <span class="string">&#x27;/å›¾ç‰‡æ–‡ä»¶è·¯å¾„&#x27;</span></span><br><span class="line">    image_list = get_image_list(image_dir, isclasses=<span class="literal">False</span>)</span><br><span class="line">    RGB_mean = get_image_pixel_mean(image_dir, image_list, img_size=<span class="number">224</span>)</span><br><span class="line">    get_image_pixel_std(image_dir, RGB_mean, image_list, img_size=<span class="number">224</span>)```</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-1-2-æ•°æ®å¢å¼º"><a href="#2-1-2-æ•°æ®å¢å¼º" class="headerlink" title="2.1.2 æ•°æ®å¢å¼º"></a>2.1.2 æ•°æ®å¢å¼º</h3><p><code>transforms.Compose</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3.0 / 4.0, 4.0 / 3.0)),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])</span><br></pre></td></tr></table></figure><p><a href="https://pytorch.org/vision/stable/transforms.html#compositions-of-transforms">è§å®˜ç½‘</a></p><h3 id="2-2-1-Dataset"><a href="#2-2-1-Dataset" class="headerlink" title="2.2.1 Dataset"></a>2.2.1 Dataset</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">imgdataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, os_path, file_path, transform </span>):</span><br><span class="line">        self.os_path = os_path</span><br><span class="line">        self.data = pd.read_csv(file_path)</span><br><span class="line">        self.transform = transform</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        img = Image.<span class="built_in">open</span>(self.os_path + self.data.image[idx])</span><br><span class="line">        label = self.data.num_label[idx]</span><br><span class="line">        </span><br><span class="line">        self.transform != <span class="literal">None</span>:</span><br><span class="line">        img = self.transform(img)</span><br><span class="line">        label = torch.tensor(label)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.data.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><h3 id="2-2-2-æ¨¡å‹æµ‹è¯•"><a href="#2-2-2-æ¨¡å‹æµ‹è¯•" class="headerlink" title="2.2.2 æ¨¡å‹æµ‹è¯•"></a>2.2.2 æ¨¡å‹æµ‹è¯•</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = imgdataset(<span class="string">&#x27;/kaggle/input/classify-leaves/&#x27;</span>, </span><br><span class="line">                           <span class="string">&#x27;/kaggle/working/processed_train.csv&#x27;</span>,</span><br><span class="line">                          transform = transform)</span><br><span class="line">train_dataloader = DataLoader(train_dataset, batch_size = <span class="number">1</span>, shuffle = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">samples = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader))</span><br><span class="line">samples[<span class="number">0</span>], samples[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">``` è¾“å…¥å¦‚ä¸‹</span><br><span class="line">(tensor([[[[<span class="number">0.7608</span>, <span class="number">0.7608</span>, <span class="number">0.7608</span>,  ..., <span class="number">0.8353</span>, <span class="number">0.8353</span>, <span class="number">0.8392</span>],</span><br><span class="line">           [<span class="number">0.7608</span>, <span class="number">0.7608</span>, <span class="number">0.7608</span>,  ..., <span class="number">0.8392</span>, <span class="number">0.8353</span>, <span class="number">0.8431</span>],</span><br><span class="line">           [<span class="number">0.7608</span>, <span class="number">0.7608</span>, <span class="number">0.7608</span>,  ..., <span class="number">0.8392</span>, <span class="number">0.8392</span>, <span class="number">0.8431</span>],</span><br><span class="line">           ...,</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>],</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>],</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>]],</span><br><span class="line"> </span><br><span class="line">          [[<span class="number">0.8118</span>, <span class="number">0.8118</span>, <span class="number">0.8118</span>,  ..., <span class="number">0.8588</span>, <span class="number">0.8588</span>, <span class="number">0.8627</span>],</span><br><span class="line">           [<span class="number">0.8118</span>, <span class="number">0.8118</span>, <span class="number">0.8118</span>,  ..., <span class="number">0.8627</span>, <span class="number">0.8588</span>, <span class="number">0.8667</span>],</span><br><span class="line">           [<span class="number">0.8118</span>, <span class="number">0.8118</span>, <span class="number">0.8118</span>,  ..., <span class="number">0.8627</span>, <span class="number">0.8627</span>, <span class="number">0.8667</span>],</span><br><span class="line">           ...,</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>],</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>],</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>]],</span><br><span class="line"> </span><br><span class="line">          [[<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.8510</span>, <span class="number">0.8510</span>, <span class="number">0.8549</span>],</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.8549</span>, <span class="number">0.8510</span>, <span class="number">0.8588</span>],</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.8549</span>, <span class="number">0.8549</span>, <span class="number">0.8588</span>],</span><br><span class="line">           ...,</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>],</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>],</span><br><span class="line">           [<span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>,  ..., <span class="number">0.7725</span>, <span class="number">0.7725</span>, <span class="number">0.7725</span>]]]]),</span><br><span class="line"> tensor([<span class="number">55</span>])) ```</span><br></pre></td></tr></table></figure><p>è¿™é‡Œå¯ä»¥ç›´æ¥çœ‹åˆ°transformsçš„ToTensoræ–¹å¼å·²ç»å°†æˆ‘ä»¬çš„æ•°æ®ä¿®æ”¹ä¹˜(C, W, H)å½¢å¼ï¼ˆåŸæ¥çš„æ˜¯ Cåœ¨æœ€åï¼‰</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_ot = model(samples[<span class="number">0</span>])</span><br><span class="line">test_pred = test_ot.logits.argmax(-<span class="number">1</span>)</span><br><span class="line">test_pred, test_ot.logits</span><br></pre></td></tr></table></figure><h1 id="3-è®­ç»ƒå¾ªç¯"><a href="#3-è®­ç»ƒå¾ªç¯" class="headerlink" title="3. è®­ç»ƒå¾ªç¯"></a>3. è®­ç»ƒå¾ªç¯</h1><h2 id="3-1-plot"><a href="#3-1-plot" class="headerlink" title="3.1 plot"></a>3.1 plot</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_loss_update</span>(<span class="params">epoch, mb, train_loss, valid_loss</span>):</span><br><span class="line"></span><br><span class="line">    x = <span class="built_in">range</span>(<span class="number">1</span>, epoch+<span class="number">1</span>)</span><br><span class="line">    y = np.concatenate((train_loss, valid_loss))</span><br><span class="line">    graphs = [[x,train_loss], [x,valid_loss]]</span><br><span class="line">    x_margin = <span class="number">0.2</span></span><br><span class="line">    y_margin = <span class="number">0.05</span></span><br><span class="line">    x_bounds = [<span class="number">1</span>-x_margin, epochs+x_margin]</span><br><span class="line">    <span class="comment"># y_bounds = [np.min(y)-y_margin, np.max(y)+y_margin]  #è¾¹ç•Œæ¢æˆ0-1çœ‹çœ‹</span></span><br><span class="line">y_bounds = [<span class="number">0</span>-y_margin, <span class="number">1</span>+y_margin]</span><br><span class="line">    </span><br><span class="line">    mb.update_graph(graphs, x_bounds, y_bounds)</span><br></pre></td></tr></table></figure><p>ä¸Šé¢æ˜¯ä¸€ä¸ª åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç»˜åˆ¶ACCçš„åŒ… <a href="https://github.com/fastai/fastprogress">fastprogress</a></p><h2 id="3-2-train-valid"><a href="#3-2-train-valid" class="headerlink" title="3.2 train_valid"></a>3.2 train_valid</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_loop</span>(<span class="params">net, device, criterion, opti, lr, lr_scheduler, batch_size, </span></span><br><span class="line"><span class="params">               train_loader, val_loader, epochs, model_name</span>):</span><br><span class="line">    </span><br><span class="line">    best_acc = <span class="number">0</span></span><br><span class="line">    train_acc, valid_acc = [], []</span><br><span class="line">    mb = master_bar(<span class="built_in">range</span>(<span class="number">1</span>, epochs+<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> mb:</span><br><span class="line">        train_correct, valid_correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># train_part</span></span><br><span class="line">        net.train()</span><br><span class="line">        <span class="keyword">for</span> batch_data <span class="keyword">in</span> progress_bar(train_loader, parent=mb):</span><br><span class="line"></span><br><span class="line">            x, y = <span class="built_in">tuple</span>(k.to(device) <span class="keyword">for</span> k <span class="keyword">in</span> batch_data)</span><br><span class="line">            outputs = net(x).logits</span><br><span class="line">            loss = criterion(outputs, y)</span><br><span class="line">            train_correct += (outputs.argmax(dim=-<span class="number">1</span>) == y).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">            opti.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            lr_scheduler.step()</span><br><span class="line">            opti.step()</span><br><span class="line">        lr_now = lr_scheduler.get_lr()[<span class="number">0</span>]</span><br><span class="line">        train_acc.append(train_correct/(<span class="built_in">len</span>(train_loader)*batch_size))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># valid_part</span></span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> batch <span class="keyword">in</span> progress_bar(val_loader, parent=mb):</span><br><span class="line"></span><br><span class="line">                x, y = <span class="built_in">tuple</span>(k.to(device) <span class="keyword">for</span> k <span class="keyword">in</span> batch_data)</span><br><span class="line">                outputs = net(x).logits</span><br><span class="line">                loss = criterion(outputs, y)</span><br><span class="line">                valid_correct += (outputs.argmax(dim=-<span class="number">1</span>) == y).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">            valid_acc.append(valid_correct/(<span class="built_in">len</span>(val_loader)*batch_size))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># plot</span></span><br><span class="line">        plot_loss_update(epochs, mb, train_acc, valid_acc)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># print info</span></span><br><span class="line">        train_loss_now = train_acc[-<span class="number">1</span>]</span><br><span class="line">        valid_loss_now = valid_acc[-<span class="number">1</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> complete! Train Acc : </span></span><br><span class="line"><span class="string">              <span class="subst">&#123;train_loss_now*<span class="number">100</span>:<span class="number">.5</span>f&#125;</span>% with lr <span class="subst">&#123;lr_now:<span class="number">.4</span>f&#125;</span>&quot;</span>, <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> complete! Validation Acc : <span class="subst">&#123;valid_loss_now*<span class="number">100</span>:<span class="number">.5</span>f&#125;</span>%&quot;</span>, <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> valid_loss_now</span><br></pre></td></tr></table></figure><p>ä¸Šé¢æˆ‘ä»¬å®šä¹‰ä¸¤ä¸ªæ•°ç»„ä¿å­˜ACCçš„å€¼ï¼Œä»¥ç»˜åˆ¶å›¾å½¢</p><h2 id="3-3-kfold-save"><a href="#3-3-kfold-save" class="headerlink" title="3.3 kfold_save"></a>3.3 kfold_save</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">kfold_loop</span>(<span class="params">data, save_path, config</span>):</span><br><span class="line">    best_acc = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> fold, (train_ids,valid_ids) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kfold.split(data)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;FOLD <span class="subst">&#123;fold&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;--------------------------------------&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># config æ•°æ®é…ç½®</span></span><br><span class="line">        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)</span><br><span class="line">        valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)</span><br><span class="line">        </span><br><span class="line">        config[<span class="string">&#x27;train_loader&#x27;</span>] = torch.utils.data.DataLoader(data, batch_size=<span class="number">32</span>, </span><br><span class="line">                                                 sampler=train_subsampler, num_workers=<span class="number">2</span>)</span><br><span class="line">        config[<span class="string">&#x27;val_loader&#x27;</span>] = torch.utils.data.DataLoader(data,batch_size=<span class="number">32</span>, </span><br><span class="line">                                                  sampler=valid_subsampler, num_workers=<span class="number">2</span>)</span><br><span class="line">        config[<span class="string">&#x27;opti&#x27;</span>]  = torch.optim.AdamW(model.parameters(), lr=lr)</span><br><span class="line">        config[<span class="string">&#x27;lr_scheduler&#x27;</span>] = CosineAnnealingLR(config[<span class="string">&#x27;opti&#x27;</span>],T_max=<span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">        net.to(device)</span><br><span class="line">        valid_acc_now = train_loop(**config)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># save  ä¿å­˜æœ€å¥½çš„æ¨¡å‹</span></span><br><span class="line">        <span class="keyword">if</span> valid_acc_now &gt; best_acc:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Best validation Acc improved from <span class="subst">&#123;best_acc:<span class="number">.5</span>f&#125;</span> to <span class="subst">&#123;valid_loss_now:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line">            net_copy = copy.deepcopy(net)</span><br><span class="line">            best_acc = valid_loss_now</span><br><span class="line"></span><br><span class="line">            save_path = config[<span class="string">&#x27;save_path&#x27;</span>]</span><br><span class="line">            path_to_model = <span class="string">f&#x27;<span class="subst">&#123;save_path&#125;</span>/<span class="subst">&#123;model_name&#125;</span>_lr_<span class="subst">&#123;lr_now:<span class="number">.5</span>f&#125;</span>_valid_acc_<span class="subst">&#123;best_acc:<span class="number">.5</span>f&#125;</span>.pt&#x27;</span></span><br><span class="line">            torch.save(net_copy.state_dict(), path_to_model)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;The model has been saved in <span class="subst">&#123;path_to_model&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>è¿™é‡Œæˆ‘ä»¬è¿›è¡ŒkæŠ˜éªŒè¯</p><h2 id="3-4-config"><a href="#3-4-config" class="headerlink" title="3.4 config"></a>3.4 config</h2><p>æœ€åæˆ‘ä»¬å®šä¹‰è¶…å‚æ•°ï¼Œä»¥åŠå…¶ä»–æ„ä»¶</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">seed = <span class="number">1222</span></span><br><span class="line">bs = <span class="number">32</span></span><br><span class="line">lr = <span class="number">3e-4</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">warm_steps = <span class="number">122</span>*epochs</span><br><span class="line">total_steps = <span class="number">458</span>*epochs</span><br><span class="line"></span><br><span class="line">set_seed(seed)</span><br><span class="line"></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.RandomResizedCrop(<span class="number">224</span>, scale=(<span class="number">0.08</span>, <span class="number">1.0</span>), ratio=(<span class="number">3.0</span> / <span class="number">4.0</span>, <span class="number">4.0</span> / <span class="number">3.0</span>)),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.ColorJitter(brightness=<span class="number">0.4</span>, contrast=<span class="number">0.4</span>, saturation=<span class="number">0.4</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">os_path = <span class="string">&#x27;/kaggle/input/classify-leaves/&#x27;</span></span><br><span class="line">file_path = <span class="string">&#x27;/kaggle/working/train_valid_dataset.csv&#x27;</span></span><br><span class="line">dataset = imgdataset(os_path, file_path, train_transform)</span><br><span class="line">kfold = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">model = ViTForImageClassification.from_pretrained(<span class="string">&#x27;google/vit-base-patch16-224&#x27;</span>)</span><br><span class="line">model.classifier = nn.Linear(<span class="number">768</span>, <span class="number">176</span>)</span><br><span class="line"><span class="keyword">for</span> idx, para <span class="keyword">in</span> <span class="built_in">enumerate</span>(model.parameters()): <span class="comment">#å†»ç»“éƒ¨åˆ†å‚æ•°</span></span><br><span class="line">    para.requires_grad = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> idx == <span class="number">197</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">criter = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure><p>æ‰“åŒ…é…ç½®</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&#x27;net&#x27;</span>:model,</span><br><span class="line">    <span class="string">&#x27;device&#x27;</span>:device,</span><br><span class="line">    </span><br><span class="line">    <span class="string">&#x27;lr&#x27;</span>:lr,</span><br><span class="line">    <span class="string">&#x27;opti&#x27;</span>:<span class="number">1</span>,</span><br><span class="line">    <span class="string">&#x27;lr_scheduler&#x27;</span>:<span class="number">1</span>,</span><br><span class="line">    <span class="string">&#x27;criterion&#x27;</span>:criter,</span><br><span class="line">    </span><br><span class="line">    <span class="string">&#x27;batch_size&#x27;</span>:bs, </span><br><span class="line">    <span class="string">&#x27;train_loader&#x27;</span>:<span class="number">1</span>, </span><br><span class="line">    <span class="string">&#x27;val_loader&#x27;</span>:<span class="number">1</span>, </span><br><span class="line">    <span class="string">&#x27;epochs&#x27;</span>:epochs, </span><br><span class="line">    <span class="string">&#x27;model_name&#x27;</span>:<span class="string">&#x27;leaves_classifier_model&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="4-è®­ç»ƒ-amp-ç»“æœåˆ†æ"><a href="#4-è®­ç»ƒ-amp-ç»“æœåˆ†æ" class="headerlink" title="4. è®­ç»ƒ &amp; ç»“æœåˆ†æ"></a>4. è®­ç»ƒ &amp; ç»“æœåˆ†æ</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">!mkdir model_save</span><br><span class="line">save_dir = os.getcwd()+<span class="string">&#x27;/model_save&#x27;</span></span><br><span class="line"></span><br><span class="line">kfold_loop(dataset, save_dir, config)</span><br></pre></td></tr></table></figure><blockquote><p>è¿™é‡Œç¬¬ä¸€ä¸ªfold å‡ºäº†ç‚¹é—®é¢˜ï¼Œæ€»ä¹‹valid_accåº”è¯¥æ˜¯ä»6%åˆ°äº†23% åé¢å°±æ˜¯è·Ÿä¸‹å›¾ä¸€æ ·äº†</p></blockquote><img src="../../article_img/1669374036209.jpg" style="zoom:80%;" /><p>è¿™é‡Œæˆ‘æˆªå–äº†ä¸¤ä¸ªfoldè¿›è¡Œæ•°æ®æŸ¥çœ‹ (1foldåœ¨p100ä¸Šè®­ç»ƒå¤§æ¦‚40åˆ†é’Ÿå·¦å³ï¼‰</p><ul><li>éšç€æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„å‡†ç¡®ç‡ä¸Šå‡ï¼Œæ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å‡†ç¡®ç‡ä¹Ÿè·Ÿtrain_accé€æ­¥æ‹Ÿåˆï¼Œå½“ç„¶ç”±äºéªŒè¯é›†çš„æ•°æ®æ²¡æœ‰è®­ç»ƒè¿‡ï¼Œä¸­é—´æœ‰ä¸€äº›æŠ–åŠ¨ã€‚ä½†æ˜¯æ¨¡å‹æœ€åè¿˜æ˜¯å­¦åˆ°ä¸œè¥¿äº†çš„ã€‚</li></ul><p><strong>å°ç»“</strong>ï¼š</p><p>ç”±äºç¡¬ä»¶èµ„æºçš„é™åˆ¶ï¼Œå°±ä¸å†è¿›è¡Œè®­ç»ƒ(æ¨¡å‹è¿˜æ˜¯åœ¨ç»§ç»­æå‡çš„)ï¼Œæˆ‘ä»¬çœç•¥äº†æ¨¡å‹èåˆå’Œæäº¤ç»“æœçš„éªŒè¯ï¼Œè¿™é‡Œç®€å•æä¸‹</p><ul><li>ä»¥æŠ•ç¥¨æ–¹å¼çš„æ¨¡å‹èåˆä¸ºä¾‹ï¼ŒVitçš„æŠ•ç¥¨ç»“æœå æƒé‡0.4ï¼Œå‰©ä¸‹çš„ResNeStå’ŒResNeXtå„å 0.25,  VGGå 0.1ï¼Œæœ€åå†³å®šè¾“å‡ºçš„æ ‡ç­¾</li><li>testä¸Šå°±æ˜¯validéƒ¨åˆ† åªè¾“å‡º176ç»´åº¦é‡Œæœ€å¤§å€¼çš„ä½ç½®å³å¯</li></ul><h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>æ­¤æ¬¡æˆ‘ä»¬å­¦ä¹ äº†<strong>Pre-train</strong>çš„èŒƒå¼ã€<strong>K-foldéªŒè¯</strong>ã€<strong>DataAugment</strong>ã€‚</p><ul><li>é‡ç‚¹æ˜¯ç†è§£â€˜æ‹¿æ¥ä¸»ä¹‰â€™ï¼Œæ€»ä¹‹æ‹¿æ¥å°±ç”¨</li><li>kæŠ˜äº¤å‰éªŒè¯åªæ˜¯éªŒè¯çš„ä¸€ç§æ–¹å¼</li><li>æ•°æ®å¢å¼ºåˆ™éœ€è¦åœ¨ç†è§£æ•°æ®é›†çš„åŸºç¡€ä¸Šè¿›è¡Œï¼Œæ˜¯ç‚¼ä¸¹å¸ˆå¿…ä¿®çš„ä¸€é—¨ï¼Œå½“ç„¶ä¹Ÿæœ‰éå¸¸å¤šä¸­å¢å¼ºæ•°æ®çš„æ–¹å¼</li></ul><p>ä¹‹åæˆ‘ä»¬å°†è¿›è¡Œå¯¹æ¯”å­¦ä¹ çš„è®²è§£</p>]]></content>
      
      
      <categories>
          
          <category> CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CV </tag>
            
            <tag> HuggingFace </tag>
            
            <tag> Trick </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CV 01 CNN MNISTè¯†åˆ«</title>
      <link href="/posts/53023.html"/>
      <url>/posts/53023.html</url>
      
        <content type="html"><![CDATA[<h1 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h1><p>æœ¬æ–‡å°†é€šè¿‡CNN è®©è®¡ç®—æœºè¯†åˆ«MNISTæ•°æ®é›†ä¸­çš„æ‰‹å†™æ•°å­— ä»¥æ­¤æ¥ä»‹ç»Pytorchçš„åŸºæœ¬ä½¿ç”¨æ–¹æ³•ï¼š</p><ul><li>Pytorchä¸­çš„æ•°æ®ç±»å‹â€”â€”tensor</li><li>Pytorchä¸­çš„æ•°æ®é›†ã€æ•°æ®åŠ è½½å™¨â€”â€”Datasetã€DataLoader</li><li>Pytorchä¸­çš„åŸºç¡€ç±»æ¨¡å‹â€”â€”torch.nn.Module</li></ul><p>ä»¥åŠç¨‹åºè®¾è®¡ä¸Šçš„ä¸€äº›å°æŠ€å·§ã€‚</p><h1 id="1-tensor"><a href="#1-tensor" class="headerlink" title="1. tensor"></a>1. tensor</h1><h2 id="1-1-æ¦‚å¿µ"><a href="#1-1-æ¦‚å¿µ" class="headerlink" title="1.1 æ¦‚å¿µ"></a>1.1 æ¦‚å¿µ</h2><p>tensorä¸€è¯è¯‘ä¸º<strong>å¼ é‡</strong>ï¼Œä¸€èˆ¬æˆ‘ä»¬æ‰€æ¥è§¦çš„çŸ©é˜µæ˜¯äºŒç»´çš„ï¼Œç§°ä¸ºäºŒé˜¶å¼ é‡ã€å‘é‡ç§°ä¸ºä¸€é˜¶å¼ é‡ã€æ ‡é‡ç§°ä¸ºé›¶é˜¶å¼ é‡ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬é€šè¿‡Numpyåº“äº†è§£ä¸€ä¸‹å¼ é‡ã€‚ï¼ˆè¿™é‡Œå¹¶éæ•°å­¦ä¸Šä¸¥æ ¼çš„å®šä¹‰ï¼Œæ„Ÿæ€§ç†è§£ä¸€ä¸‹å³å¯ï¼‰</p><h3 id="1-1-1-äºŒé˜¶å¼ é‡-çŸ©é˜µ"><a href="#1-1-1-äºŒé˜¶å¼ é‡-çŸ©é˜µ" class="headerlink" title="1.1.1 äºŒé˜¶å¼ é‡ çŸ©é˜µ"></a>1.1.1 äºŒé˜¶å¼ é‡ çŸ©é˜µ</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é¦–å…ˆæˆ‘ä»¬ä¸¾ä¸€ä¸ªä¸‰è¡Œå…«åˆ—çš„çŸ©é˜µ</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="number">1</span>,<span class="number">25</span>).reshape(<span class="number">3</span>,<span class="number">8</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([[ 1,  2,  3,  4,  5,  6,  7,  8],</span></span><br><span class="line"><span class="string">       [ 9, 10, 11, 12, 13, 14, 15, 16],</span></span><br><span class="line"><span class="string">       [17, 18, 19, 20, 21, 22, 23, 24]])&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">b = np.ones_like(a).T</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;array([[1, 1, 1],</span></span><br><span class="line"><span class="string">           [1, 1, 1],</span></span><br><span class="line"><span class="string">           [1, 1, 1],</span></span><br><span class="line"><span class="string">           [1, 1, 1],</span></span><br><span class="line"><span class="string">           [1, 1, 1],</span></span><br><span class="line"><span class="string">           [1, 1, 1],</span></span><br><span class="line"><span class="string">           [1, 1, 1],</span></span><br><span class="line"><span class="string">           [1, 1, 1]])&#x27;&#x27;&#x27;</span></span><br><span class="line">          </span><br><span class="line"><span class="comment"># æˆ‘ä»¬åˆ›å»ºä»¥ä¸Šä¸¤ä¸ªçŸ©é˜µï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æŠŠä»–ä»¬åšç‚¹ä¹˜</span></span><br><span class="line">a@b</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;array([[ 36,  36,  36],</span></span><br><span class="line"><span class="string">           [100, 100, 100],</span></span><br><span class="line"><span class="string">           [164, 164, 164]]) &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>ä¸Šé¢æˆ‘ä»¬åˆ›å»ºäº†ä¸¤ä¸ªçŸ©é˜µaä¸ºä¸‰è¡Œå…«åˆ—ï¼Œbä¸ºå…«è¡Œä¸‰åˆ—ï¼Œä¸¤è€…åšç‚¹ç§¯å¾—åˆ°ä¸€ä¸ªä¸‰è¡Œä¸‰åˆ—çš„çŸ©é˜µã€‚</p><p>æˆ‘ä»¬æ‹‰åˆ°åˆ—è¡¨çš„è§’åº¦è§£é‡Šè¿™ä¸ªçŸ©é˜µï¼Œæˆ‘ä»¬å°†æ‰€æœ‰æ•°æ®éƒ½åŒ…å«åœ¨ä¸€ä¸ªå¤§åˆ—è¡¨ä¹‹å†…ï¼Œå¤§åˆ—è¡¨é‡Œæœ‰ä¸‰ä¸ªå°åˆ—è¡¨ï¼Œæ¯ä¸ªåˆ—è¡¨å†…æœ‰å…«ä¸ªå…ƒç´ ï¼Œ</p><p>å³<strong>ä¸‰ä¸ªå°åˆ—è¡¨ä»£è¡¨ä¸‰è¡Œï¼Œæ¯ä¸ªåˆ—è¡¨çš„å…«ä¸ªå…ƒç´ ä»£è¡¨å…«ä¸ªç»´åº¦</strong>ã€‚</p><blockquote><p>è¿™é‡Œä¸¾ä¸ªå°æ —å­å¸®åŠ©ç†è§£ä¸€ä¸‹ç»´åº¦ï¼š</p><p>æˆ‘ä»¬åœ¨ä¸‰å¹´çº§äºŒç­ç»™å„ä½åŒå­¦åšä¿¡æ¯ç™»è®°ï¼Œæ¯ä¸ªäººæ‰€éœ€è¦å¡«å†™ã€å§“åã€å¹´é¾„ã€èº«é«˜ã€ä½“é‡ã€‘å››é¡¹å†…å®¹ï¼Œæˆ‘ä»¬æŠŠæ¯ä¸ªäººçš„ä¿¡æ¯è®°ä¸ºä¸€æ¡æ•°æ®ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥è¯´è¿™æ¡æ•°æ®æœ‰å››ä¸ªç‰¹å¾ï¼Œå®ƒçš„ç»´åº¦ä¸ºå››ã€‚</p><p>é€šå¸¸æ¥è®²æˆ‘ä»¬æŠŠç‰¹å¾è®°ä¸º<strong>feature</strong>ï¼Œç§°è¿™æ¡æ•°æ®æœ‰å››ä¸ªç‰¹å¾ã€‚</p><p>ç°åœ¨æ•´ä¸ªç­çº§çš„ä¿¡æ¯éƒ½å¡«å†™å¥½äº†åº”è¯¥æ˜¯å¦‚ä½•çš„å½¢çŠ¶ï¼Œæˆ‘ä»¬å‡è®¾æœ‰32ä¸ªäººï¼š</p><p>ã€ã€å¼ ä¸‰ã€7ã€130ã€ 70ã€‘</p><p>â€‹ã€æå››ã€7ã€131ã€ 71ã€‘</p><p>â€‹  ã€‚ã€‚ã€‚</p><p>â€‹ã€æå°æ˜ã€7ã€129ã€70ã€‘ã€‘ å¦‚ä½•æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ª32è¡Œ4åˆ—çš„çŸ©é˜µï¼Œè®°ä¸ºï¼ˆ32,4ï¼‰</p><p>æ¥ä¸‹æ¥æˆ‘ä»¬æŠŠè§†è§’æ‹‰å€’æ•´ä¸ªä¸‰å¹´çº§ï¼Œæˆ‘ä»¬å‡è®¾æœ‰7ä¸ªç­çº§ï¼š</p><p>é‚£ä¹ˆæˆ‘ä»¬å¾—åˆ°çš„æ•°æ®ç»´åº¦åº”è¯¥æ˜¯ï¼ˆ7,32,4ï¼‰ï¼Œè¡¨ç¤ºæˆ‘ä»¬æœ‰7ä¸ªç­çº§çš„æ•°æ®ï¼Œæ¯ä¸ªç­çº§çš„æ•°æ®ç»´åº¦ï¼ˆ32,4ï¼‰ã€‚</p><p>æ­¤åæˆ‘ä»¬éƒ½ç§°è¿™ä¸ªâ€œç­çº§ä¸º<strong>batch</strong>â€œ ï¼Œè‡³æ­¤æˆ‘ä»¬ä»äºŒç»´çš„çŸ©é˜µä¸Šå‡åˆ°ä¸‰ç»´çš„å¼ é‡ã€‚</p></blockquote><h3 id="1-1-2-å¼ é‡"><a href="#1-1-2-å¼ é‡" class="headerlink" title="1.1.2 å¼ é‡"></a>1.1.2 å¼ é‡</h3><p>ä¸‹é¢æˆ‘ä»¬å°†ä»‹ç»å¸¸ç”¨çš„å¼ é‡å½¢å¼</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é¦–å…ˆä»‹ç»ä¸‹ä¸€å¼ å›¾ç‰‡é€šå¸¸çš„æ•°æ®æ ¼å¼ï¼Œæˆ‘ä»¬ä½¿ç”¨Numpyæ¥ä¼ªé€ ä¸€ä¸‹æ•°æ®</span></span><br><span class="line"></span><br><span class="line">np.random.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;array([[[[-1.03301822, -0.26956785, -1.81246034, ..., -0.2025034 ,</span></span><br><span class="line"><span class="string">          -0.24770628,  0.45183312],</span></span><br><span class="line"><span class="string">         [ 1.09102807,  0.92955389,  0.07537901, ...,  0.69203358,</span></span><br><span class="line"><span class="string">          -0.17726632, -0.74610015],</span></span><br><span class="line"><span class="string">         [ 0.40508712, -1.2507095 ,  0.68702445, ..., -0.12526432,</span></span><br><span class="line"><span class="string">           0.0390443 ,  1.00993313],</span></span><br><span class="line"><span class="string">         ...,</span></span><br><span class="line"><span class="string">         [ 1.96843042, -2.43286678,  0.08543089, ..., -1.57232148,</span></span><br><span class="line"><span class="string">           0.92844287, -0.25532137],</span></span><br><span class="line"><span class="string">         [ 0.46919141, -0.13700029,  1.78645959, ...,  0.01334257,</span></span><br><span class="line"><span class="string">           1.31030895, -0.22523819],</span></span><br><span class="line"><span class="string">         [ 0.63897933,  0.54846445, -0.64030391, ...,  0.92298892,</span></span><br><span class="line"><span class="string">          -0.50840421,  1.34232325]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[-0.01892086,  0.1456131 , -0.08903806, ...,  1.68250139,</span></span><br><span class="line"><span class="string">           1.2097305 , -0.2680935 ],</span></span><br><span class="line"><span class="string">         [ 0.92759263,  0.22665021,  1.28734004, ...,  0.09925943,</span></span><br><span class="line"><span class="string">           1.30039407,  3.34710594],</span></span><br><span class="line"><span class="string">         [ 0.53486942, -0.56230181, -1.92117215, ...,  1.33047469,</span></span><br><span class="line"><span class="string">          -1.19211895, -0.03081918],</span></span><br><span class="line"><span class="string">         ...,</span></span><br><span class="line"><span class="string">         [ 0.2539067 , -2.13160564,  0.27519544, ..., -0.62223126,</span></span><br><span class="line"><span class="string">           0.5818296 ,  0.07102949],</span></span><br><span class="line"><span class="string">         [-0.7524386 , -0.71244818,  0.88997093, ...,  0.16566338,</span></span><br><span class="line"><span class="string">           0.80577231, -3.35350436],</span></span><br><span class="line"><span class="string">         [ 0.99558393, -2.32335969, -2.87512549, ...,  1.16290939,</span></span><br><span class="line"><span class="string">           2.24089232,  0.22083378]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 1.35970859,  0.7961136 ,  0.09896652, ...,  1.82609401,</span></span><br><span class="line"><span class="string">          -0.49607535,  0.23424012],</span></span><br><span class="line"><span class="string">         [-0.22283053, -1.35535905, -0.55896315, ...,  1.68093489,</span></span><br><span class="line"><span class="string">           0.80969216,  0.63538616],</span></span><br><span class="line"><span class="string">         [-0.88285682,  0.59389887, -1.05559301, ..., -0.00719476,</span></span><br><span class="line"><span class="string">          -0.25654492, -1.40716977],</span></span><br><span class="line"><span class="string">         ...,</span></span><br><span class="line"><span class="string">         [ 0.44508688, -0.05650302, -2.97674436, ...,  1.25730001,</span></span><br><span class="line"><span class="string">          -1.66409024,  0.96057644],</span></span><br><span class="line"><span class="string">         [-1.3237267 , -0.27798159, -1.8947621 , ...,  1.96216661,</span></span><br><span class="line"><span class="string">          -0.10569547, -0.8446272 ],</span></span><br><span class="line"><span class="string">         [ 0.22525617,  0.75040916,  0.72823974, ..., -1.93525763,</span></span><br><span class="line"><span class="string">          -0.74464397,  0.55771249]]]]) &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>ä¸Šé¢å°±æ˜¯ä¸€å¼ å›¾ç‰‡**W(width)<strong>ä¸º28ï¼Œ</strong>H(heigh)**ä¸º28ï¼Œæœ‰RGBä¸‰ä¸ªé€šé“ï¼Œbatchä¸º1çš„å›¾ç‰‡(è¿™ä¸ªbatché‡Œé¢åªæœ‰ä¸€å¼ å›¾ç‰‡)çš„æ•°æ®è¡¨ç¤ºå½¢å¼ã€‚</p><p>å½“ç„¶ä¸Šé¢çš„æ•°æ®å¤ªè¿‡å¤æ‚ï¼Œæˆ‘ä»¬ä»¥ä¸‹é¢Wå’ŒHéƒ½ä¸º4çš„æ•°æ®ç»§ç»­è®²è§£ä¸€ä¸‹å„ä¸ªæ•°æ®çš„æ„ä¹‰ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">np.random.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;array([[[[ 0.43748082, -0.65000689,  0.13972451, -0.40213376],</span></span><br><span class="line"><span class="string">            [ 0.09342289, -0.83655856,  0.51844492,  0.96505144],</span></span><br><span class="line"><span class="string">            [ 0.68421876,  1.05527391, -0.30821748, -1.89826909],</span></span><br><span class="line"><span class="string">            [-0.36654524,  0.22642376,  0.16545107,  0.00401234]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            [[-0.13032482,  0.68182741, -0.52511016,  0.75875314],</span></span><br><span class="line"><span class="string">             [-1.39072336, -0.22848391, -1.64733525,  0.3339502 ],</span></span><br><span class="line"><span class="string">             [-1.06568103, -0.58455172, -0.02874822, -0.64499225],</span></span><br><span class="line"><span class="string">             [-0.23380602, -0.74809941, -0.71214339, -0.44950305]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            [[-1.51112191,  0.49145194, -0.01839728, -1.52788219],</span></span><br><span class="line"><span class="string">             [ 0.93370593,  0.96444176, -0.67434299, -1.8492484 ],</span></span><br><span class="line"><span class="string">             [ 0.51140855, -0.58682968, -1.16261225, -0.65782238],</span></span><br><span class="line"><span class="string">             [ 0.8643421 ,  0.79983446, -0.92330871, -2.45649675]]]]) &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li><p>ä¸€å·ä½<strong>batch</strong>&#x3D;1è¡¨ç¤ºåªæœ‰ä¸€å¼ å›¾ç‰‡</p><ul><li>è‹¥batch&#x3D;3ï¼Œæˆ‘ä»¬ä¸‹é¢é™åˆ°çš„æ¨¡å‹ä¾æ¬¡å–æœ¬æ‰¹æ¬¡å†…ã€0ã€‘å·(3,4,4)ã€ã€1ã€‘(3,4,4)ã€ã€2ã€‘(3,4,4)è¿›è¡Œå¤„ç†</li></ul></li><li><p>äºŒå·ä½<strong>Channel</strong>&#x3D;3 è¡¨ç¤ºæœ‰ä¸‰ä¸ªé€šé“åˆ†åˆ«æ˜¯RGB</p><ul><li>å¦‚ä¸Šé¢ 0.43748082â€¦.0.00401234ï¼Œå°±è¡¨ç¤ºåœ¨Ré€šé“å†…ï¼Œè¿™å¼ å›¾ç‰‡çš„é¢œè‰²æ•°æ®</li><li>Gå’ŒBé€šé“åŒç†ï¼Œè®©ä¸‰è€…å åŠ å°±å¯ä»¥è¡¨ç¤ºé¢œè‰²çš„æ˜æš—ï¼Œä»è€Œå‹¾å‹’ç”»é¢ï¼Œæ¸²æŸ“é¢œè‰²</li></ul></li><li><p>æœ€åçš„ä¸¤ä½å°±è¡¨ç¤ºé•¿å®½ï¼Œæ¯ä¸ªå…ƒç´ è¡¨ç¤ºåƒç´ ç‚¹çš„æ˜æš—ç¨‹åº¦ã€‚å¦‚Ré€šé“çš„ç¬¬ä¸€ä¸ªå…ƒç´ 0.43748082å°±è¡¨ç¤ºè¿™ä¸ªåƒç´ ç‚¹æœ‰å¤šçº¢</p><p>(çº¢ä¹Ÿæœ‰ç¨‹åº¦å¯¹å§)</p></li></ul><h2 id="1-2-Pytorchä¸­tensorçš„API"><a href="#1-2-Pytorchä¸­tensorçš„API" class="headerlink" title="1.2 Pytorchä¸­tensorçš„API"></a>1.2 Pytorchä¸­tensorçš„API</h2><p>Pytorchä¸­tensorå·ç§°æ˜¯è·ŸNumpyåŠå…¶ç›¸ä¼¼çš„æ“ä½œæ–¹å¼ï¼Œæœ‰Numpyçš„å­¦ä¹ åŸºç¡€çš„è¯å‡ ä¹ä¸ç”¨ä»˜å‡ºå­¦ä¹ æˆæœ¬æ¥é€‚åº”tensorã€‚ä½†æ˜¯å®é™…æƒ…å†µå°±ç»å¸¸å‡ºç°å„ç§è­¦å‘Šã€‚æ— è®ºå¦‚ä½•ï¼Œtensorå¯ä»¥äº«å—åˆ°GPUçš„åŠ é€Ÿè¿ç®—ï¼Œæ€»çš„æ¥è¯´ä¹Ÿå¤Ÿå‹å¥½ï¼Œä¸‹é¢æˆ‘ä»¬å°†ä»‹ç»å…¶å¸¸ç”¨çš„API</p><p>é¦–å…ˆæ˜¯éšæœºå‡½æ•°ï¼ŒåŸºæœ¬è·ŸNumpyæ˜¯ä¸€æ ·çš„ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">rand_tensor = torch.rand(shape)</span><br><span class="line">ones_tensor = torch.ones(shape)</span><br><span class="line">zeros_tensor = torch.zeros(shape)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Random Tensor:</span></span><br><span class="line"><span class="string"> tensor([[0.7453, 0.7993, 0.8484],</span></span><br><span class="line"><span class="string">        [0.3592, 0.3243, 0.7226]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Ones Tensor:</span></span><br><span class="line"><span class="string"> tensor([[1., 1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1., 1.]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Zeros Tensor:</span></span><br><span class="line"><span class="string"> tensor([[0., 0., 0.],</span></span><br><span class="line"><span class="string">        [0., 0., 0.]]) &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>æ¥ä¸‹æ¥ä»‹ç»tensorå¯¹è±¡çš„ä¸€äº›å±æ€§ï¼Œå…¶ä¸­deviceé»˜è®¤å°±æ˜¯ä½¿ç”¨cpuï¼Œè¡¨ç¤ºæˆ‘ä»¬æ•°æ®åœ¨cpuä¸Šã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tensor = torch.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[0.8165, 0.1909, 0.6631, 0.3062],</span></span><br><span class="line"><span class="string">           [0.0178, 0.5158, 0.0267, 0.9819],</span></span><br><span class="line"><span class="string">           [0.6103, 0.7354, 0.7933, 0.2770]]) &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">tensor.shape   <span class="comment"># å°†è¿”å› torch.Size([3, 4])</span></span><br><span class="line">tensor.dtype<span class="comment"># å°†è¿”å› torch.float32</span></span><br><span class="line">tensor.device<span class="comment"># å°†è¿”å› cpu</span></span><br><span class="line"></span><br><span class="line">device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span><span class="comment"># è¿™å¥è¯ç»å¸¸æ¥æŒ‡å®šæ•°æ®å¤„ç†çš„è®¾å¤‡</span></span><br></pre></td></tr></table></figure><p>torch.catä¹Ÿæ˜¯ä¸€ä¸ªå¸¸ç”¨çš„å‡½æ•°ï¼Œç”¨æ¥é“¾æ¥æ•°æ®ã€‚</p><p>ä¸‹é¢ä»¥ç¬¬ä¸€è¡Œä¸ºä¾‹ï¼Œcatå‡½æ•°å°†<code>[0.8165, 0.1909, 0.6631, 0.3062]</code>ä¸<code>[0.8165, 0.1909, 0.6631, 0.3062]</code>ã€<code>[0.8165, 0.1909, 0.6631, 0.3062,]</code>è¿æ¥ï¼Œè¿™æ˜¯å› ä¸ºdim&#x3D;1è¡¨ç¤ºåœ¨ç¬¬ä¸€ç»´åº¦ï¼Œå…¶è§†è§’å†…çš„å¯æ“ä½œå•ä½ä¸º<code>0.8165, 0.1909, 0.6631, 0.3062</code>è¿™äº›å…ƒç´ ï¼Œdim&#x3D;0åˆ™å¯æ“ä½œçš„åŸºæœ¬å•ä½ä¸ºtensor(è¿™é‡Œçš„tensorè¡¨ç¤ºä¸Šé¢çš„ä¸‰è¡Œå››åˆ—çš„å®ä¾‹å¼ é‡)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.cat([tensor, tensor, tensor], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[0.8165, 0.1909, 0.6631, 0.3062, 0.8165, 0.1909, 0.6631, 0.3062, 0.8165,</span></span><br><span class="line"><span class="string">         0.1909, 0.6631, 0.3062],</span></span><br><span class="line"><span class="string">        [0.0178, 0.5158, 0.0267, 0.9819, 0.0178, 0.5158, 0.0267, 0.9819, 0.0178,</span></span><br><span class="line"><span class="string">         0.5158, 0.0267, 0.9819],</span></span><br><span class="line"><span class="string">        [0.6103, 0.7354, 0.7933, 0.2770, 0.6103, 0.7354, 0.7933, 0.2770, 0.6103,</span></span><br><span class="line"><span class="string">         0.7354, 0.7933, 0.2770]]) &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>å¦å¤–ä»‹ç»ä¸€ä¸‹å¸¸ç”¨çš„ç±»å‹è½¬æ¢</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">t = torch.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">n = np.random.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">t.to_list()<span class="comment"># å°†tensorç±»å‹è½¬æ¢ä¸ºlist</span></span><br><span class="line">t.numpy()<span class="comment"># è½¬æ¢ä¸ºNumpyç±»å‹</span></span><br><span class="line">torch.from_numpy(n)<span class="comment"># ä»Numpyè½¬æ¢ä¸ºtensor</span></span><br></pre></td></tr></table></figure><p>æœ€åæœ€å¸¸ç”¨çš„å°±æ˜¯ä¸‹é¢ä¸¤å¥</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">torch.tensor(data) <span class="comment"># è¿”å›tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])å¯ä½¿ç”¨dtype=torch.float32æ¢æˆæµ®ç‚¹æ•°</span></span><br><span class="line">torch.Tensor(data)<span class="comment"># è¿”å› tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])</span></span><br></pre></td></tr></table></figure><h1 id="2-Dataset-DataLoader"><a href="#2-Dataset-DataLoader" class="headerlink" title="2. Dataset DataLoader"></a>2. Dataset DataLoader</h1><p> éƒ½è¯´æ•°æ®ç§‘å­¦å®¶ä¸€èˆ¬çš„æ—¶é—´éƒ½èŠ±åœ¨æ•°æ®å¤„ç†ä¸Šï¼Œä¸€ç‚¹ä¸å‡ã€‚å‰é¢èŠ±äº†è¿™ä¹ˆå¤§ç¯‡å¹…è®²ä»·tensorï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°†ä»‹ç»Pytorchä¸­å­˜å‚¨æ•°æ®çš„</p><p>Datasetå’Œæ•°æ®åŠ è½½å™¨DataLoader</p><h2 id="2-1-ä½ çš„æ•°æ®ç±»"><a href="#2-1-ä½ çš„æ•°æ®ç±»" class="headerlink" title="2.1 ä½ çš„æ•°æ®ç±»"></a>2.1 ä½ çš„æ•°æ®ç±»</h2><p>è™½ç„¶æˆ‘ä»¬ä½¿ç”¨çš„MNISTæ•°æ®é›†å·²ç»å¯ä»¥ç›´æ¥é€šè¿‡Pytorchçš„APIè°ƒç”¨ï¼Œå¦‚ä¸‹</p><p><code>from torchvision import datasets</code></p><p><code>datasets.MNIST(root=&#39;../dataset/mnist/&#39;, train=True, download=True, transform=transform)</code></p><blockquote><p>rootè¡¨ç¤ºå­˜å‚¨æˆ–è€…åŠ è½½æ•°æ®çš„è·¯å¾„</p><p>trainè¡¨ç¤ºæ˜¯å¦åªåŠ è½½è®­ç»ƒéƒ¨åˆ†çš„æ•°æ®é›†ï¼Œä¸è®¾å®šé»˜è®¤åŠ è½½å…¨éƒ¨æ•°æ®é›†</p><p>downloadå­—é¢æ„æ€</p><p>transformæŒ‡ä»£è¿™æ‰¹æ•°æ®ä½¿ç”¨ä»€ä¹ˆè½¬æ¢å½¢å¼ï¼Œä¸€èˆ¬æ¥è¯´æ˜¯ä¸€ç§æ•°æ®å¢å¼ºæ–¹å¼ï¼Œä»¥åä¼šä¸“é—¨ä»‹ç»</p></blockquote><p>æˆ‘ä»¬è¿˜æ˜¯æ¥å…·ä½“è§£é‡Šä¸‹é€šå¸¸è¦è‡ªå®šä¹‰ä½¿ç”¨çš„datasetã€‚</p><p>å®šä¹‰ç¬¦åˆä½ è¦æ±‚çš„æ•°æ®é›†æœ‰ä¸‰æ­¥å¿…é¡»æ“ä½œï¼š</p><ul><li>å®šä¹‰ä½ è‡ªå·±çš„æ•°æ®é›†ç±»å¹¶ç»§æ‰¿è‡ª<code>torch.utils.data.Dataset</code></li><li>éœ€è¦åŒ…å«<code>__len__</code>æ–¹æ³•è¿”å›é•¿åº¦</li><li>éœ€è¦åŒ…å«<code>__getitem__</code>æ–¹æ³•ï¼ŒæŒ‰ç…§ä¸‹æ ‡å–å¾—æ•°æ®</li></ul><p>ä»¥ä¸Šé…ç½®ä¹Ÿéƒ½æ˜¯ä¸ºäº†é…åˆDataLoaderçš„ä½¿ç”¨ï¼Œä¸‹é¢æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªdatasetç±»</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TitanicDataSets</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,flag</span>):</span><br><span class="line">        xy = preprocess(pd.read_csv(<span class="string">&quot;Titanic.csv&quot;</span>), flag=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> flag == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">            self.x_data = xy.iloc[:, :-<span class="number">1</span>][:<span class="number">800</span>]</span><br><span class="line">            self.y_data = xy.iloc[:, -<span class="number">1</span>][:<span class="number">800</span>]</span><br><span class="line">            self.<span class="built_in">len</span> = self.x_data.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> flag == <span class="string">&quot;valid&quot;</span>:</span><br><span class="line">            self.x_data = xy[<span class="number">0</span>][<span class="number">800</span>:<span class="number">892</span>]</span><br><span class="line">            self.y_data = xy[<span class="number">1</span>][<span class="number">800</span>:<span class="number">892</span>]</span><br><span class="line">            self.<span class="built_in">len</span> = self.x_data.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">return</span> self.x_data[index], self.y_data[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br></pre></td></tr></table></figure><p>ä¸Šé¢æˆ‘ä»¬å¼•å…¥kaggleè‘—åçš„<a href="https://www.kaggle.com/competitions/titanic/data">æ³°å¦å°¼å…‹å·å¹¸å­˜è€…é¢„æµ‹æ¯”èµ›ä½¿ç”¨çš„æ•°æ®é›†</a>ï¼Œå…¶ä¸­x_dataè·å¾—çš„æ˜¯å‰å…«ç™¾è¡Œä¹˜å®¢çš„ä¿¡æ¯ï¼Œy_dataè®°å½•çš„å°±æ˜¯æ˜¯å¦å­˜æ´»ã€‚</p><blockquote><p>ä¸€èˆ¬æ¥è¯´æˆ‘ä»¬ä¹Ÿ<strong>å°†æ•°æ®é›†åˆ†ä¸ºtrainå’Œvalidä¸¤éƒ¨åˆ†</strong>ï¼Œå› ä¸ºæœ€åæˆ‘ä»¬éœ€è¦é¢„æµ‹çš„æ•°æ®é›†å¹¶ä¸ä¼šæœ‰æ˜¯å¦å­˜æ´»çš„æ ‡ç­¾ï¼Œæ‰€ä»¥<strong>é€šè¿‡è®­ç»ƒæ¨¡å‹å‚æ•°ä»¥æ‹Ÿåˆtrainéƒ¨åˆ†çš„æ•°æ®ï¼Œä»¥validä¸ºæœ¬æ¬¡è®­ç»ƒçš„ç»“æœå¯¼å‘ä»¥ä¿®æ­£æ¨¡å‹å‚æ•°</strong>ï¼Œæœ€ç»ˆé¢„æµ‹ï¼Œå°±æ˜¯æˆ‘ä»¬çš„ç›®çš„ã€‚</p></blockquote><p>å¦‚ä¸Šé¢æ‰€ç¤ºï¼ŒPythonä¸­çš„è¯­å¥å°±æ˜¯è¿™ä¹ˆç®€æ´æ˜äº†ï¼Œæˆ‘ä»¬åœ¨åˆå§‹éƒ¨åˆ†è¯»å–æ•°æ®é›†ï¼Œç„¶åæ ¹æ®ä¼ å…¥çš„flagå†³å®šæ˜¯å¤„ç†trainè¿˜æ˜¯validçš„éƒ¨åˆ†æ•°æ®ï¼Œæœ€åæˆ‘ä»¬èµ‹äºˆè¿™ä¸ªç±»åƒåˆ—è¡¨é‚£æ ·çš„è·å–ä¸‹æ ‡å’Œåˆ‡ç‰‡èƒ½åŠ›(<code>__getitem__</code>æ–¹æ³•)ã€ä»¥åŠè¿”å›é•¿åº¦çš„èƒ½åŠ›(<code>__len__</code>æ–¹æ³•)</p><h2 id="2-2-æ•°æ®åŠ è½½å™¨"><a href="#2-2-æ•°æ®åŠ è½½å™¨" class="headerlink" title="2.2 æ•°æ®åŠ è½½å™¨"></a>2.2 æ•°æ®åŠ è½½å™¨</h2><p>Pytorchçš„æ•°æ®åŠ è½½å™¨DataLoaderç®€å•æ˜“ç”¨ï¼Œä¸‹é¢ä»‹ç»å®ƒéƒ¨åˆ†å¸¸ç”¨å‚æ•°ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = TitanicDataSets(flag=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">train_loader = DataLoader(dataset=train_dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><ul><li>dataset è¡¨ç¤ºå®ƒæ‰€å¤„ç†çš„æ•°æ®ï¼Œä¸€èˆ¬æ˜¯ä½ å®šä¹‰çš„datasetç±»ï¼Œæˆ–è€…å…·æœ‰ä¸‹æ ‡å–å€¼ï¼Œå’Œè¿”å›é•¿åº¦çš„æ•°æ®ç±»å‹ä¹Ÿå¯ä»¥</li><li>batch_size è¡¨ç¤ºä¸€è¯ä¼ ç»™æ¨¡å‹å¤šå°‘æ¡æ•°æ®</li><li>shuffle è¡¨ç¤ºæ˜¯å¦æ‰“ä¹±</li><li>num_workers è¡¨ç¤ºä½¿ç”¨ä½ cpuçš„å‡ ä¸ªæ ¸è¿›è¡Œè¯»å–</li></ul><p>å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„è¯­å¥æŸ¥çœ‹dataloaderè¿”å›ç»™ä½ çš„æ•°æ®å½¢çŠ¶</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">samples = next(iter(train_loader))</span><br><span class="line">samples[:2]# æŸ¥çœ‹æœ¬æ‰¹æ¬¡(batch)çš„å‰ä¸¤ä¸ªæ ·æœ¬([0]å·ï¼Œ[1]å·)</span><br></pre></td></tr></table></figure><h1 id="3-æ¨¡å‹"><a href="#3-æ¨¡å‹" class="headerlink" title="3. æ¨¡å‹"></a>3. æ¨¡å‹</h1><p>å¯¹äºæ¨¡å‹ï¼Œä»¥æˆ‘çš„ç†è§£ï¼Œæ•°æ®è™½ç„¶æ˜¯æ­»çš„ï¼Œä½†æ˜¯ç†è§£å®ƒçš„æ–¹å¼æ˜¯æ´»çš„ï¼›æ¨¡å‹æ˜¯æ´»çš„ï¼Œä½†æ˜¯ç»„åˆå®ƒçš„æ–¹å¼å¹¶æ²¡æœ‰é‚£ä¹ˆçµæ´»ã€‚è¿™é‡Œä¹‹æ‰€ä»¥è¯´æ˜¯ç»„åˆï¼Œè¯´ç‚¹é¢˜å¤–è¯ï¼Œæ˜¯å› ä¸ºå¦‚ä»Šé¢„è®­ç»ƒæ¨¡å‹å¤§è¡Œå…¶é“ï¼Œå¤§æ¨¡å‹åœ¨å„ä¸ªä»»åŠ¡ä¸Šä¸æ–­åˆ·æ–°çºªå½•(SOTA)ï¼Œå°å‹æœºæ„å¾ˆéš¾æœ‰åŠ›é‡å»è®­ç»ƒè¿™ç§å¤§æ¨¡å‹ï¼Œäºæ˜¯åœ¨å¤§æ¨¡å‹ä¸Šä¿®ä¿®æ”¹æ”¹ä»¥é€‚åº”ä¸‹æ¸¸ä»»åŠ¡çš„æ–¹å¼ï¼Œåªèƒ½ä½¿ç”¨è¿™ç§åƒæ˜¯Transformerçš„æ–¹å¼ä¸æ–­å˜å½¢ç»„åˆï¼Œæ€»æ„Ÿè§‰ç¼ºäº†ç‚¹æ´»åŠ›ã€‚(å¥ å®šPre-trainçš„Bertå°±æ˜¯åœ¨TransformeråŸºç¡€ä¸Šæå‡ºæ¥çš„)ã€‚</p><h2 id="3-1-æ¨¡å‹å®šä¹‰"><a href="#3-1-æ¨¡å‹å®šä¹‰" class="headerlink" title="3.1 æ¨¡å‹å®šä¹‰"></a>3.1 æ¨¡å‹å®šä¹‰</h2><p>ä¸‹é¢å¼€å§‹å®šä¹‰æˆ‘ä»¬çš„CNNæ¨¡å‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">320</span>, <span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># flatten data from (n,1,28,28) to (n, 784)</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.pooling(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">        x = x.view(batch_size, -<span class="number">1</span>) <span class="comment"># -1 æ­¤å¤„è‡ªåŠ¨ç®—å‡ºçš„æ˜¯320</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><ul><li>åˆå§‹åŒ–éƒ¨åˆ†å°±æ˜¯å®šä¹‰è¿™ä¸ªæ¨¡å‹çš„å„ç§æ–¹æ³•</li><li>forwardå‘å‰ä¼ æ’­ï¼Œåº”ç”¨åˆå§‹åŒ–éƒ¨åˆ†å®šä¹‰çš„å‡½æ•°</li></ul><p>å› ä¸ºMNISTæ•°æ®é›†æ˜¯é»‘ç™½å›¾ç‰‡æ‰€ä»¥åªæœ‰ä¸€ä¸ªé€šé“(ä»¥ç°åº¦greyåˆ»ç”»å›¾åƒå³å¯)</p><h2 id="3-2-æ¨¡å‹åŠŸèƒ½ç»†èŠ‚"><a href="#3-2-æ¨¡å‹åŠŸèƒ½ç»†èŠ‚" class="headerlink" title="3.2 æ¨¡å‹åŠŸèƒ½ç»†èŠ‚"></a>3.2 æ¨¡å‹åŠŸèƒ½ç»†èŠ‚</h2><p><code>torch.nn.Conv2d</code>å³convolutionï¼ˆå·ç§¯å±‚ï¼‰</p><ul><li><p>ç¬¬ä¸€ä¸ªå‚æ•°è¡¨ç¤ºè¿›å…¥å·ç§¯å±‚æ•°æ®çš„channelæ•°</p></li><li><p>ç¬¬äºŒä¸ªå‚æ•°è¡¨ç¤ºå®Œæˆå·ç§¯åæ•°æ®çš„channelæ•°</p></li><li><p>padding&#x3D;1 å³åœ¨å›¾å½¢å‘¨å›´å¡«å……ä¸€åœˆä¸º0çš„æ•°æ®(ä¸€èˆ¬æ¥è¯´æ˜¯æœ‰äº›å›¾å½¢åœ¨æŸäº›æƒ…å†µä¸‹ä¸paddingå°†ä¼šå–ä¸åˆ°åŸæœ¬è¾¹ç•Œä¸Šçš„å€¼)</p></li><li><p>kernel_sizeè¡¨ç¤ºå·ç§¯æ ¸å¤§å°(3,3)ï¼Œå¦‚å›¾æ‰€ç¤ºï¼ˆ5,5ï¼‰çš„å›¾å½¢paddingä¹‹åå˜ä¸ºï¼ˆ7,7ï¼‰ï¼Œå…¶ç»è¿‡å·ç§¯æ ¸æ˜ å°„æˆï¼ˆ3,3ï¼‰çš„å½¢çŠ¶</p></li></ul><p><img src="/../../article_img/Convolution_arithmetic_-_Padding_strides.gif"></p><blockquote><p>å·ç§¯æ ¸è¿›è¡Œçš„æ“ä½œæ˜¯elementwise multiplicationï¼Œå°±æ˜¯å…ƒç´ ä¸æ ¸ä¸Šå¯¹åº”å…ƒç´ ç›¸ä¹˜ä¹‹ååŠ èµ·æ¥å°±å¯ä»¥äº†</p><p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=conv2d#torch.nn.Conv2d">è¿™é‡Œä¹Ÿè¯·å„ä½æŸ¥çœ‹Pytochæ–‡æ¡£æŸ¥çœ‹æ›´å¤šå‚æ•°çš„è¯¦ç»†è§£é‡Š</a></p></blockquote><p><code>torch.nn.MaxPool2d</code></p><p>ä¹Ÿå°±æ˜¯åœ¨ä¸€ä¸ªè®¾å®šçš„æ ¸çš„çª—å£å†…å–æœ€å¤§å€¼</p><p><strong>æ³¨æ„maxpoolå°±æ˜¯ä¸ºäº†å–å¾—æ­¤åŒºåŸŸæœ€å¤§å€¼ä½œä¸ºç‰¹å¾è¾“å‡ºç»™ä¸‹ä¸€å±‚çš„æ‰€ä»¥ä¸ä¼šæœ‰overlapçš„åœ°æ–¹</strong></p><p><img src="/../../article_img/maxpool.gif"></p><p><code>æ¿€æ´»å‡½æ•°relu</code></p><p>ç›´æ¥ä¸Šå›¾ï¼Œç½®äºsigmaå‡½æ•°ã€softmaxå‡½æ•°ã€tanhå‡½æ•°ä¹‹åä¼šå¼€æ–‡è®²</p><p><img src="/../../article_img/1_DfMRHwxY1gyyDmrIAd-gjQ.png"></p><p><code>torch.nn.Linear</code></p><p>å°±æ˜¯å…¨è¿æ¥å±‚ã€‚</p><p>å¯¹äºç»è¿‡å·ç§¯ã€æ± åŒ–ã€æ¿€æ´»çš„æ•°æ®ï¼Œç»´åº¦ä¸º(batch_size, b, c, d)ï¼Œ</p><p>æˆ‘ä»¬å°†å…¶å‹ç¼©ä¸º(batch_size, n) æœ€åé€ç»™å…¨è¿æ¥å±‚åšnåˆ°10çš„æ˜ å°„ï¼Œæœ€åå˜ä¸º(batch_size, 10)ï¼Œä»¥æœ€å¤§æ•°çš„ä¸‹æ ‡ä½œä¸ºæˆ‘ä»¬æ¨¡å‹çš„é¢„æµ‹ç»“æœ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¦‚batch_size = 2</span></span><br><span class="line"></span><br><span class="line">tensor = torch.rand(<span class="number">2</span>,<span class="number">10</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[0.1022, 0.3252, 0.8618, 0.1433, 0.8307, 0.8538, 0.1535, 0.1760, 0.0021,0.9704],</span></span><br><span class="line"><span class="string"> [0.6809, 0.6555, 0.1134, 0.3555, 0.4866, 0.5923, 0.5204, 0.9048, 0.5630,0.4472]]</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line"> </span><br><span class="line">tensor.argmax(dim=-<span class="number">1</span>)   <span class="comment"># è·å¾— [9, 7] ç¬¬ä¸€ä¸ªåˆ—è¡¨æœ€å¤§å€¼çš„ä¸‹æ ‡æ˜¯9ï¼Œç¬¬äºŒä¸ªæ˜¯7</span></span><br></pre></td></tr></table></figure><h1 id="4-è®­ç»ƒ"><a href="#4-è®­ç»ƒ" class="headerlink" title="4. è®­ç»ƒ"></a>4. è®­ç»ƒ</h1><h2 id="4-1-ä¸€èˆ¬æµç¨‹"><a href="#4-1-ä¸€èˆ¬æµç¨‹" class="headerlink" title="4.1 ä¸€èˆ¬æµç¨‹"></a>4.1 ä¸€èˆ¬æµç¨‹</h2><p>é¦–å…ˆå°†æ¨¡å‹å®ä¾‹åŒ–ï¼Œå¹¶å¼•å…¥æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’Œè®¾å¤‡ã€‚ï¼ˆå…³äºæŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ä¹‹åä¹Ÿä¼šå¼€æ–‡è®²ï¼‰</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = Net()</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure><p>åŠ è½½æ•°æ®ï¼Œè¿™é‡Œå‡½æ•°åéƒ½æ˜¯è§åçŸ¥æ„ï¼Œå¾ˆå¥½ç†è§£</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"> </span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=<span class="literal">False</span>, batch_size=batch_size)</span><br></pre></td></tr></table></figure><p>ä¸‹é¢å®šä¹‰è®­ç»ƒå¾ªç¯</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">       <span class="comment"># æ³¨æ„è¿™é‡Œå› ä¸ºæ˜¯MNISTæ•°æ®é›†ï¼Œæ‰€ä»¥è‡ªåŠ¨è¿”å›tensorç±»å‹ï¼Œè¿™æ‰æœ‰to()æ–¹æ³•</span></span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        target = target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"> </span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"> </span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch+<span class="number">1</span>, batch_idx+<span class="number">1</span>, running_loss/<span class="number">300</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            images = images.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;accuracy on test set: %d %% &#x27;</span> % (<span class="number">100</span>*correct/total))</span><br></pre></td></tr></table></figure><p>ä»¥ä¸Šæ¨¡å‹å‡†ç¡®ç‡åœ¨98%</p><h2 id="4-2-çœ‹çœ‹å‡†ä¸å‡†"><a href="#4-2-çœ‹çœ‹å‡†ä¸å‡†" class="headerlink" title="4.2 çœ‹çœ‹å‡†ä¸å‡†"></a>4.2 çœ‹çœ‹å‡†ä¸å‡†</h2><p>ä»¥ä¸‹å†…å®¹ä½¿ç”¨jupyter notebookæŸ¥çœ‹</p><p>å•ä¸ªæŸ¥çœ‹(train_loaderå°±æ˜¯ä¸Šé¢æµç¨‹ä¸­å®šä¹‰çš„)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_pred</span>():</span><br><span class="line">    samples = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line">    x = samples[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    pred = model(x).argmax(-<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred.item())</span><br><span class="line"></span><br><span class="line">    plt.imshow(x.squeeze().numpy())</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">show_pred()</span><br></pre></td></tr></table></figure><p><img src="/../../article_img/Mnist_pred.png"></p><p>æ‰¹é‡æŸ¥çœ‹(train_loaderå°±æ˜¯ä¸Šé¢æµç¨‹ä¸­å®šä¹‰çš„)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_batch_pred</span>():</span><br><span class="line">    samples = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line">    x = samples[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">    <span class="keyword">for</span> i, imgs <span class="keyword">in</span> <span class="built_in">enumerate</span>(x[:<span class="number">10</span>], <span class="number">0</span>):</span><br><span class="line">        npimg = imgs.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">        plt.subplot(<span class="number">2</span>, <span class="number">10</span>, i+<span class="number">1</span>)</span><br><span class="line">        plt.imshow(npimg, cmap=plt.cm.binary)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    pred = model(x[:<span class="number">10</span>]).argmax(-<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred.numpy().tolist())</span><br><span class="line">    </span><br><span class="line">show_batch_pred()</span><br></pre></td></tr></table></figure><p><img src="/../../article_img/Mnist_batch.png"></p><p>å¯ä»¥çœ‹åˆ°è¿˜æ˜¯é”™äº†ä¸€ä¸ªçš„ï¼Œå€’æ•°ç¬¬ä¸‰åº”è¯¥æ˜¯4 (è¦ä¸å°±æ˜¯æˆ‘çœ‹é”™äº†)</p><h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><ul><li>ä¸‹é¢æˆ‘ä»¬æ¥æ€»ç»“ä¸€ä¸‹è®­ç»ƒä¸€ä¸ªæ¨¡å‹çš„pipelineï¼Œæˆ‘è®¤ä¸ºæ€»ç»“è®©æˆ‘ä»¬çš„pipelineè·å¾—ä¸€å®šçš„æ³›åŒ–èƒ½åŠ›</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰æ•°æ®</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])</span><br><span class="line"> </span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=<span class="literal">False</span>, batch_size=batch_size)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># å®šä¹‰æ¨¡å‹</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">320</span>, <span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># flatten data from (n,1,28,28) to (n, 784)</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.pooling(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">        x = x.view(batch_size, -<span class="number">1</span>) <span class="comment"># -1 æ­¤å¤„è‡ªåŠ¨ç®—å‡ºçš„æ˜¯320</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> x </span><br><span class="line"> </span><br><span class="line"><span class="comment"># è®­ç»ƒå’ŒéªŒè¯</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        target = target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"> </span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"> </span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch+<span class="number">1</span>, batch_idx+<span class="number">1</span>, running_loss/<span class="number">300</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            images = images.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;accuracy on test set: %d %% &#x27;</span> % (<span class="number">100</span>*correct/total))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">epochs</span>):</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">        train(epoch)</span><br><span class="line">        test()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># æ¨¡å—å®šä¹‰ï¼Œä¸€èˆ¬è¿™é‡Œä¼šåŠ å…¥è¶…å‚æ•°çš„å®šä¹‰</span></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒ</span></span><br><span class="line">main(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><ul><li><p>å›é¡¾æ•´ä¸ªæµç¨‹: å‡†å¤‡æ•°æ®â€”&gt; å®šä¹‰æ¨¡å‹â€”&gt; è®­ç»ƒå¾ªç¯è®¾è®¡â€”&gt; è¶…å‚æ•°â€”&gt; è®­ç»ƒå¹¶åˆ†æç»“æœã€‚å„ä¸ªç¯èŠ‚ç»†èŠ‚çš„è®¾è®¡è¯·å„ä½å‚ç…§<a href="https://pytorch.org/docs/stable/index.html">Pytochå®˜æ–¹æ–‡æ¡£ç ”ç©¶</a></p></li><li><p>ä»¥ä¸Šå°±æ˜¯æ•´ä¸ªæ•°æ®åˆ°æ¨¡å‹åˆ°ç»“æœçš„æµç¨‹ï¼Œä¸‹èŠ‚æˆ‘ä»¬å°†ä»‹ç»VGGã€ResNet50ç­‰é¢„è®­ç»ƒæ¨¡å‹</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CV </tag>
            
            <tag> Pytorch åŸºç¡€ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PythonåŸºç¡€01 æ•°æ®ç±»å‹</title>
      <link href="/posts/12763.html"/>
      <url>/posts/12763.html</url>
      
        <content type="html"><![CDATA[<h1 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h1><p>æœ¬æ–‡ä»‹ç»Pythonä¸­åŸºæœ¬çš„æ•°æ®ç±»å‹ï¼š</p><ul><li>å­—ç¬¦ä¸²ã€æ•°å­—</li><li>åˆ—è¡¨</li><li>å­—å…¸</li><li>é›†åˆ</li><li>å…ƒç»„</li></ul><p>ä»¥åŠä¸€äº›å¸¸ç”¨çš„å¤„ç†å°æŠ€å·§ã€‚</p><h1 id="1-å­—ç¬¦ä¸²ã€æ•°å­—"><a href="#1-å­—ç¬¦ä¸²ã€æ•°å­—" class="headerlink" title="1. å­—ç¬¦ä¸²ã€æ•°å­—"></a>1. å­—ç¬¦ä¸²ã€æ•°å­—</h1><p>Pythonä¸­å­—ç¬¦ä¸²ï¼ˆstrï¼‰çš„å¤„ç†å¯¹äºæ²¡æœ‰ä»»ä½•å˜æˆç»éªŒçš„åŒå­¦å¯èƒ½æœ‰äº›è‹¦æ¼ï¼Œå¦‚ä¸‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s1 = <span class="string">&#x27;1222&#x27;</span></span><br><span class="line">i = <span class="number">1222</span></span><br><span class="line"></span><br><span class="line">add_up = s1 + i <span class="comment"># è¿™æ®µå‡½æ•°å°±ä¼šæŠ¥é”™ï¼Œå› ä¸ºæ— æ³•å°† intç±»å‹ ä¸ strç±»å‹ç›¸åŠ </span></span><br></pre></td></tr></table></figure><ul><li><p>int ï¼šæ•´æ•°ç±»å‹ï¼Œå°†å°æ•°æŠ¹é™¤</p><ul><li>float ï¼šæµ®ç‚¹æ•°ç±»å‹ï¼Œå› ä¸ºäºŒè¿›åˆ¶è¿›ä½çš„å…³ç³»æ•°æ®å¹¶ä¸å‡†ç¡®çš„</li></ul></li><li><p>ä»¥ä¸Šå°±æ˜¯æé†’å„ä½ï¼Œå¯¹æ•°æ®å¤„ç†çš„æ—¶å€™ï¼Œä¸€å®šè¦ç•™å¿ƒæ•°æ®çš„ç±»å‹</p></li></ul><h2 id="1-1-å­—ç¬¦ä¸²ä¸­çš„åºå·"><a href="#1-1-å­—ç¬¦ä¸²ä¸­çš„åºå·" class="headerlink" title="1.1 å­—ç¬¦ä¸²ä¸­çš„åºå·"></a>1.1 å­—ç¬¦ä¸²ä¸­çš„åºå·</h2><p>å­—ç¬¦ä¸²çš„åºå·å¯ä»¥è®©ä½ å¿«é€Ÿå–å¾—ä¸€ä¸²å­—ç¬¦ä¸­ä»»æ„ä½ç½®çš„ä»»æ„å­—ç¬¦ï¼Œæœ‰å¦‚ä¸‹ä¸‰ç§åŸºæœ¬æ–¹å¼ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">&#x27;Attention Is A Talent&#x27;</span> <span class="comment"># é¦–å…ˆåˆ›å»ºä¸€ä¸ªå­—ç¬¦ä¸²</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬ä¸€ç§ å–å•ä¸ªå­—ç¬¦</span></span><br><span class="line">s[<span class="number">0</span>] <span class="comment"># å°†è·å¾— &#x27;A&#x27;</span></span><br><span class="line">s[<span class="number">20</span>]<span class="comment"># å°†è·å¾— &#x27;t&#x27;  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬äºŒç§ å–å¤šä¸ªå­—ç¬¦</span></span><br><span class="line">s[<span class="number">0</span>:<span class="number">2</span>]  <span class="comment"># å°†è·å¾— &#x27;At&#x27; </span></span><br><span class="line">s[:<span class="number">20</span>]<span class="comment"># å°†è·å¾— &#x27;Attention Is A Talen&#x27;</span></span><br><span class="line">s[::<span class="number">2</span>]  <span class="comment"># å°†è·å¾— &#x27;AtninI  aet&#x27;</span></span><br><span class="line">s[::<span class="number">1</span>]  <span class="comment"># å°†è·å¾— &#x27;Attention Is A Talent&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬ä¸‰ç§ å€’åº</span></span><br><span class="line">s[-<span class="number">1</span>]   <span class="comment"># å°†è·å¾— &#x27;t&#x27; </span></span><br><span class="line">s[-<span class="number">21</span>:]<span class="comment"># å°†è·å¾— &#x27;Attention Is A Talent&#x27;</span></span><br></pre></td></tr></table></figure><p>æœ‰å¦‚ä¸‹éœ€è¦æ³¨æ„çš„å‡ ä¸ªåœ°æ–¹ï¼š</p><ol><li><p>åœ¨pythonä¸­æˆ‘ä»¬ä½¿ç”¨å¼•å·åŒ…è£¹éœ€è¦çš„å­—ç¬¦ä¸²å†…å®¹</p></li><li><p>å­—ç¬¦ä¸²çš„åºå·æ˜¯ä» 0 å¼€å§‹å®šä¹‰çš„ï¼Œæ‰€ä»¥ä¸Šé¢çš„sæœ‰21ä¸ªå­—ç¬¦ï¼Œè€Œ<strong>æ–¹æ‹¬å·å†…</strong>çš„å–å€¼èŒƒå›´æ˜¯[0,20], ç»†å¿ƒä½ çš„è‚¯å®šå‘ç°äº†ï¼Œç©ºæ ¼æ•°ä¹Ÿç®—è¿›å»äº†ã€‚æ²¡é”™<strong>ç©ºæ ¼ä¹Ÿç®—ä¸€ç§ç‰¹æ®Šçš„å­—ç¬¦</strong>ã€‚</p></li><li><p>ç¬¬äºŒç§å–å€¼æ–¹å¼æˆ‘ä»¬ç§°ä¹‹ä¸º<strong>åˆ‡ç‰‡</strong>ï¼Œpythonä¸­çš„åˆ‡ç‰‡æ–¹å¼ç­‰ä»·æ•°å­¦ä¸Šçš„**å·¦é—­å³å¼€~[x, y)**ï¼Œä¸Šé¢å­—ç¬¦s[:20]ï¼Œæ˜¯å–å¾—s[20]å·ä½å·¦è¾¹çš„å…¨éƒ¨å€¼ï¼Œä½†æ˜¯ä¸ä¼šåŒ…å«s[20]ã€‚</p></li></ol><p>â€‹å½“ç„¶æ˜¯ç”¨s[0:20] ä¹Ÿæ˜¯ç­‰ä»·çš„ã€‚</p><p>â€‹<strong>æ­¥é•¿</strong> å³ç¬¬äºŒç§æ–¹æ³•çš„ç¬¬ä¸‰ä¸ªå¼å­ï¼Œæ˜¯ç”¨æ­¥é•¿å°±æ˜¯å­—é¢æ„æ€ï¼Œæ¯èµ°næ­¥å–å€¼ã€‚</p><p>â€‹s[::2]å°±æ˜¯ s[0]ç¬¬ä¸€æ­¥ï¼Œ s[1]ç¬¬äºŒæ­¥(å­˜å‚¨)ï¼Œs[2]ç¬¬ä¸‰æ­¥ï¼Œs[3]ç¬¬å››æ­¥(å­˜å‚¨)â€¦.</p><ol start="4"><li><p>å€’åºæ˜¯å­—ç¬¦ä¸²çš„å¦ä¸€å¥—åºå·ï¼Œå®ƒæœ‰å¾ˆå¤šåº”ç”¨åœºæ™¯ï¼Œæ¯”å¦‚å®šä¹‰ä¸€ä¸ªå¾ˆé•¿çš„å­—ç¬¦ä¸²ä½ å¯èƒ½éœ€è¦ç”¨s[1222222]æ‰èƒ½å–å¾—è¿™ä¸ªå€¼ï¼Œä½†æ˜¯æ˜¯ç”¨s[-1]å°±å¾ˆæ–¹ä¾¿ã€‚</p><p>å½“ç„¶ï¼Œéœ€è¦æ³¨æ„<strong>å€’åºæ˜¯ä»[-1]å¼€å§‹çš„</strong>ã€‚</p></li></ol><h2 id="1-2-ç‰¹æ®Šå­—ç¬¦"><a href="#1-2-ç‰¹æ®Šå­—ç¬¦" class="headerlink" title="1.2 ç‰¹æ®Šå­—ç¬¦"></a>1.2 ç‰¹æ®Šå­—ç¬¦</h2><p><code>&#39;\n&#39;(æ¢è¡Œ)    &#39;\b&#39;(å›é€€)    &#39;\r&#39;(å…‰æ ‡å›åˆ°æœ¬è¡Œè¡Œé¦–)  &#39;\t&#39;(ç›¸å½“äºå…«ä¸ªç©ºæ ¼ï¼Œä¸¤ä¸ªtable)</code></p><p>ä»¥ä¸Šå°±æ˜¯å‡ ä¸ªå¸¸è§çš„ç‰¹æ®Šå­—ç¬¦ï¼Œå…¶ä¸­ç‰¹åˆ«éœ€è¦æ³¨æ„çš„æ˜¯è·¯å¾„ä¸­çš„æ–œæ å¦‚é‡åˆ° \nigger è®¡ç®—æœºå¯èƒ½å°±æ— æ³•æ˜ç™½ä½ è¾“å…¥çš„æ˜¯ â€˜iggerâ€™ï¼Œè¿˜æ˜¯å«æœ‰nçš„å­—ç¬¦ä¸²ã€‚æœ‰ä»¥ä¸‹ä¸¤ç§å¤„ç†æ–¹å¼ï¼š</p><ul><li><code>&#39;\\nigger&#39;</code> </li><li><code>r&#39;\nigger&#39;</code></li></ul><h2 id="1-3-å­—ç¬¦ä¸²çš„è¿ç®—ä»¥åŠå¸¸ç”¨å‡½æ•°"><a href="#1-3-å­—ç¬¦ä¸²çš„è¿ç®—ä»¥åŠå¸¸ç”¨å‡½æ•°" class="headerlink" title="1.3 å­—ç¬¦ä¸²çš„è¿ç®—ä»¥åŠå¸¸ç”¨å‡½æ•°"></a>1.3 å­—ç¬¦ä¸²çš„è¿ç®—ä»¥åŠå¸¸ç”¨å‡½æ•°</h2><p><strong>è¿ç®—</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s1 + s2               <span class="comment"># å°†ä¸¤ä¸ªå­—ç¬¦ä¸²è¿æ¥</span></span><br><span class="line">s1*n                  <span class="comment"># å°†s1å¤åˆ¶næ¬¡</span></span><br><span class="line">s1 <span class="keyword">in</span> s2              <span class="comment"># å¦‚æœs1æ˜¯s2çš„å­—ä¸² åˆ™è¿”å› True å¦ False</span></span><br></pre></td></tr></table></figure><p><strong>å‡½æ•°</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">&#x27; Attention,Is,A,Talent &#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># splitå‡½æ•°</span></span><br><span class="line">s.split(<span class="string">&#x27;,&#x27;</span>)<span class="comment"># è¾“å‡ºä¸º [&#x27; Attention&#x27;, &#x27;Is&#x27;, &#x27;A&#x27;, &#x27;Talent &#x27;]</span></span><br><span class="line">                   <span class="comment"># splitå‡½æ•°ä»¥é€—å·ä¸ºæ ‡å¿—ï¼Œè¿”å›ä¸€ä¸ªåˆ†éš”åçš„åˆ—è¡¨</span></span><br><span class="line"><span class="comment"># countå‡½æ•°                   </span></span><br><span class="line">s.count(<span class="string">&#x27;A&#x27;</span>)                    <span class="comment"># ç»Ÿè®¡Aåœ¨sä¸­çš„æ¬¡æ•°ï¼Œæœ¬ä¾‹ä¸­å°†è¿”å›intç±»å‹çš„2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># upperï¼Œlowerå‡½æ•°</span></span><br><span class="line">s.upper() / s1.lower()          <span class="comment"># å°†å­—ç¬¦ä¸²è½¬åŒ–ä¸ºå¯¹åº”çš„å¤§å°å†™</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># replaceå‡½æ•°</span></span><br><span class="line">s.replace(<span class="string">&#x27;tion&#x27;</span>, <span class="string">&#x27;&#x27;</span>)  <span class="comment"># å°†å­—ç¬¦ä¸²ä¸­çš„&#x27;tion&#x27;æ›¿æ¢ä¸º&#x27;&#x27;ï¼Œå³æ²¡æœ‰ä¸œè¥¿ï¼Œç›¸å½“äºåˆ é™¤</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># centerå‡½æ•°</span></span><br><span class="line">s.center(<span class="number">30</span>, <span class="string">&#x27;=&#x27;</span>)               <span class="comment"># å°†sæ”¾åœ¨ä¸­é—´ï¼Œå·¦å³ä¸¤ä¾§å¹³å‡å¡«å……ç­‰äºå·è‡³æ€»å­—ç¬¦æ•°ä¸º30</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># stripå‡½æ•°</span></span><br><span class="line">s.strip(<span class="string">&#x27; &#x27;</span>)                    <span class="comment"># sä¸¤ä¾§åˆ é™¤ç©ºæ ¼ï¼Œä»¥åŠå…¶ä»–ä¸å¯è¯»ç¬¦å·å¦‚&#x27;\n&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># joinå‡½æ•°</span></span><br><span class="line"><span class="string">&#x27;,&#x27;</span>.join(s)                     <span class="comment"># sä¸­æ¯ä¸ªå­—ç¬¦é—´å¡«å……é€—å·</span></span><br><span class="line"><span class="comment"># è¿”å› &#x27;A,t,t,e,n,t,i,o,n,,,I,s,,,A,,,T,a,l,e,n,t&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># lenå‡½æ•°</span></span><br><span class="line"><span class="built_in">len</span>(s)<span class="comment"># è¿”å›sçš„é•¿åº¦</span></span><br></pre></td></tr></table></figure><ol><li>ä¸Šé¢æˆ‘ä»¬ä»¥é€—å·ä¸ºåˆ†éš”ç¬¦ä½¿ç”¨splitå‡½æ•°ï¼Œä½†æ˜¯æ³¨æ„<strong>ä¸­è‹±æ–‡çš„é€—å·æ˜¯æœ‰åŒºåˆ«çš„</strong>ï¼Œå…¶ä»–æœ‰äº›ç¬¦å·ä¹Ÿä¸€æ ·ï¼Œéœ€è¦æ³¨æ„ã€‚</li><li>ä¸Šè¿°ä¸­çš„replaceå‡ ä¹å¯ä»¥ä»£æ›¿centerå‡½æ•°ï¼Œä½†æ˜¯æ³¨æ„<strong>stripåªèƒ½å¤„ç†å­—ç¬¦ä¸²çš„ä¸¤ç«¯</strong></li><li>å¦‚joinå‡½æ•°è¿”å›çš„ç»“æœï¼Œå†æ¬¡æé†’ç©ºæ ¼ä¹Ÿç®—æ˜¯å­—ç¬¦</li><li>æœ€åï¼Œ<strong>ä¸Šè¿°æ“ä½œäº§ç”Ÿéƒ½æ˜¯ä¸€ä¸ªæ–°çš„å¯¹è±¡</strong>ï¼Œå³è°ƒç”¨såè¿”å›çš„æ˜¯åŸæœ¬çš„å­—ç¬¦ä¸²ï¼Œå¹¶ä¸æ˜¯å‡½æ•°ä½œç”¨åçš„ç»“æœã€‚<br>éœ€è¦<code>s = s.replace(&#39;tion&#39;, &#39;&#39;)  </code> èµ‹å€¼æ‰â€˜ç”Ÿæ•ˆâ€™ã€‚</li></ol><h2 id="1-4-æ•°å­—å‡½æ•°"><a href="#1-4-æ•°å­—å‡½æ•°" class="headerlink" title="1.4 æ•°å­—å‡½æ•°"></a>1.4 æ•°å­—å‡½æ•°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">pow</span>(x, n)    <span class="comment">#ä¸ºxçš„næ¬¡æ–¹</span></span><br><span class="line"><span class="built_in">divmod</span>(<span class="number">10</span>, <span class="number">3</span>)    <span class="comment"># è¾“å‡ºä¸ºï¼ˆ3ï¼Œ 1ï¼‰</span></span><br><span class="line"><span class="built_in">abs</span>()       <span class="comment">#è¿”å›å€¼ä¸ºç»å¯¹å€¼</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">int</span>(<span class="number">12.34</span>)   <span class="comment">#è¾“å‡º 12</span></span><br><span class="line"><span class="built_in">float</span>(<span class="number">12</span>), <span class="built_in">float</span>(<span class="string">&#x27;12.23&#x27;</span>)  <span class="comment">#è¾“å‡ºä¸º 12.0 å’Œ 12.23</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">round</span>(<span class="number">1.2345</span>ï¼Œ <span class="number">2</span>)   <span class="comment">#ä¿ç•™ä¸¤ä½å°æ•°</span></span><br><span class="line"><span class="built_in">max</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)   <span class="comment">#è¿”å›å€¼ä¸º3</span></span><br><span class="line"><span class="built_in">min</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)   <span class="comment">#è¿”å›å€¼ä¸º1</span></span><br></pre></td></tr></table></figure><h2 id="1-5-æ ¼å¼åŒ–å­—ç¬¦ä¸²"><a href="#1-5-æ ¼å¼åŒ–å­—ç¬¦ä¸²" class="headerlink" title="1.5 æ ¼å¼åŒ–å­—ç¬¦ä¸²"></a>1.5 æ ¼å¼åŒ–å­—ç¬¦ä¸²</h2><p>åœ¨æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªæ•°æ®ä¹‹åï¼Œç»å¸¸éœ€è¦å¯¹å…¶åšä¿ç•™å¤šå°‘ä½å°æ•°ã€å±…ä¸­æ‰“å°ã€é å³è¾“å‡ºã€ç­‰æ“ä½œï¼Œæˆ‘ä»¬ä¸€èˆ¬å«ä½¿å…¶æ ¼å¼åŒ–ã€‚åœ¨pythonä¸­æœ‰ä¸‰ç§æ ¼å¼åŒ–å¡«å……å­—ç¬¦ä¸²çš„æ–¹å¼ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># formatæ–¹å¼</span></span><br><span class="line">a, b, c = <span class="string">&#x27;Is&#x27;</span>, <span class="string">&#x27;Talent&#x27;</span>, <span class="number">0.12222</span></span><br><span class="line"><span class="string">&#x27;Attention &#123;a&#125; A &#123;b&#125; version &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(a, b, c)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æˆ‘ä»¬å°†å¾—åˆ°å¦‚ä¸‹è¾“å‡º &#x27;Attention Is A Talent version0.12&#x27;</span></span><br></pre></td></tr></table></figure><p>formatæ ¼å¼åŒ–å°†æŒ‰ç…§é¡ºåºå¡«å…¥ä¸Šé¢å­—ç¬¦ä¸²{}çš„ç©ºä½ï¼Œ{:.2f}è¡¨ç¤ºæ­¤å¤„ä¿ç•™ä¸¤ä½å°æ•°</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fæ–¹å¼</span></span><br><span class="line">a, b, c = <span class="string">&#x27;Is&#x27;</span>, <span class="string">&#x27;Talent&#x27;</span>, <span class="number">0.12222</span></span><br><span class="line"><span class="string">f&#x27;Attention <span class="subst">&#123;a&#125;</span> A <span class="subst">&#123;b&#125;</span> version <span class="subst">&#123;c:<span class="number">.2</span>f&#125;</span>&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æˆ‘ä»¬å°†å¾—åˆ°å¦‚ä¸‹è¾“å‡º &#x27;Attention Is A Talent version0.12&#x27;</span></span><br></pre></td></tr></table></figure><p>fæ ¼å¼åŒ–å°±æ˜¯å¯¹formatæ–¹å¼çš„ç®€åŒ–ç‰ˆ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># %æ–¹å¼</span></span><br><span class="line">a, b, c = <span class="string">&#x27;Is&#x27;</span>, <span class="string">&#x27;Talent&#x27;</span></span><br><span class="line"><span class="string">&#x27;Attention %s A %s &#x27;</span>% (<span class="string">&#x27;Is&#x27;</span>, <span class="string">&#x27;Talent&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æˆ‘ä»¬å°†å¾—åˆ°å¦‚ä¸‹è¾“å‡º &#x27;Attention Is A Talent &#x27;</span></span><br></pre></td></tr></table></figure><p>è¿™ç§æ–¹å¼å¾ˆè€äº†ï¼Œæ¨èä½¿ç”¨fæ–¹å¼ï¼Œéå¸¸ç®€æ´ã€‚</p><p><strong>ä»¥ä¸‹ä¸æ˜¯å¿…çœ‹å†…å®¹ï¼šformatå¡«å……æ–¹å¼</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chr</span>(Unicode)<span class="comment">#è¿”å›Unicodeå¯¹åº”çš„å­—ç¬¦</span></span><br><span class="line"><span class="built_in">ord</span>(<span class="string">&#x27;å­—&#x27;</span>)   <span class="comment">#è¿”å›å¯¹åº”çš„ç¼–ç ï¼Œå¦‚chr(ord(&#x27;a&#x27;)+i ) å³å¯éå†26å­—æ¯</span></span><br></pre></td></tr></table></figure><p><strong>å¡«å……ç‰©è‹¥ä¸ºchr(12222)ï¼Œç­‰ç‰¹æ®Šå­—ç¬¦</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">f&#x27;<span class="subst">&#123;<span class="built_in">chr</span>(<span class="number">12222</span>):^<span class="number">10</span>&#125;</span>&#x27;</span></span><br><span class="line"><span class="comment"># è¾“å‡ºä¸º &#x27;    â¾¾     &#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">f&#x27;&#x27;</span>&#123;<span class="built_in">chr</span>(<span class="number">12222</span>):=^<span class="number">10</span>&#125;<span class="string">&#x27;</span></span><br><span class="line"><span class="string">&#x27;</span>====â¾¾=====<span class="string">&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">f&#x27;</span><span class="string">&#x27;&#123;chr(12222):=&gt;10&#125;&#x27;</span></span><br><span class="line"><span class="string">&#x27;=========â¾¾&#x27;</span></span><br></pre></td></tr></table></figure><p>å¦‚ä¸Š{chr(12222):^10} å°†chr(12222)å¯¹åº”çš„å­—ç¬¦è¾“å‡ºåœ¨ä¸­é—´ï¼Œå·¦å³ä¸¤ä¾§å¡«å……ç©ºæ ¼ã€‚</p><p>ä¹Ÿå¯ç”¨ç­‰å·ç­‰å…¶ä»–ç¬¦å·å¡«å……ï¼Œæˆ–è€…ä½¿ç”¨&gt;å¤§äºå·ä½¿ç»“æœç½®å³ã€‚</p><h1 id="2-åˆ—è¡¨"><a href="#2-åˆ—è¡¨" class="headerlink" title="2. åˆ—è¡¨"></a>2. åˆ—è¡¨</h1><p>åˆ—è¡¨è·Ÿä¸Šæ–‡ä¸­æåˆ°çš„å­—ç¬¦ä¸²å¾ˆåƒï¼Œæˆ–è€…è¯´å­—ç¬¦ä¸²æ˜¯ä¸€ç§ç‰¹æ®Šçš„åˆ—è¡¨ï¼Œå…¶æ‰€æœ‰å…ƒç´ éƒ½æ˜¯å­—ç¬¦ä¸²ã€‚</p><p>pythonä¸­çš„åˆ—è¡¨ï¼ˆlistï¼‰ï¼Œåœ¨æˆ‘çš„å°è±¡é‡Œå‡ ä¹å¯ä»¥è£…ä»»ä½•çš„ä¸œè¥¿: å­—ç¬¦ä¸²ã€æ•°å­—ã€ç”šè‡³ä½ å®šä¹‰çš„å‡½æ•°â€¦</p><p><strong>åˆ—è¡¨æ˜¯ä¸€ç§éå¸¸å¥½ç”¨çš„æ•°æ®ç±»å‹ï¼Œä¹Ÿæ˜¯æˆ‘ä»¬æœ€å¸¸ä½¿ç”¨æ•°æ®ç±»å‹</strong>ï¼Œä»¥ä¸‹æ¦‚è¦å¯¹å…¶ç®€è¦ä»‹ç»å¹¶è¡¥å……å‡ ä¸ª<strong>åˆ¤æ–­ç¬¦</strong>ã€‚</p><h2 id="2-1-æ¦‚è¦"><a href="#2-1-æ¦‚è¦" class="headerlink" title="2.1 æ¦‚è¦"></a>2.1 æ¦‚è¦</h2><p>åˆ—è¡¨åŒå­—ç¬¦ä¸²ä¹Ÿæœ‰<strong>æ­£ååºå·ä¸‹æ ‡ï¼Œåˆ‡ç‰‡æ“ä½œ</strong>ï¼Œä¸åŒçš„æ˜¯åˆ—è¡¨å¯ä»¥å«æœ‰å„ç§ç±»å‹çš„æ•°æ®</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ls = [<span class="string">&#x27;Attention Is A Talent&#x27;</span>, <span class="number">100</span>, <span class="string">&#x27;% &#x27;</span>]</span><br><span class="line"></span><br><span class="line">ls[<span class="number">0</span>] == ls[-<span class="number">3</span>] <span class="comment"># è¿”å›True</span></span><br><span class="line"><span class="string">&#x27;A&#x27;</span> <span class="keyword">in</span> ls<span class="comment"># è¿”å›True</span></span><br><span class="line"><span class="built_in">str</span>(ls[<span class="number">1</span>]) + ls[<span class="number">2</span>] + ls[<span class="number">0</span>]<span class="comment"># &#x27;100% Attention Is A Talent&#x27;</span></span><br></pre></td></tr></table></figure><ul><li><p>ä¸Šé¢æˆ‘ä»¬ä½¿ç”¨<strong>åŒç­‰å·</strong>ä½œä¸ºåˆ¤æ–­ç¬¦ï¼Œç­‰ä»·è¯¢é—®python æ˜¯å¦ ls[0] &#x3D; ls[-3]</p><ul><li>è¿˜æœ‰ !&#x3D; ã€&gt;&#x3D;ã€&lt;&#x3D;ã€ç­‰</li></ul></li><li><p>ä¸Šé¢æˆ‘ä»¬ä½¿ç”¨<strong>in</strong>ä½œä¸ºåˆ¤æ–­è¯ï¼Œç­‰ä»·è¯¢é—®python æ˜¯å¦ â€˜Aâ€™ åœ¨ ls</p><ul><li>è¿˜æœ‰ not inï¼Œorï¼Œandç­‰</li></ul></li><li><p>ç¬¬äºŒç‚¹ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†str()ï¼Œå®ƒæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå°†å¯¹ä¼ ç»™å®ƒçš„å€¼åšå­—ç¬¦ä¸²åŒ–çš„å¤„ç†</p><ul><li>intç±»å‹çš„ 100 â€”â€”&gt; â€˜100â€™ å³æ•°å­—100å˜æˆå­—ç¬¦ä¸²äº†</li></ul></li></ul><h2 id="2-2-åˆ—è¡¨çš„è¿ç®—ä»¥åŠå¸¸ç”¨å‡½æ•°"><a href="#2-2-åˆ—è¡¨çš„è¿ç®—ä»¥åŠå¸¸ç”¨å‡½æ•°" class="headerlink" title="2.2 åˆ—è¡¨çš„è¿ç®—ä»¥åŠå¸¸ç”¨å‡½æ•°"></a>2.2 åˆ—è¡¨çš„è¿ç®—ä»¥åŠå¸¸ç”¨å‡½æ•°</h2><p><strong>è¿ç®—</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ls = [<span class="string">&#x27;Attention Is A Talent&#x27;</span>, <span class="number">100</span>, <span class="string">&#x27;% &#x27;</span>]</span><br><span class="line"></span><br><span class="line">ls * <span class="number">2</span> <span class="comment"># å°†è¿”å› [&#x27;Attention Is A Talent&#x27;, 100, &#x27;%&#x27;, &#x27;Attention Is A Talent&#x27;, 100, &#x27;%&#x27;]</span></span><br><span class="line"></span><br><span class="line">ls + ls[:<span class="number">1</span>]<span class="comment"># å°†è¿”å› [&#x27;Attention Is A Talent&#x27;, 100, &#x27;%&#x27;, &#x27;Attention Is A Talent&#x27;]</span></span><br></pre></td></tr></table></figure><ul><li>æ³¨æ„ï¼Œ<strong>åˆ—è¡¨çš„åŠ æ³•æ“ä½œåªèƒ½åœ¨åˆ—è¡¨è·Ÿåˆ—è¡¨ä¹‹é—´</strong>ã€‚<ul><li>å¦‚ä¸Šå›¾ä½¿ç”¨ ls + ls[0] å°†ä¼šæŠ¥é”™</li></ul></li></ul><p><strong>å‡½æ•°</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¸‹é¢xè¡¨ç¤ºå•ä¸ªå…ƒç´ ã€lsè¡¨ç¤ºåˆ—è¡¨0å·ã€ls1è¡¨ç¤ºåˆ—è¡¨1å·</span></span><br><span class="line"></span><br><span class="line">ls.append(x)<span class="comment"># ç»™lså°¾æ·»åŠ xå…ƒç´ </span></span><br><span class="line">ls.remove(x)<span class="comment"># å°†lsä¸­å‡ºç°çš„ç¬¬ä¸€ä¸ªxåˆ é™¤ï¼Œå¦‚è¦åˆ é™¤æ‰€æœ‰xå¯ä»¥ç”¨ï¼ˆwhile+flagï¼‰æˆ–è€…seté›†åˆç±»å‹é™¤é‡</span></span><br><span class="line">ls.extend(ls1)<span class="comment"># å°†lsåé¢è¿æ¥ls1</span></span><br><span class="line">ls.reverse()<span class="comment"># å°†åˆ—è¡¨çš„å…ƒç´ é€†ç½®</span></span><br><span class="line">ls.insert(i,x)<span class="comment"># åœ¨iä½ç½® æ’å…¥x</span></span><br><span class="line">ls.pop(i)<span class="comment"># iä½ç½®å…ƒç´ å‡ºæ ˆï¼Œåˆ é™¤</span></span><br></pre></td></tr></table></figure><p>(è¿™é‡ŒåŠ äº›åˆ—è¡¨å¤æ‚ä¸€ç‚¹çš„æ–¹æ³•ï¼Œå¦‚æœæ²¡æœ‰äº†è§£pythonä¸­çš„å­—å…¸ã€å…ƒç»„æ•°æ®ç±»å‹ï¼Œå¯ä»¥åœ¨ä¸‹æ–‡ä¸­äº†è§£åå†çœ‹)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ls = [(<span class="string">&#x27;tom&#x27;</span>, <span class="number">95</span>), (<span class="string">&#x27;jerry&#x27;</span>, <span class="number">80</span>), (<span class="string">&#x27;mike&#x27;</span>, <span class="number">99</span>), (<span class="string">&#x27;john&#x27;</span>, <span class="number">70</span>)]</span><br><span class="line">ls.sort()</span><br><span class="line">ls.sort(reverse = ture)<span class="comment"># é€†æ’åº</span></span><br><span class="line">ls.sort(key= <span class="keyword">lambda</span> x:x[<span class="number">1</span>])<span class="comment"># æŒ‰å€¼æ’åº </span></span><br><span class="line">-------------------------------</span><br><span class="line"></span><br><span class="line"><span class="built_in">sorted</span>(ls)<span class="comment"># ä¼šè‡ªåŠ¨æŠŠåºåˆ—ä»å°åˆ°å¤§æ’åº</span></span><br><span class="line"><span class="built_in">sorted</span>(ls, reverse = true)</span><br><span class="line"><span class="built_in">sorted</span>(ls, <span class="keyword">lambda</span> x:x[<span class="number">0</span>])<span class="comment"># ä»¥lambdaå‡½æ•°ä½œä¸ºå€¼æ’åº</span></span><br><span class="line">-------------------------------</span><br><span class="line"></span><br><span class="line">seasons = [<span class="string">&#x27;Spring&#x27;</span>, <span class="string">&#x27;Summer&#x27;</span>, <span class="string">&#x27;Fall&#x27;</span>, <span class="string">&#x27;Winter&#x27;</span>]<span class="comment"># enumerate()çš„å¯¹è±¡å¿…é¡»æ˜¯å¯ä»¥è¿­ä»£çš„ç±»å‹(iterable)</span></span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">enumerate</span>(seasons))</span><br><span class="line">[(<span class="number">0</span>, <span class="string">&#x27;Spring&#x27;</span>), (<span class="number">1</span>, <span class="string">&#x27;Summer&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;Fall&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;Winter&#x27;</span>)]</span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">enumerate</span>(seasons, start=<span class="number">1</span>))</span><br><span class="line">[(<span class="number">1</span>, <span class="string">&#x27;Spring&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;Summer&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;Fall&#x27;</span>), (<span class="number">4</span>, <span class="string">&#x27;Winter&#x27;</span>)]</span><br></pre></td></tr></table></figure><ul><li><p>ç¬¬ä¸€éƒ¨åˆ†ä¸­ä¸º<strong>lsçš„sortæ–¹æ³•</strong>é…ç½®å‚æ•°</p><ul><li>reverse è¡¨ç¤ºé€†ç½®ï¼Œå¦‚æœå¯¹è±¡æ²¡æœ‰â€˜å¤§å°â€™ï¼Œåˆ™æŒ‰ç…§åŸæ¥çš„é¡ºåºç›´æ¥é€†ç½®</li><li>key å‚æ•°è¡¨ç¤ºæ’åºæ ¹æ®æ­¤å€¼çš„å¤§å°ï¼Œè¿™é‡Œæˆ‘ä»¬å°±æ˜¯ä»¥æ¯ä¸ªå…ƒç»„çš„ç¬¬äºŒä¸ªå€¼ä½œä¸ºvalueæ’åº</li></ul></li><li><p>ç¬¬äºŒéƒ¨åˆ†æ˜¯ä½¿ç”¨<strong>pythonä¸­çš„sortedå’Œsortå‡½æ•°</strong></p><ul><li><p>ç¬¬ä¸€ä¸ªå‚æ•°è¡¨ç¤ºä¼ å…¥çš„å¯è¿­ä»£æ•°æ®ç±»å‹(å°±æ˜¯åˆ—è¡¨è¿™ç§å«æœ‰å¾ˆå¤šå…ƒç´ ï¼Œå¯ä»¥ä¸€ä¸ªä¸€ä¸ªå‡ºæ¥çš„æ•°æ®ç±»å‹)</p></li><li><p>ç¬¬äºŒä¸ªå‚æ•° åŒä¸Šé¢çš„key</p></li><li><blockquote><p><strong>sort ä¸ sorted åŒºåˆ«ï¼š</strong></p><p>sort æ˜¯åº”ç”¨åœ¨ list ä¸Šçš„æ–¹æ³•ï¼Œsorted å¯ä»¥å¯¹æ‰€æœ‰å¯è¿­ä»£çš„å¯¹è±¡è¿›è¡Œæ’åºæ“ä½œã€‚</p><p>list çš„ sort æ–¹æ³•è¿”å›çš„æ˜¯å¯¹å·²ç»å­˜åœ¨çš„åˆ—è¡¨è¿›è¡Œæ“ä½œï¼Œæ— è¿”å›å€¼ï¼Œè€Œå†…å»ºå‡½æ•° sorted æ–¹æ³•è¿”å›çš„æ˜¯ä¸€ä¸ªæ–°çš„ listï¼Œè€Œä¸æ˜¯åœ¨åŸæ¥çš„åŸºç¡€ä¸Šè¿›è¡Œçš„æ“ä½œã€‚</p></blockquote></li></ul></li><li><p>ç¬¬ä¸‰éƒ¨åˆ†ä½¿ç”¨äº†<strong>enumerateå‡½æ•°</strong>ï¼Œè¿™ä¸ªå‡½æ•°ä¸»è¦æ˜¯ä¸ºå…ƒç´ æ·»åŠ ä¸‹æ ‡ï¼Œæ–¹ä¾¿ä¸€äº›ç‰¹æ®Šåœºæ™¯å¤„ç†</p><ul><li>enumerateå‡½æ•°è¿”å›ä¸€ä¸ªå«æœ‰ä½ç½®ä¸‹æ ‡çš„å…ƒç»„ç±»å‹ï¼Œä¸º(indexï¼Œelement)å½¢å¼</li></ul></li></ul><h2 id="2-3-åˆ—è¡¨åº”ç”¨çš„ä¾‹å­"><a href="#2-3-åˆ—è¡¨åº”ç”¨çš„ä¾‹å­" class="headerlink" title="2.3 åˆ—è¡¨åº”ç”¨çš„ä¾‹å­"></a>2.3 åˆ—è¡¨åº”ç”¨çš„ä¾‹å­</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ls = [<span class="string">&#x27;Alice&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>]</span><br><span class="line"><span class="built_in">list</span>(lt) = ls[<span class="number">0</span>]<span class="comment"># [0]å·ä¸ºå­—ç¬¦ï¼Œå¯¼å…¥listä¸­ä¼šåˆ†å‰²æˆ[&#x27;a&#x27;, &#x27;l&#x27;, &#x27;i&#x27;, &#x27;c&#x27;, &#x27;e&#x27;]</span></span><br><span class="line">------------------------------------</span><br><span class="line">ls = [<span class="string">&#x27;Ali:ce&#x27;</span>, <span class="string">&#x27;Bo:b&#x27;</span>]</span><br><span class="line">lt = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> ls:</span><br><span class="line">    elem = i.split(<span class="string">&#x27;:&#x27;</span>)[-<span class="number">1</span>]<span class="comment"># ls[i]ä¸ºå­—ç¬¦ä¸²ä½¿ç”¨splitåˆ†å‰²-&gt;[&#x27;Ali&#x27;,&#x27;ce&#x27;]å–[-1]</span></span><br><span class="line">    lt.append(elem)<span class="comment"># ç›´æ¥+=ä¼šå˜æˆ[&#x27;c&#x27;,&#x27;e&#x27;],æ‰€ä»¥ä½¿ç”¨listçš„append,åˆ™ç›´æ¥å°†strçš„ceåŠ å…¥</span></span><br><span class="line"><span class="comment"># lt = [ce, b]  å¹²å‡€çš„å­—ç¬¦ä¸²åˆ—è¡¨</span></span><br></pre></td></tr></table></figure><h1 id="3-å­—å…¸"><a href="#3-å­—å…¸" class="headerlink" title="3. å­—å…¸"></a>3. å­—å…¸</h1><p>Pythonå­—å…¸ï¼ˆdictï¼‰æ˜¯å¦ä¸€ç§<strong>å¯å˜å®¹å™¨æ¨¡å‹</strong>,å¯å­˜å‚¨ä»»æ„ç±»å‹å¯¹è±¡ã€‚å¦‚å­—ç¬¦ä¸²ã€æ•°å­—ã€å…ƒç»„ç­‰å…¶ä»–å®¹å™¨æ¨¡å‹<br><strong>å› ä¸ºå­—å…¸æ˜¯æ— åºçš„æ‰€ä»¥ä¸æ”¯æŒç´¢å¼•å’Œåˆ‡ç‰‡</strong></p><p>æ³¨æ„ï¼š</p><ul><li>keyä¸å¯ä»¥é‡å¤,å¦åˆ™åªä¼šä¿ç•™ç¬¬ä¸€ä¸ª;</li><li>valueå€¼å¯ä»¥é‡å¤;</li><li>keyå¯ä»¥æ˜¯ä»»æ„çš„æ•°æ®ç±»å‹,ä½†ä¸èƒ½å‡ºç°å¯å˜çš„æ•°æ®ç±»å‹,ä¿è¯keyå”¯ä¸€;</li><li>keyä¸€èˆ¬å½¢å¼ä¸ºå­—ç¬¦ä¸²ã€‚</li></ul><h2 id="3-1-åŸºæœ¬å±æ€§"><a href="#3-1-åŸºæœ¬å±æ€§" class="headerlink" title="3.1 åŸºæœ¬å±æ€§"></a>3.1 åŸºæœ¬å±æ€§</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dic.keys()<span class="comment"># è¿”å›å­—å…¸ä¸­æ‰€æœ‰çš„key</span></span><br><span class="line">dic.values()<span class="comment"># è¿”å›åŒ…å«valueçš„åˆ—è¡¨</span></span><br><span class="line">dic.items()<span class="comment"># è¿”å›åŒ…å«(é”®å€¼,å®å€¼)å…ƒç»„çš„åˆ—è¡¨</span></span><br></pre></td></tr></table></figure><h2 id="3-2-åŸºæœ¬å‡½æ•°"><a href="#3-2-åŸºæœ¬å‡½æ•°" class="headerlink" title="3.2 åŸºæœ¬å‡½æ•°"></a>3.2 åŸºæœ¬å‡½æ•°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">dic.setdefault(k,value)</span><br><span class="line"><span class="comment">#å¦‚æœkeyå€¼å­˜åœ¨,é‚£ä¹ˆè¿”å›å¯¹åº”å­—å…¸çš„value,ä¸ä¼šç”¨åˆ°è‡ªå·±è®¾ç½®çš„value;</span></span><br><span class="line"><span class="comment">#å¦‚æœkeyå€¼ä¸å­˜åœ¨.è¿”å›None,å¹¶ä¸”æŠŠæ–°è®¾ç½®çš„keyå’Œvalueä¿å­˜åœ¨å­—å…¸ä¸­;</span></span><br><span class="line"><span class="comment">#å¦‚æœkeyå€¼ä¸å­˜åœ¨,ä½†è®¾ç½®äº†value,åˆ™è¿”å›è®¾ç½®çš„value;</span></span><br><span class="line"></span><br><span class="line">dic.get(k,value)</span><br><span class="line"><span class="comment">#å¦‚æœkeyå€¼å­˜åœ¨,é‚£ä¹ˆè¿”å›å¯¹åº”å­—å…¸çš„value,ä¸ä¼šç”¨åˆ°è‡ªå·±è®¾ç½®çš„value;</span></span><br><span class="line"><span class="comment">#å¦‚æœkeyå€¼ä¸å­˜åœ¨.è¿”å›None,ä½†æ˜¯ä¸ä¼šæŠŠæ–°è®¾ç½®çš„keyå’Œvalueä¿å­˜åœ¨å­—å…¸ä¸­;</span></span><br><span class="line"><span class="comment">#å¦‚æœkeyå€¼ä¸å­˜åœ¨,ä½†è®¾ç½®äº†value,åˆ™è¿”å›è®¾ç½®çš„value;</span></span><br><span class="line"></span><br><span class="line">dic.items()</span><br><span class="line"><span class="comment">#æ‰“å°å­—å…¸ä¸­çš„æ‰€æœ‰å…ƒç»„</span></span><br></pre></td></tr></table></figure><p><strong>ä»¥ä¸‹ä¸æ˜¯å¿…çœ‹å†…å®¹ï¼šdic.get(key, init_value)</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ls = [(<span class="string">&#x27;tom&#x27;</span>, <span class="number">95</span>), (<span class="string">&#x27;tom&#x27;</span>, <span class="number">95</span>), (<span class="string">&#x27;tom&#x27;</span>, <span class="number">95</span>), (<span class="string">&#x27;jerry&#x27;</span>, <span class="number">80</span>), (<span class="string">&#x27;mike&#x27;</span>, <span class="number">99</span>), (<span class="string">&#x27;john&#x27;</span>, <span class="number">70</span>)]</span><br><span class="line"></span><br><span class="line">ls1,dic = [], &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i, j <span class="keyword">in</span> ls:</span><br><span class="line">    ls1.append(i)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i  <span class="keyword">in</span> ls1:</span><br><span class="line">dic[i] = dic.get(i, <span class="number">0</span>) + <span class="number">1</span>         </span><br><span class="line">dic</span><br></pre></td></tr></table></figure><p>getç¬¬ä¸€ä¸ªå‚æ•°ä¸ºå¯¹åº”çš„é”®ï¼Œç¬¬äºŒä¸ªå‚æ•°ä¸ºé”®å¯¹åº”çš„åˆå§‹å€¼ã€‚</p><p>getæ–¹æ³•å°†é”®å¯¹åº”çš„å€¼åˆå§‹åŒ–ä¸º0ï¼Œä»¥åæ¯è§ä¸€æ¬¡åŠ ä¸€æ¬¡ï¼Œåœ¨æ–‡æœ¬ç»Ÿè®¡æ—¶ç»å¸¸ä½¿ç”¨ã€‚</p><p>ç›¸å¯¹äºdic[i]ï¼Œdic.get(i)ä¸ä¼šæŠ¥é”™ï¼Œè€Œå®ƒæ¯è§ä¸€æ¬¡åŠ ä¸€æ¬¡è€Œä¸æ˜¯è¦†ç›–ï¼Œæ˜æ˜¾é€Ÿåº¦ä¼šæ¯”å‰è€…æ…¢ã€‚(ä½†æ˜¯ä¸æ˜¯å¤§é‡æ•°æ®éƒ½å·®ä¸å¤šã€‚)</p><h1 id="4-é›†åˆ"><a href="#4-é›†åˆ" class="headerlink" title="4.é›†åˆ"></a>4.é›†åˆ</h1><p>åœ¨Pythonä¸­é›†åˆï¼ˆsetï¼‰å…ƒç´ ä¹‹é—´æ— åºï¼Œ<strong>æ¯ä¸ªå…ƒç´ å”¯ä¸€</strong>ï¼Œä¸å­˜åœ¨ç›¸åŒå…ƒç´ <strong>é›†åˆå…ƒç´ ä¸å¯æ›´æ”¹</strong>ï¼Œä¸èƒ½æ˜¯å¯å˜æ•°æ®ç±»å‹</p><h2 id="4-1-åˆ›å»ºå’Œè¿ç®—"><a href="#4-1-åˆ›å»ºå’Œè¿ç®—" class="headerlink" title="4.1 åˆ›å»ºå’Œè¿ç®—"></a>4.1 åˆ›å»ºå’Œè¿ç®—</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ä½¿ç”¨ä¸¤ç§æ–¹å¼å»ºç«‹</span><br><span class="line">A = &#123;<span class="string">&quot;python&quot;</span>, <span class="number">123</span>, (<span class="string">&quot;python&quot;</span>,<span class="number">123</span>)&#125; <span class="comment"># ä½¿ç”¨&#123;&#125;å»ºç«‹é›†åˆ</span></span><br><span class="line">è¾“å‡ºä¸º&#123;<span class="number">123</span>, <span class="string">&#x27;python&#x27;</span>, (<span class="string">&#x27;python&#x27;</span>, <span class="number">123</span>)&#125;</span><br><span class="line">B = <span class="built_in">set</span>(<span class="string">&quot;pypy123&quot;</span>) <span class="comment"># ä½¿ç”¨set()å»ºç«‹é›†åˆ</span></span><br><span class="line">è¾“å‡ºä¸º&#123;<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;p&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;y&#x27;</span>&#125;</span><br><span class="line">C = &#123;<span class="string">&quot;python&quot;</span>, <span class="number">123</span>, <span class="string">&quot;python&quot;</span>,<span class="number">123</span>&#125;<span class="comment"># å»é‡</span></span><br><span class="line">è¾“å‡ºä¸º&#123;<span class="string">&#x27;python&#x27;</span>, <span class="number">123</span>&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">S | T å¹¶ï¼Œè¿”å›ä¸€ä¸ªæ–°é›†åˆï¼ŒåŒ…æ‹¬åœ¨é›†åˆSå’ŒTä¸­çš„æ‰€æœ‰å…ƒç´  </span><br><span class="line">S - T å·®ï¼Œè¿”å›ä¸€ä¸ªæ–°é›†åˆï¼ŒåŒ…æ‹¬åœ¨é›†åˆSä½†ä¸åœ¨Tä¸­çš„å…ƒç´  </span><br><span class="line">S &amp; T äº¤ï¼Œè¿”å›ä¸€ä¸ªæ–°é›†åˆï¼ŒåŒ…æ‹¬åŒæ—¶åœ¨é›†åˆSå’ŒTä¸­çš„å…ƒç´  </span><br><span class="line">S ^ T è¡¥ï¼Œè¿”å›ä¸€ä¸ªæ–°é›†åˆï¼ŒåŒ…æ‹¬é›†åˆSå’ŒTä¸­çš„éç›¸åŒå…ƒç´  </span><br><span class="line">S &lt;= T æˆ– S &lt; T     è¿”å›<span class="literal">True</span>/<span class="literal">False</span>ï¼Œåˆ¤æ–­Så’ŒTçš„å­é›†å…³ç³» </span><br><span class="line">S &gt;= T æˆ– S &gt; T     è¿”å›<span class="literal">True</span>/<span class="literal">False</span>ï¼Œåˆ¤æ–­Så’ŒTçš„åŒ…å«å…³ç³»</span><br></pre></td></tr></table></figure><h2 id="4-2-å‡½æ•°"><a href="#4-2-å‡½æ•°" class="headerlink" title="4.2 å‡½æ•°"></a>4.2 å‡½æ•°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(s) <span class="comment">#è¿”å›åºåˆ—sçš„é•¿åº¦ï¼Œå³å…ƒç´ ä¸ªæ•°</span></span><br><span class="line"><span class="built_in">min</span>(s) <span class="comment">#è¿”å›åºåˆ—sçš„æœ€å°å…ƒç´ ï¼Œsä¸­å…ƒç´ éœ€è¦å¯æ¯”è¾ƒ</span></span><br><span class="line"><span class="built_in">max</span>(s) <span class="comment">#è¿”å›åºåˆ—sçš„æœ€å¤§å…ƒç´ ï¼Œsä¸­å…ƒç´ éœ€è¦å¯æ¯”è¾ƒ</span></span><br><span class="line">s.index(x) / s.index(x, i, j)     <span class="comment">#è¿”å›åºåˆ—sä»iå¼€å§‹åˆ°jä½ç½®ä¸­ç¬¬ä¸€æ¬¡å‡ºç°å…ƒç´ xçš„ä½ç½®</span></span><br><span class="line">s.count(x) <span class="comment">#è¿”å›åºåˆ—sä¸­å‡ºç°xçš„æ€»æ¬¡æ•°</span></span><br></pre></td></tr></table></figure><p>å…¶ä¸­len()ã€min()ã€max()å‡½æ•°æ˜¯å†…ç½®çš„é€šç”¨å‡½æ•°</p><h1 id="5-å…ƒç»„"><a href="#5-å…ƒç»„" class="headerlink" title="5. å…ƒç»„"></a>5. å…ƒç»„</h1><p>pythonä¸­çš„å…ƒç»„ï¼ˆtupleï¼‰æ˜¯ä¸€ç§åºåˆ—ç±»å‹ï¼Œä¸€æ—¦åˆ›å»ºå°±<strong>ä¸èƒ½è¢«ä¿®æ”¹</strong> ï¼Œä½¿ç”¨<strong>å°æ‹¬å· () æˆ– tuple() åˆ›å»º</strong>ï¼Œå…ƒç´ é—´ç”¨é€—å· , åˆ†éš” ã€‚</p><h2 id="5-1-åˆ›å»ºå’Œå–å€¼"><a href="#5-1-åˆ›å»ºå’Œå–å€¼" class="headerlink" title="5.1 åˆ›å»ºå’Œå–å€¼"></a>5.1 åˆ›å»ºå’Œå–å€¼</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">creature = <span class="string">&quot;cat&quot;</span>,<span class="string">&quot;dog&quot;</span>,<span class="string">&quot;tiger&quot;</span>,<span class="string">&quot;human&quot;</span></span><br><span class="line">creature = (<span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;tiger&#x27;</span>, <span class="string">&#x27;human&#x27;</span>) <span class="comment"># å¯ä»¥ä½¿ç”¨æ‹¬å·å’Œä¸å¸¦æ‹¬å·çš„ä¸¤ä¸¤ç§</span></span><br><span class="line">color = (<span class="number">0x001100</span>, <span class="string">&quot;blue&quot;</span>, creature)<span class="comment"># è¾“å‡ºä¼šå¾—åˆ°ï¼ˆï¼Œï¼Œï¼ˆï¼‰ï¼‰</span></span><br></pre></td></tr></table></figure><p>å…ƒç»„çš„å–å€¼æ“ä½œè·Ÿåˆ—è¡¨ä¸€æ ·</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">creature = <span class="string">&quot;cat&quot;</span>,<span class="string">&quot;dog&quot;</span>,<span class="string">&quot;tiger&quot;</span>,<span class="string">&quot;human&quot;</span></span><br><span class="line">creature[::-<span class="number">1</span>]<span class="comment"># è¾“å‡ºä¸º(&#x27;human&#x27;, &#x27;tiger&#x27;, &#x27;dog&#x27;, &#x27;cat&#x27;)</span></span><br><span class="line">color = (<span class="number">0x001100</span>, <span class="string">&quot;blue&quot;</span>, creature)</span><br><span class="line">color[-<span class="number">1</span>][<span class="number">2</span>]<span class="comment"># è¾“å‡ºä¸º&#x27;tiger&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="5-2-å‡½æ•°"><a href="#5-2-å‡½æ•°" class="headerlink" title="5.2 å‡½æ•°"></a>5.2 å‡½æ•°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span>(x) <span class="comment"># å°†å…¶ä»–ç±»å‹å˜é‡xè½¬å˜ä¸ºé›†åˆç±»å‹</span></span><br><span class="line">t.discard(x)     <span class="comment"># ç§»é™¤Sä¸­å…ƒç´ xï¼Œå¦‚æœxä¸åœ¨é›†åˆSä¸­ï¼Œä¸æŠ¥é”™</span></span><br><span class="line">t.remove(x) <span class="comment"># ç§»é™¤Sä¸­å…ƒç´ xï¼Œå¦‚æœxä¸åœ¨é›†åˆSä¸­ï¼Œäº§ç”ŸKeyErrorå¼‚å¸¸</span></span><br><span class="line">t.pop() <span class="comment"># éšæœºè¿”å›Sçš„ä¸€ä¸ªå…ƒç´ ï¼Œæ›´æ–°Sï¼Œè‹¥Sä¸ºç©ºäº§ç”ŸKeyErrorå¼‚å¸¸</span></span><br><span class="line">t.add(x) <span class="comment"># å¦‚æœxä¸åœ¨é›†åˆSä¸­ï¼Œå°†xå¢åŠ åˆ°S</span></span><br><span class="line">t.clear() <span class="comment"># ç§»é™¤Sä¸­æ‰€æœ‰å…ƒç´ </span></span><br><span class="line">x <span class="keyword">in</span> t<span class="comment"># åˆ¤æ–­Sä¸­å…ƒç´ xï¼Œxåœ¨é›†åˆSä¸­ï¼Œè¿”å›Trueï¼Œå¦åˆ™è¿”å›False</span></span><br><span class="line">x <span class="keyword">not</span> <span class="keyword">in</span> t <span class="comment"># åˆ¤æ–­Sä¸­å…ƒç´ xï¼Œxä¸åœ¨é›†åˆSä¸­ï¼Œè¿”å›Trueï¼Œå¦åˆ™è¿”å›False</span></span><br><span class="line">t.copy() <span class="comment"># è¿”å›é›†åˆSçš„ä¸€ä¸ªå‰¯æœ¬</span></span><br><span class="line"><span class="built_in">len</span>(t) <span class="comment"># è¿”å›é›†åˆSçš„å…ƒç´ ä¸ªæ•°</span></span><br></pre></td></tr></table></figure><h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><ul><li><p>åŒä¸Šæ–‡æˆ‘ä»¬å®šä¹‰çš„å­—ç¬¦ä¸²ã€åˆ—è¡¨ã€å­—å…¸ï¼Œæˆ‘ä»¬æŒ‰ç…§<strong>è§åçŸ¥æ„</strong>çš„åŸåˆ™ï¼Œå°†å…¶èµ‹å€¼ç»™sã€lsã€dicã€‚è¿™æ ·åšæ˜¯ä¸ºäº†ç¨‹åºçš„å¯è¯»æ€§ã€‚ä»Šåæˆ‘ä»¬åœ¨å†™ç¨‹åºçš„æ—¶å€™ä¼šå®šä¹‰å¾ˆå¤šå˜é‡ï¼Œå˜é‡ä¸€å¤šäº†å°±å®¹æ˜“ææ··äº†ï¼Œé¡ºè—¤æ‘¸ç“œæ‰¾ç€æ•ˆç‡åˆå¾ˆä½ï¼Œæ‰€ä»¥ç»™ä½ çš„å˜é‡å–ä¸€ä¸ªå¥½åå­—ï¼Œæ˜¯ä¸€ä¸ªå¾ˆåˆ’ç®—çš„å†³å®šã€‚</p><ul><li>ä¸¾ä¸ªä¾‹å­<code>train_df = pandas.DataFrame(&#39;../train.csv&#39;)</code>ä¸­çš„ train_dfè¡¨ç¤ºè¿™ä¸ªæ˜¯ä¸ªè®­ç»ƒæ•°æ®ï¼Œå…¶æ•°æ®ç±»å‹ä¸ºpandasçš„DataFrameç»“æ„ã€‚</li></ul></li><li><p>æ­¤å¤–åœ¨æ“ä½œæ•°æ®çš„æ—¶å€™ä¸€å®šè¦æ³¨æ„æ•°æ®ç±»å‹ï¼Œæ ¹æ®æ•°æ®çš„ç‰¹æ€§é€‰æ‹©åˆé€‚çš„æ•°æ®ç±»å‹ã€‚</p></li><li><p>æœ€åï¼Œpythonæœ€å¥½ç”¨çš„åœ°æ–¹åœ¨äºæœ‰å„ç§å„æ ·çš„åº“ä¾›ä½ é€‰æ‹©ï¼Œè€ŒæŒæ¡å®ƒåŸºç¡€çš„æ•°æ®ç»“æ„æ˜¯ç¬¬ä¸€æ­¥ï¼Œä¸‹é¢æˆ‘ä»¬å°†è®²è§£å‡½æ•°ä»¥åŠç±»ï¼Œæœ€åä»‹ç»ä¸¤ä¸ªå¸¸ç”¨çš„åº“ï¼Œä»‹ç»ä¸€äº›å¦‚ä½•å¿«é€ŸæŒæ¡ä¸€ä¸ªåº“çš„é€šæ³•ã€‚</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pythonåŸºç¡€ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformer &amp; Self-Attention</title>
      <link href="/posts/4330.html"/>
      <url>/posts/4330.html</url>
      
        <content type="html"><![CDATA[<h1 id="å¾…å®Œæˆ"><a href="#å¾…å®Œæˆ" class="headerlink" title="å¾…å®Œæˆ"></a>å¾…å®Œæˆ</h1><ul><li>å¤±æ•ˆå›¾ç‰‡å¤„ç†</li></ul><p><a href="https://jalammar.github.io/illustrated-transformer/">é˜¿ä¸‰åšå®¢åœ°å€</a></p><ul><li><p><a href="https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.999.0.0&vd_source=6997c0a04f6a78d03d30de86e9b949d9">ææ²è€å¸ˆ 48åˆ†é’Ÿè®²è§£ encoder-decoderä¸­(KVâ€“Q)çš„è¿ç®—</a>: </p><ul><li><p><strong>KQç›¸ä¹˜å°±æ˜¯å•ä¸ªqå¯¹æ‰€æœ‰kçš„ç›¸ä¼¼åº¦ä½œä¸ºattention score(ç»™è¿™ä¸ªKå€¼å¤šå°‘æ³¨æ„åŠ›)ï¼Œä¸å•ä¸ªvåšåŠ æƒå’Œ(æƒå€¼æ¥è‡ªKQ)</strong></p><p>å†é€šè¿‡<strong>æ³¨æ„åŠ›åˆ†æ•°</strong>ä¸<strong>Vå‘é‡ç›¸ä¹˜</strong>ï¼Œ<strong>å¾—åˆ°æ¯ä¸ªVåº”è¯¥å¤šå¤§çš„ç¼©æ”¾</strong>ï¼Œ è¿›è¡Œç›¸åŠ åå°±å¾—åˆ°äº†æœ€ç»ˆVåº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­äº†</p></li></ul></li></ul><p><a href="https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.999.0.0&vd_source=6997c0a04f6a78d03d30de86e9b949d9">ææ²è€å¸ˆ 56åˆ† å¯¹multi-headè¾“å‡ºå’Œlinearå±‚ç›¸è¾ƒäºRNNçš„è®²è§£</a>ï¼š</p><ul><li><p>è¯å‘é‡ç»è¿‡Attentionå±‚æŠ“å–å…¨å±€ä¿¡æ¯ï¼Œæ±‡èšä¹‹åï¼Œåœ¨æ¯ä¸ªç‚¹ä¸Šéƒ½æœ‰äº†æ‰€éœ€è¦çš„ä¿¡æ¯</p><p>(æƒé‡ä¸åŒï¼Œæ¯ä¸ªè¾“å‡ºçš„å‘é‡çš„é‡ç‚¹åœ¨ä¸åŒçš„positionç¼–ç ä½ç½®ä¸Š)ï¼Œå› æ­¤åªéœ€è¦åšlinear transformationã€‚</p></li><li><p><strong>bertä¸­transformerå‚æ•°è®¡ç®—</strong>:</p></li></ul><blockquote><p>embedding: vocab_size&#x3D;30522, max_position_embeddings&#x3D;512, token_type_embeddings&#x3D;2(å°±è¿›è¡Œä¸¤å¥åˆ†åˆ«æ ‡è®°ï¼Œå¤šäº†æˆªæ–­)</p><p>â€‹ï¼ˆ30522+512+2ï¼‰*768 &#x3D; 23835648 (23M)</p><p>self-attention: 768&#x2F;12 &#x3D; 64 (å¤šå¤´æ¯å¤´åˆ†64ç»´åº¦çš„å‘é‡) ï¼Œ64*768(æ¯ä¸ª64æ˜ å°„å›768)ï¼ŒQKVä¸‰ä¸ªçŸ©é˜µ, </p><p>â€‹  æœ€åä¸€å±‚ 786(64 *12çš„æ‹¼æ¥)-&gt;768çš„çº¿æ€§å˜æ¢</p><p>â€‹(768&#x2F;12 * 768 <em>3 ) * 12 + (768</em>768) &#x3D; 2359296</p><p>â€‹ç»è¿‡12ä¸ªtransformer</p><p>â€‹2359296*12 &#x3D; 28311552 (28M)</p><p>feedfoward: è‡ªæ³¨æ„åŠ›å±‚ä¹‹å åˆ†åˆ«åœ¨ encoder å’Œ decoder ä¸­æœ‰ä¸ªä¸€ä¸ªå…¨è¿æ¥å±‚</p><p>â€‹ç»´åº¦ä» 768-&gt;4*768_768-&gt;768</p><p>â€‹(768*4 * 768 )*2 &#x3D; 4718592</p><p>â€‹(768*4 * 768 )*2  * 12 &#x3D; 56623104 (56M)</p><p>layernorm: æœ‰ä¼½é©¬å’Œè´å¡”ä¸¤ä¸ªå‚æ•°ï¼Œembeddingå±‚ï¼ˆ768 * 2ï¼‰ï¼Œ12å±‚çš„self-attentionï¼Œ</p><p>â€‹768 * 2 + 768 * 2 * 2 * 12 &#x3D; 38400</p><p>æ€»è®¡: 23835648+28311552+56623104+38400 &#x3D; 108808704      (108M)</p><p>æ¯ä¸€å±‚çš„å‚æ•°ä¸º:  å¤šå¤´æ³¨æ„åŠ›çš„å‚æ•° + æ‹¼æ¥çº¿æ€§å˜æ¢çš„å‚æ•° + feed-forwardçš„å‚æ•° + layer-normçš„å‚æ•°</p><p>768 * 768 &#x2F; 12 * 3 * 12 + 768 * 768 + 768 * 3072 * 2 + 768 * 2 * 2 &#x3D; 7080960  (7M)</p></blockquote><h1 id="Encoder-ç¼–ç é˜¶æ®µ"><a href="#Encoder-ç¼–ç é˜¶æ®µ" class="headerlink" title="Encoder ç¼–ç é˜¶æ®µ"></a>Encoder ç¼–ç é˜¶æ®µ</h1><h2 id="Multi-head-Attention"><a href="#Multi-head-Attention" class="headerlink" title="Multi-head Attention"></a>Multi-head Attention</h2><p>å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å°†ä¸€ä¸ªè¯å‘é‡ç•™è¿‡å…«ä¸ª self-attention å¤´ç”Ÿæˆå…«ä¸ªè¯å‘é‡ vectorï¼Œ</p><p>å°†å…«ä¸ªè¯å‘é‡æ‹¼æ¥ï¼Œé€šè¿‡ fc å±‚è¿›è¡Œ softmax è¾“å‡ºã€‚</p><p>ä¾‹å¦‚ï¼š</p><p>è¯å‘é‡ä¸º (1,4) â€“&gt; </p><p>ç»è¿‡ QKV çŸ©é˜µ(ç³»æ•°) å¾—åˆ° (1,3) å…«ä¸ª (1,3)*8 â€“&gt;</p><p>å°†è¾“å‡ºæ‹¼æ¥æˆ (8,3) çŸ©é˜µä¸å…¨è¿æ¥å±‚çš„ç³»æ•°çŸ©é˜µè¿›è¡Œç›¸ä¹˜å† softmax <strong>ç¡®å®šæœ€åè¾“å‡ºçš„</strong> è¯å‘é‡ â€“&gt; (1,4)</p><h3 id="æ³¨æ„-QKVçŸ©é˜µæ€ä¹ˆæ¥çš„-attentionåˆ†æ•°-ï¼Œæœ€åä¸ºä»€ä¹ˆè¦æ‹¼æ¥ï¼Œä»¥åŠFCå±‚çš„ç³»æ•°"><a href="#æ³¨æ„-QKVçŸ©é˜µæ€ä¹ˆæ¥çš„-attentionåˆ†æ•°-ï¼Œæœ€åä¸ºä»€ä¹ˆè¦æ‹¼æ¥ï¼Œä»¥åŠFCå±‚çš„ç³»æ•°" class="headerlink" title="æ³¨æ„ QKVçŸ©é˜µæ€ä¹ˆæ¥çš„(attentionåˆ†æ•°)ï¼Œæœ€åä¸ºä»€ä¹ˆè¦æ‹¼æ¥ï¼Œä»¥åŠFCå±‚çš„ç³»æ•°"></a>æ³¨æ„ QKVçŸ©é˜µæ€ä¹ˆæ¥çš„(attentionåˆ†æ•°)ï¼Œæœ€åä¸ºä»€ä¹ˆè¦æ‹¼æ¥ï¼Œä»¥åŠFCå±‚çš„ç³»æ•°</h3><ol><li><p>qkç›¸ä¹˜å¾—åˆ°ï¼Œè¯å‘é‡ä¸å…¶ä»–è¯çš„attentionåˆ†æ•°( q1*(k1,k2,k3) )</p></li><li><p>å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶è®©ä¸€ä»½è¯å‘é‡äº§ç”Ÿäº†å¤šä»½ç­”æ¡ˆï¼Œå°†æ¯ä¸€ä»½æ³¨æ„åŠ›æœºåˆ¶çš„äº§ç‰©æ‹¼æ¥ï¼Œ</p><p>è·å¾—äº†è¯å‘é‡åœ¨ä¸åŒæ³¨æ„åŠ›çŸ©é˜µè¿ç®—åçš„åˆ†æ•°ï¼Œè¿›è¡Œæ‹¼æ¥åï¼Œsoftmaxè¾“å‡º<strong>æœ€æ³¨æ„çš„è¯</strong>ï¼Œå³æ˜¯æ³¨æ„åŠ›æœºåˆ¶ã€‚</p></li><li><p><strong>å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†å‘é‡å¤åˆ¶nä»½(nä¸ºå¤šå¤´å¤´æ•°)ï¼ŒæŠ•å½±åˆ°å¦‚512&#x2F;8 &#x3D; 64çš„64ç»´çš„ä½ç»´ç©ºé—´ï¼Œæœ€åå°†æ¯ä¸€å±‚çš„è¾“å‡ºç»“æœ</strong></p><p><strong>æ­¤å¤„ä¸ºå…«å±‚ï¼Œ8*64&#x3D;512 æ‹¼å›512ç»´çš„è¾“å‡ºæ•°æ®</strong></p><p><strong>ç”±äºScale Dot Product åªæ˜¯åšä¹˜æ³•ç‚¹ç§¯(å‘é‡å˜æˆqvkä¹‹åçš„attentionè¿ç®—)ï¼Œæ²¡ä»€ä¹ˆå‚æ•°ï¼Œå› æ­¤é‡ç‚¹å­¦ä¹ çš„å‚æ•°åœ¨Multi-Headçš„çº¿æ€§å˜æ¢ä¸­ï¼Œ</strong></p><p><strong>å³å°† 64*8çš„å…«ä»½æ•°æ®çº¿æ€§å˜æ¢çš„ä¸‹æ–‡ä¸­çš„W0ï¼Œç»™æ¨¡å‹å…«æ¬¡æœºä¼šå¸Œæœ›èƒ½å¤Ÿå­¦åˆ°ä»€ä¹ˆï¼Œæœ€ååœ¨æ‹¼æ¥å›æ¥ã€‚</strong>&#x3D;&#x3D;</p></li></ol><hr><p><strong>æ³¨æ„åŠ›æœºåˆ¶æµç¨‹</strong>ï¼š</p><p><strong>q â€“&gt; æŸ¥è¯¢å‘é‡</strong></p><p><strong>set( kï¼Œv)    k â€“&gt;å…³é”®å­— vâ€”-&gt; å€¼</strong></p><p><strong>å¦‚æœ qå¯¹kçš„ç›¸ä¼¼åº¦å¾ˆé«˜ï¼Œåˆ™è¾“å‡ºvçš„æ¦‚ç‡ä¹Ÿå˜é«˜</strong></p><img src="https://jalammar.github.io/images/t/self-attention-output.png" alt="img" style="zoom: 80%;" /><p><strong>â€™å¤šå¤´â€™æ³¨æ„åŠ›æœºåˆ¶</strong> </p><p>è¯·æ³¨æ„å¹¶æ¨æ¼”å…¶<strong>è¯å‘é‡ç»´åº¦ä¸ç³»æ•°çŸ©é˜µå¸¦çš„è¡Œæ•°</strong></p><p><img src="https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png" alt="img"></p><hr><h3 id="Scale-Dot-Product"><a href="#Scale-Dot-Product" class="headerlink" title="Scale Dot Product"></a>Scale Dot Product</h3><p><img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png" alt="img"></p><p><strong>step1</strong></p><p>QKåšç‚¹ç§¯ï¼Œåˆ™è¾“å‡ºæ¯ä¸€è¡Œï¼Œæ˜¯qä¸æ‰€æœ‰kçš„ç›¸ä¹˜ç›¸åŠ ç»“æœï¼Œ</p><p>Î±1 &#x3D; ï¼ˆq11k11+q12k21+q13k31 ,  q11k12+q12k22+q13k32 )</p><p>Î±2åŒç†ã€‚</p><p><strong>step2</strong></p><p>æ‰€ä»¥å¾—åˆ°äº†query1å¯¹æ‰€æœ‰keyçš„ç›¸ä¼¼åº¦ï¼Œæœ€åæ¯ä¸€è¡Œåšä¸ªsoftmaxè¿›è¡Œæ¦‚ç‡åˆ†å¸ƒã€‚</p><p>é™¤ä»¥æ ¹å·dkæ˜¯ä¸ºäº†å¹³æ»‘æ¢¯åº¦ï¼Œå…·ä½“æ¥è¯´ï¼š<strong>å½“æ¦‚ç‡è¶‹è¿‘äº1çš„æ—¶å€™softmaxå‡½æ•°çš„æ¢¯åº¦å¾ˆå°</strong>ï¼Œ<strong>é™¤ä»¥dkè®©æ•°å€¼æ¥è¿‘å‡½æ•°ä¸­éƒ¨ï¼Œæ¢¯åº¦ä¼šæ¯”è¾ƒé™¡å³­</strong></p><p><strong>step3</strong></p><p>å°†ç¬¬äºŒæ­¥çš„ç»“æœä¸Vç›¸ä¹˜å¾—åˆ°æœ€åçš„è¾“å‡º</p><hr><h2 id="Position-Embedding"><a href="#Position-Embedding" class="headerlink" title="Position Embedding"></a>Position Embedding</h2><p>ä½ç½®ç¼–ç æ˜¯ å°†embeddingå¥½çš„è¯å‘é‡åŠ ä¸Š position embedding vector å°†<strong>ä¿¡æ¯èåˆï¼Œåœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­è¿›è¡Œè®¡ç®—</strong>ã€‚</p><p>(åŸæ–‡æ˜¯ä½¿ç”¨sin coså°†è¯å‘é‡ä»½ä¸¤éƒ¨åˆ†è¿›è¡Œç¼–ç ï¼Œ æœ¬æ–‡ä¸­å°†äº¤æ›¿ä½¿ç”¨sin cosï¼Œå³å•æ•°sin åŒæ•°cos)</p><p>ä½ç½®åµŒå…¥ç¼–ç ï¼Œä¸»è¦æ˜¯ä¸ºäº†ç¼–è¾‘å®šä½<strong>è¯å‘é‡çš„ä½ç½®</strong>ä»¥åŠ<strong>è¯å‘é‡é—´çš„ç›¸å¯¹è·ç¦»</strong></p><blockquote><p>posä¸º è¯çš„ç§ç±»æ•°ï¼Œä¸ºè¡Œæ ‡å·</p><p>i ä¸ºç‰¹å¾ç»´åº¦</p><p>len(pos) * len(i)  è¡¨ç¤ºä¸ºä¸€position embedding çŸ©é˜µï¼Œ æ¯ä¸€è¡Œä¸ºè¯çš„ä½ç½®ä¿¡æ¯ï¼Œæ¯ä¸€åˆ—è¡¨ç¤ºåœ¨ç‰¹å¾ä¸Šåç½®ï¼Œ</p><p><strong>å°†ä½ç½®ä¿¡æ¯ èå…¥ è¯å‘é‡ä¿¡æ¯ ä½¿è¯è·å¾— æ—¶é—´ä¸Šçš„ç›¸å¯¹ä¿¡æ¯</strong></p></blockquote><p><a href="https://www.imagehub.cc/image/JqzAac"><img src="https://s1.imagehub.cc/images/2022/11/09/image638960e7f1096a03.png" alt="image638960e7f1096a03.png" border="0" /></a></p><img src="https://jalammar.github.io/images/t/transformer_positional_encoding_large_example.png" alt="img" style="zoom: 67%;" /><img src="https://jalammar.github.io/images/t/attention-is-all-you-need-positional-encoding.png" alt="img"  /><h2 id="Residual-ç»†èŠ‚"><a href="#Residual-ç»†èŠ‚" class="headerlink" title="Residual ç»†èŠ‚"></a>Residual ç»†èŠ‚</h2><p><img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_2.png" alt="img"></p><h1 id="Decoder-è§£ç é˜¶æ®µ"><a href="#Decoder-è§£ç é˜¶æ®µ" class="headerlink" title="Decoder è§£ç é˜¶æ®µ"></a>Decoder è§£ç é˜¶æ®µ</h1><h3 id="Mask-Multi-head"><a href="#Mask-Multi-head" class="headerlink" title="Mask Multi-head"></a>Mask Multi-head</h3><p>ä¸encoderä¸åŒçš„æ˜¯ï¼Œè§£ç å™¨åœ¨å·¥ä½œæ—¶ä¼šå¼•å…¥ <strong>Mask Multi-head æœºåˆ¶</strong>ï¼Œå°†å³ä¾§çš„è¯ç›–ä½(è®¾ä¸ºè´Ÿæ— ç©·æˆ–è€…åˆ«çš„)ã€‚</p><p>å…·ä½“æ¥è¯´:</p><ol><li><p><strong>encoder å°†ç”Ÿæˆçš„Kå’ŒVçŸ©é˜µ</strong>ä¼ å…¥ decoder çš„ self-attention æ¨¡å—ä¸­ï¼Œè€Œ <strong>decoder å°† mask åçš„QçŸ©é˜µ</strong>ä¸å…¶åšattentionã€‚</p></li><li><p>maskåšçš„äº‹æƒ…</p><p><a href="https://www.imagehub.cc/image/JPWaZm"><img src="https://s1.imagehub.cc/images/2022/10/31/IMG_235920221004-111643.jpg" alt="IMG_235920221004-111643.jpg" border="0" /></a></p></li></ol><p><img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" alt="img"></p><p>è§£ç è¿˜æ˜¯å¾—ä¸€ä¸ªä¸ªæ¥çš„</p><p><strong>æ—¶é—´ç»´åº¦</strong> </p><p>åœ¨æ—¶é—´åºåˆ—çš„æƒ…å†µä¸‹ï¼Œè¯å‘é‡è¡¨ç¤ºä¸ºï¼Œt1æ—¶åˆ»çš„vectorï¼Œt2æ—¶åˆ»çš„vectorâ€¦.</p><p>maskåšçš„äº‹æƒ…å°±æ˜¯å°†åé¢(å³è¾¹)çš„ tnä¸ªæ—¶åˆ»éƒ½å±è”½æ‰ï¼Œ</p><p>è€ŒQmatrixçš„å½¢æˆ å°†vectorå«æœ‰äº†å…¶ä¹‹åè¯çš„ä¿¡æ¯(å…±äº«äº†ç³»æ•°çŸ©é˜µ)ï¼Œæ‰€ä»¥å°†å…¶å³è¾¹å±è”½ã€‚</p><p>åˆ™å‰”é™¤äº†åé¢è¯çš„ä¿¡æ¯ï¼Œä»è€Œä¸è¿›è¡Œè€ƒè™‘ã€‚</p><h3 id="Mask-ç»†èŠ‚"><a href="#Mask-ç»†èŠ‚" class="headerlink" title="Mask ç»†èŠ‚"></a>Mask ç»†èŠ‚</h3><p>maskå°±æ˜¯ä¸ºäº†é˜»æ­¢è¯çŸ¥é“åé¢çš„ä¿¡æ¯ï¼Œå…·ä½“æ¥è¯´å°±æ˜¯QKVçŸ©é˜µè¿˜ç›¸ä¹˜ï¼Œä½†æ˜¯å¼•å…¥-infæ¥é˜»æ­¢å³è¾¹(åé¢çš„ä¿¡æ¯æ±‡èš)</p><p><a href="https://www.imagehub.cc/image/JP7vvk"><img src="https://s1.imagehub.cc/images/2022/10/31/1a35106e841b162c68e41ceb2d8aafb.jpg" alt="1a35106e841b162c68e41ceb2d8aafb.jpg" border="0" style="zoom:50%;" /></a></p><p><strong>ç¬¬ä¸€æ¬¡ç‚¹ç§¯ï¼š</strong>å°†Qå’ŒKçŸ©é˜µç›¸ä¹˜å¾—åˆ°attentionåˆ†æ•°ï¼Œ</p><p>å°†å³ä¸Šè§’ç½®é›¶å°±ä¼šå¾—åˆ°åªå«æœ‰æœ¬èº«ä¿¡æ¯å’Œç›¸å¯¹ä½ç½®ä¹‹å‰(å·¦è¾¹)çš„ä¿¡æ¯ï¼Œ</p><p>ä¸”<strong>ç¬¬äºŒæ¬¡ç‚¹ç§¯:</strong> Mask(QK)ä¸Vç›¸ä¹˜ç”±ä¸‹ä¸‰è§’çŸ©é˜µçš„æ€§è´¨ï¼Œ</p><p><a href="https://www.imagehub.cc/image/JPuD0r"><img src="https://s1.imagehub.cc/images/2022/10/31/752a1f3305f3573aacc1c7b92395faf.jpg" alt="752a1f3305f3573aacc1c7b92395faf.jpg" border="0" style="zoom:50%;" /></a></p><img src="https://z3.ax1x.com/2021/04/20/c7w7rD.png#shadow" alt="img" style="zoom:50%;" /><p><strong>æ³¨: maskå»è´Ÿæ— ç©·æ˜¯å› ä¸º SoftMaxä¸­ eçš„æŒ‡æ•°å½¢å¼åªæœ‰åœ¨è´Ÿæ— ç©·æ‰ä¸ºé›¶ï¼Œ</strong></p><p><strong>è¿™æ ·ç›¸ä¹˜æ•°æ®ä¸ä¼šæœ‰ä¸€ç‚¹å½±å“ï¼Œå–å…¶ä»–å€¼ï¼Œéƒ½ä¼šå½±å“softmax</strong></p><img src="https://z3.ax1x.com/2021/04/20/c7w48x.png#shadow" alt="img"  /><p><img src="https://s1.ax1x.com/2020/07/12/U3FCQ0.png" alt="img"></p><h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><ol><li>ç‰¹åˆ«æ³¨æ„ç†è§£ attentionæœºåˆ¶å°†è¯å‘é‡ä¹‹é—´çš„è”ç³»ï¼Œ <strong>attentionåˆ†æ•°</strong></li><li>embeddingæ–¹å¼ä¸º <strong>è¯å‘é‡+ä½ç½®ç¼–ç å‘é‡</strong></li><li>å¼•å…¥äº† <strong>Residual</strong></li><li><strong>encoder-decoderå±‚çš„ä¼ å…¥</strong>ä¸ºKVçŸ©é˜µï¼Œdecoderç”ŸæˆQçŸ©é˜µ</li><li><strong>Maskæ–¹å¼</strong></li></ol>]]></content>
      
      
      <categories>
          
          <category> Dive Into Paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attentionæœºåˆ¶</title>
      <link href="/posts/54367.html"/>
      <url>/posts/54367.html</url>
      
        <content type="html"><![CDATA[<h1 id="å¾…å®Œæˆ"><a href="#å¾…å®Œæˆ" class="headerlink" title="å¾…å®Œæˆ"></a>å¾…å®Œæˆ</h1><ul><li>å¤±æ•ˆå›¾ç‰‡å¤„ç†</li></ul><p><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">åšå®¢åœ°å€</a></p><h2 id="ä¼ ç»ŸSeq2Seq"><a href="#ä¼ ç»ŸSeq2Seq" class="headerlink" title="ä¼ ç»ŸSeq2Seq"></a>ä¼ ç»ŸSeq2Seq</h2><p>â€‹<a href="https://www.imagehub.cc/image/JJyQxx"><img src="https://s1.imagehub.cc/images/2022/10/29/image9776ac96fcdc3b7e.png" alt="image9776ac96fcdc3b7e.png" border="0" /></a></p><p><a href="https://jalammar.github.io/images/seq2seq_4.mp4">åŠ¨ç”»è¿æ¥</a></p><p>å·¦ä¾§ä¸º input å°†å¥å­ä¸€ä¸ªä¸€ä¸ªæŠ•å…¥åˆ° encoder ä¸­ï¼Œ</p><p>encoderæ•´ä¸ªå¤„ç†å…¶ç›¸å…³æ€§å¾—åˆ° contextï¼Œåç»™ decoderï¼Œ</p><p>decoder è¿›è¡Œä¸€ä¸ªä¸€ä¸ªè§£ç è¾“å‡ºï¼Œå¾—åˆ°æ•´ä¸ªç¿»è¯‘åçš„å¥å­ã€‚</p><h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><p>An attention model differs from a classic sequence-to-sequence model in two main ways:</p><ul><li>First, the encoder passes a lot more data to the decoder. Instead of passing the last hidden state of the encoding stage, the encoder passes <em>all</em> the hidden states to the decoder:</li></ul><p>â€‹<strong>æ³¨æ„åŠ›æœºåˆ¶å°†äº§ç”Ÿçš„éšè—å±‚ä¿¡æ¯(æ—¶é—´æ­¥éª¤ä¿¡æ¯)ï¼Œå…¨éƒ¨ä¿ç•™ï¼Œä¸€æ¬¡æ€§ä¼ ç»™ Decoderã€‚</strong></p><img src="https://img-blog.csdnimg.cn/20181119222424704.gif" alt="img" style="zoom: 80%;" /><ul><li><p>Second, an attention decoder does an extra step before producing its output. In order to focus on the parts of the input that are relevant to this decoding time step, the decoder does the following:</p><ol><li><p>Look at the set of encoder hidden states it received â€“ each encoder hidden state is most associated with a certain word in the input sentence</p></li><li><p>Give each hidden state a score (letâ€™s ignore how the scoring is done for now)</p></li><li><p>Multiply each hidden state by its softmaxed score, thus amplifying hidden states with high scores, and drowning out hidden states with low scores</p></li></ol></li></ul><p>â€‹<strong>decoder å°† encoder è¾“å…¥çš„éšè—å±‚çš„ vector è¿›è¡Œæ‰“åˆ†å¾—åˆ°ä¸€ä¸ªåˆ†æ•°vectorï¼Œ</strong></p><p>â€‹<strong>å°†åˆ†æ•° vector åš softmaxï¼Œå¾—åˆ°ä¸€ä¸ªæƒé‡ vectorï¼Œ</strong></p><p>â€‹<strong>å°†æƒé‡ vector ä¸éšè—å±‚ vector ç›¸ä¹˜å¾—åˆ° æ³¨æ„åŠ› vectorï¼Œ</strong></p><p>â€‹<strong>æœ€åæŠŠæ³¨æ„åŠ› vector è¿›è¡Œç›¸åŠ å°±å®Œæˆäº†ã€‚</strong></p><p><a href="https://www.imagehub.cc/image/JJ8xIK"><img src="https://s1.imagehub.cc/images/2022/10/29/imageb79497ae8b6c83ca.png" alt="imageb79497ae8b6c83ca.png" border="0" /></a></p><ul><li>æ³¨æ„: å°† encoder çš„éšè—å±‚ä¿¡æ¯ä¼ å…¥ decoderä¹‹åï¼Œdecoder æ¯ä¸€æ­¥éƒ½å°†ä½¿ç”¨å…¶ä¼ å…¥çš„éšè—å±‚ä¿¡æ¯åš attentionã€‚</li></ul><p><img src="https://img-blog.csdnimg.cn/20181119222700993.gif" alt="img"></p><p>â€‹<strong>ç”±ä¸Šå›¾å¯ä»¥çœ‹åˆ°ï¼Œè¾“å‡ºæ—¶ Attention æœºåˆ¶å°±æ˜¯å°†æ³¨æ„åŠ›æ”¾åœ¨åˆ†æ•°æœ€é«˜çš„å‘é‡ä¸Šï¼Œæ‰€ä»¥ï¼Œç§°ä¹‹ä¸ºâ€™æ³¨æ„åŠ›æœºåˆ¶â€™</strong></p>]]></content>
      
      
      <categories>
          
          <category> Dive Into Paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HF 02</title>
      <link href="/posts/45348.html"/>
      <url>/posts/45348.html</url>
      
        <content type="html"><![CDATA[<h1 id="å¾…å®Œæˆ"><a href="#å¾…å®Œæˆ" class="headerlink" title="å¾…å®Œæˆ"></a>å¾…å®Œæˆ</h1><ul><li>ç¤ºä¾‹è¯¦è§£</li></ul><h3 id="Transformeråˆ†ä¸¤å—BERT-amp-GPTéƒ½å¾ˆèƒ½æ‰“"><a href="#Transformeråˆ†ä¸¤å—BERT-amp-GPTéƒ½å¾ˆèƒ½æ‰“" class="headerlink" title="Transformeråˆ†ä¸¤å—BERT&amp;GPTéƒ½å¾ˆèƒ½æ‰“"></a>Transformeråˆ†ä¸¤å—BERT&amp;GPTéƒ½å¾ˆèƒ½æ‰“</h3><ol><li><p>BERTç”¨çš„æ˜¯transformerçš„encoder</p><blockquote><p>BERTæ˜¯ç”¨äº†Transformerçš„encoderä¾§çš„ç½‘ç»œï¼Œencoderä¸­çš„Self-attentionæœºåˆ¶åœ¨ç¼–ç ä¸€ä¸ªtokençš„æ—¶å€™åŒæ—¶åˆ©ç”¨äº†å…¶ä¸Šä¸‹æ–‡çš„tokenï¼Œå…¶ä¸­â€˜åŒæ—¶åˆ©ç”¨ä¸Šä¸‹æ–‡â€™å³ä¸ºåŒå‘çš„ä½“ç°ï¼Œè€Œå¹¶éæƒ³Bi-LSTMé‚£æ ·æŠŠå¥å­å€’åºè¾“å…¥ä¸€éã€‚</p></blockquote></li><li><p>GPTç”¨çš„æ˜¯transformerçš„decoder</p><blockquote><p>åœ¨å®ƒä¹‹å‰æ˜¯GPTï¼ŒGPTä½¿ç”¨çš„æ˜¯Transformerçš„decoderä¾§çš„ç½‘ç»œï¼ŒGPTæ˜¯ä¸€ä¸ªå•å‘è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒè¿‡ç¨‹ï¼Œæ›´é€‚ç”¨äºæ–‡æœ¬ç”Ÿæˆï¼Œé€šè¿‡å‰æ–‡å»é¢„æµ‹å½“å‰çš„å­—ã€‚</p></blockquote></li></ol><h2 id="Bertçš„embedding"><a href="#Bertçš„embedding" class="headerlink" title="Bertçš„embedding"></a>Bertçš„embedding</h2><p>Embeddingç”±ä¸‰ç§Embeddingæ±‚å’Œè€Œæˆï¼š</p><ol><li><p>Token Embeddingsæ˜¯è¯å‘é‡ï¼Œç¬¬ä¸€ä¸ªå•è¯æ˜¯CLSæ ‡å¿—ï¼Œå¯ä»¥ç”¨äºä¹‹åçš„åˆ†ç±»ä»»åŠ¡</p><blockquote><p>BERTåœ¨ç¬¬ä¸€å¥å‰ä¼šåŠ ä¸€ä¸ª[CLS]æ ‡å¿—ï¼Œ<strong>æœ€åä¸€å±‚è¯¥ä½å¯¹åº”å‘é‡å¯ä»¥ä½œä¸ºæ•´å¥è¯çš„è¯­ä¹‰è¡¨ç¤º</strong>ï¼Œä»è€Œç”¨äºä¸‹æ¸¸çš„åˆ†ç±»ä»»åŠ¡ç­‰ã€‚å› ä¸ºä¸æ–‡æœ¬ä¸­å·²æœ‰çš„å…¶å®ƒè¯ç›¸æ¯”ï¼Œè¿™ä¸ªæ— æ˜æ˜¾è¯­ä¹‰ä¿¡æ¯çš„ç¬¦å·ä¼šæ›´<strong>â€œå…¬å¹³â€åœ°èåˆæ–‡æœ¬ä¸­å„ä¸ªè¯çš„è¯­ä¹‰ä¿¡æ¯</strong>ï¼Œä»è€Œæ›´å¥½çš„è¡¨ç¤ºæ•´å¥è¯çš„è¯­ä¹‰ã€‚ å…·ä½“æ¥è¯´ï¼Œself-attentionæ˜¯ç”¨æ–‡æœ¬ä¸­çš„å…¶å®ƒè¯æ¥å¢å¼ºç›®æ ‡è¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œä½†æ˜¯ç›®æ ‡è¯æœ¬èº«çš„è¯­ä¹‰è¿˜æ˜¯ä¼šå ä¸»è¦éƒ¨åˆ†çš„ï¼Œå› æ­¤ï¼Œç»è¿‡BERTçš„12å±‚ï¼ˆBERT-baseä¸ºä¾‹ï¼‰ï¼Œæ¯æ¬¡è¯çš„embeddingèåˆäº†æ‰€æœ‰è¯çš„ä¿¡æ¯ï¼Œå¯ä»¥å»æ›´å¥½çš„è¡¨ç¤ºè‡ªå·±çš„è¯­ä¹‰ã€‚è€Œ[CLS]ä½æœ¬èº«æ²¡æœ‰è¯­ä¹‰ï¼Œç»è¿‡12å±‚ï¼Œå¥å­çº§åˆ«çš„å‘é‡ï¼Œç›¸æ¯”å…¶ä»–æ­£å¸¸è¯ï¼Œå¯ä»¥æ›´å¥½çš„è¡¨å¾å¥å­è¯­ä¹‰ã€‚</p></blockquote></li><li><p>Segment Embeddingsç”¨æ¥åŒºåˆ«ä¸¤ç§å¥å­ï¼Œå› ä¸ºé¢„è®­ç»ƒä¸å…‰åšLMè¿˜è¦åšä»¥ä¸¤ä¸ªå¥å­ä¸ºè¾“å…¥çš„åˆ†ç±»ä»»åŠ¡</p></li><li><p>Position Embeddingså’Œä¹‹å‰æ–‡ç« ä¸­çš„Transformerä¸ä¸€æ ·ï¼Œä¸æ˜¯ä¸‰è§’å‡½æ•°è€Œæ˜¯å­¦ä¹ å‡ºæ¥çš„</p></li></ol><h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><h3 id="tokenizer"><a href="#tokenizer" class="headerlink" title="tokenizer"></a>tokenizer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoConfig,AutoModel,AutoTokenizer,AdamW,get_linear_schedule_with_warmup,logging</span><br><span class="line"></span><br><span class="line"><span class="comment"># configæ¨¡å—</span></span><br><span class="line">MODEL_NAME=<span class="string">&quot;bert-base-chinese&quot;</span></span><br><span class="line">config = AutoConfig.from_pretrained(MODEL_NAME) <span class="comment">#c onfigå¯ä»¥é…ç½®æ¨¡å‹ä¿¡æ¯</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tokenizeræ¨¡å—</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)</span><br><span class="line"></span><br><span class="line">tokenizer.all_special_ids <span class="comment"># æŸ¥çœ‹ç‰¹æ®Šç¬¦å·çš„id [100, 102, 0, 101, 103]</span></span><br><span class="line">tokenizer.all_special_tokens <span class="comment"># æŸ¥çœ‹token  [&#x27;[UNK]&#x27;, &#x27;[SEP]&#x27;, &#x27;[PAD]&#x27;, &#x27;[CLS]&#x27;, &#x27;[MASK]&#x27;]</span></span><br><span class="line"></span><br><span class="line">tokenizer.vocab_size <span class="comment"># è¯æ±‡è¡¨å¤§å°</span></span><br><span class="line">tokenizer.vocab <span class="comment"># è¯æ±‡å¯¹åº”çš„dictå½¢å¼</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## tokening</span></span><br><span class="line">text=<span class="string">&quot;æˆ‘åœ¨åŒ—äº¬å·¥ä½œ&quot;</span></span><br><span class="line">token_ids=tokenizer.encode(text)</span><br><span class="line">token_ids <span class="comment"># [101, 2769, 1762, 1266, 776, 2339, 868, 102]</span></span><br><span class="line">tokenizer.convert_ids_to_tokens(token_ids) <span class="comment"># [&#x27;[CLS]&#x27;, &#x27;æˆ‘&#x27;, &#x27;åœ¨&#x27;, &#x27;åŒ—&#x27;, &#x27;äº¬&#x27;, &#x27;å·¥&#x27;, &#x27;ä½œ&#x27;, &#x27;[SEP]&#x27;]</span></span><br><span class="line">  <span class="comment"># convert_tokens_to_ids(tokens) ä¸ºå¯¹åº”æ–¹æ³•</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">## padding åšå‘é‡å¡«å……</span></span><br><span class="line">token_ids=tokenizer.encode(text,padding=<span class="literal">True</span>,max_length=<span class="number">30</span>,add_special_tokens=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## encode_plus</span></span><br><span class="line">token_ids=tokenizer.encode_plus(</span><br><span class="line">    text,padding=<span class="string">&quot;max_length&quot;</span>,</span><br><span class="line">    max_length=<span class="number">30</span>,</span><br><span class="line">    add_special_tokens=<span class="literal">True</span>,</span><br><span class="line">    return_tensors=<span class="string">&#x27;pt&#x27;</span>,</span><br><span class="line">    return_token_type_ids=<span class="literal">True</span>,</span><br><span class="line">    return_attention_mask=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="ä½¿ç”¨pre-trainæ¨¡å‹è½½å…¥æ•°æ®"><a href="#ä½¿ç”¨pre-trainæ¨¡å‹è½½å…¥æ•°æ®" class="headerlink" title="ä½¿ç”¨pre_trainæ¨¡å‹è½½å…¥æ•°æ®"></a>ä½¿ç”¨pre_trainæ¨¡å‹è½½å…¥æ•°æ®</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model=AutoModel.from_pretrained(MODEL_NAME)</span><br><span class="line">outputs=model(token_ids[<span class="string">&#x27;input_ids&#x27;</span>],token_ids[<span class="string">&#x27;attention_mask&#x27;</span>])</span><br></pre></td></tr></table></figure><h3 id="æ•°æ®é›†datasetå®šä¹‰"><a href="#æ•°æ®é›†datasetå®šä¹‰" class="headerlink" title="æ•°æ®é›†datasetå®šä¹‰"></a>æ•°æ®é›†datasetå®šä¹‰</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EnterpriseDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,texts,labels,tokenizer,max_len</span>):</span><br><span class="line">        self.texts=texts</span><br><span class="line">        self.labels=labels</span><br><span class="line">        self.tokenizer=tokenizer</span><br><span class="line">        self.max_len=max_len</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.texts)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,item</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        item ä¸ºæ•°æ®ç´¢å¼•ï¼Œè¿­ä»£å–ç¬¬itemæ¡æ•°æ®</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        text=<span class="built_in">str</span>(self.texts[item])</span><br><span class="line">        label=self.labels[item]</span><br><span class="line">        </span><br><span class="line">        encoding=self.tokenizer.encode_plus(</span><br><span class="line">            text,</span><br><span class="line">            add_special_tokens=<span class="literal">True</span>,</span><br><span class="line">            max_length=self.max_len,</span><br><span class="line">            return_token_type_ids=<span class="literal">True</span>,</span><br><span class="line">            pad_to_max_length=<span class="literal">True</span>,</span><br><span class="line">            return_attention_mask=<span class="literal">True</span>,</span><br><span class="line">            return_tensors=<span class="string">&#x27;pt&#x27;</span>,  <span class="comment">#è½¬ä¸ºtensor</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line"><span class="comment">#print(encoding[&#x27;input_ids&#x27;])</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;texts&#x27;</span>:text,</span><br><span class="line">            <span class="string">&#x27;input_ids&#x27;</span>:encoding[<span class="string">&#x27;input_ids&#x27;</span>].flatten(),</span><br><span class="line">            <span class="string">&#x27;attention_mask&#x27;</span>:encoding[<span class="string">&#x27;attention_mask&#x27;</span>].flatten(),</span><br><span class="line">            <span class="comment"># toeken_type_ids:0</span></span><br><span class="line">            <span class="string">&#x27;labels&#x27;</span>:torch.tensor(label,dtype=torch.long)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Universe </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HuggingFace </tag>
            
            <tag> Bert </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HF 01</title>
      <link href="/posts/45347.html"/>
      <url>/posts/45347.html</url>
      
        <content type="html"><![CDATA[<h1 id="å¾…å®Œæˆ"><a href="#å¾…å®Œæˆ" class="headerlink" title="å¾…å®Œæˆ"></a>å¾…å®Œæˆ</h1><ul><li>ç¤ºä¾‹è¯¦è§£</li><li></li></ul><p><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Attention åŸæ–‡</a></p><h2 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h2><ul><li><p>å…¨é¢æ‹¥æŠ±Transformerï¼šNLPä¸‰å¤§ç‰¹å¾æŠ½å–å™¨(CNN&#x2F;RNN&#x2F;TF)ä¸­ï¼Œè¿‘ä¸¤å¹´æ–°æ¬¢<strong>Transformeræ˜æ˜¾ä¼šå¾ˆå¿«æˆä¸ºNLPé‡Œæ‹…å½“å¤§ä»»çš„æœ€ä¸»æµçš„ç‰¹å¾æŠ½å–å™¨ã€‚</strong></p></li><li><p>åƒWordvecå‡ºç°ä¹‹åä¸€æ ·ï¼Œåœ¨äººå·¥æ™ºèƒ½é¢†åŸŸç§å„ç§ç›®æ ‡çš†å¯å‘é‡åŒ–ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬ç»å¸¸å¬åˆ°çš„â€œ<strong>ä¸‡ç‰©çš†å¯Embedding</strong>â€ã€‚è€ŒTransformeræ¨¡å‹å’ŒBertæ¨¡å‹çš„å‡ºç°ï¼Œæ›´æ˜¯NLPé¢†åŸŸåˆ’æ—¶ä»£çš„äº§ç‰©ï¼šå°†<strong>transformerå’ŒåŒå‘è¯­è¨€æ¨¡å‹è¿›è¡Œèåˆ</strong>ï¼Œä¾¿å¾—åˆ°NLPåˆ’æ—¶ä»£çš„ï¼Œä¹Ÿæ˜¯å½“ä¸‹åœ¨å„è‡ªNLPä¸‹æµä»»åŠ¡ä¸­è·å¾—state-of-the-artçš„æ¨¡å‹-BERT</p></li><li><p><strong>BERTèµ·æºäºé¢„è®­ç»ƒçš„ä¸Šä¸‹æ–‡è¡¨ç¤ºå­¦ä¹ </strong>ï¼Œä¸ä¹‹å‰çš„æ¨¡å‹ä¸åŒï¼ŒBERTæ˜¯ä¸€ç§æ·±åº¦åŒå‘çš„ã€æ— ç›‘ç£çš„è¯­è¨€è¡¨ç¤ºï¼Œä¸”ä»…ä½¿ç”¨çº¯æ–‡æœ¬è¯­æ–™åº“è¿›è¡Œé¢„è®­ç»ƒçš„æ¨¡å‹ã€‚<strong>ä¸Šä¸‹æ–‡æ— å…³æ¨¡å‹ï¼ˆå¦‚word2vecæˆ–GloVeï¼‰ä¸ºè¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªå•è¯ç”Ÿæˆä¸€ä¸ªè¯å‘é‡è¡¨ç¤ºï¼Œå› æ­¤å®¹æ˜“å‡ºç°å•è¯çš„æ­§ä¹‰é—®é¢˜</strong>ã€‚BERTè€ƒè™‘åˆ°å•è¯å‡ºç°æ—¶çš„ä¸Šä¸‹æ–‡ã€‚ä¾‹å¦‚ï¼Œè¯â€œæ°´åˆ†â€çš„word2vecè¯å‘é‡åœ¨â€œæ¤ç‰©éœ€è¦å¸æ”¶æ°´åˆ†â€å’Œâ€œè´¢åŠ¡æŠ¥è¡¨é‡Œæœ‰æ°´åˆ†â€æ˜¯ç›¸åŒçš„ï¼Œä½†BERTæ ¹æ®ä¸Šä¸‹æ–‡çš„ä¸åŒæä¾›ä¸åŒçš„è¯å‘é‡ï¼Œè¯å‘é‡ä¸å¥å­è¡¨è¾¾çš„å¥æ„æœ‰å…³ã€‚</p></li></ul><h3 id="Embeddingï¼š"><a href="#Embeddingï¼š" class="headerlink" title="Embeddingï¼š"></a>Embeddingï¼š</h3><p><img src="https://raw.githubusercontent.com/w5688414/paddleImage/main/bert_img/embedding.png" alt="img"></p><ul><li>é¦–å…ˆç±»ä¼¼ word2vec çš„ tokenåŒ–ï¼Œå†è¿›è¡Œç‰‡æ®µæ ‡è®°( segment )ï¼Œæœ€å ids çš„ä½ç½®ç¼–ç (  position )</li><li>ç¼–ç åä¸€ä¸ª â€™è¯â€˜ æœ‰ä¸‰ä¸ªä¿¡æ¯ï¼Œtokenã€æ®µè½ä½ç½®ä¿¡æ¯ã€ç»å¯¹ä½ç½®ä¿¡æ¯( id: 1ã€2ã€3â€¦)</li></ul><h4 id="Embeddingè§£å†³çš„é—®é¢˜"><a href="#Embeddingè§£å†³çš„é—®é¢˜" class="headerlink" title="Embeddingè§£å†³çš„é—®é¢˜:"></a>Embeddingè§£å†³çš„é—®é¢˜:</h4><ul><li>é¦–å…ˆæ˜¯ä¹‹å‰ç”¨çš„ <strong>One-Hot Key</strong>ï¼Œé«˜ç»´åº¦ï¼Œç¦»æ•£çš„ï¼Œä½ä¿¡æ¯å¯†åº¦çš„å‚¨å­˜å½¢å¼</li><li>å…¶æ¬¡æ˜¯æ›´å¥½çš„ <strong>Contextual Similarity</strong>ï¼Œä¸Šä¸‹æ–‡ç›¸å…³ç›¸ä¼¼æ€§ã€‚</li></ul><h2 id="Preview-Api"><a href="#Preview-Api" class="headerlink" title="Preview Api"></a>Preview Api</h2><h3 id="å‰ç½®æŸ¥çœ‹ï¼š"><a href="#å‰ç½®æŸ¥çœ‹ï¼š" class="headerlink" title="å‰ç½®æŸ¥çœ‹ï¼š"></a>å‰ç½®æŸ¥çœ‹ï¼š</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer</span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&quot;bert-base-chinese&quot;</span>) <span class="comment"># è·å–ç›¸åº”æ¨¡å‹çš„tokenizer</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForMaskedLM</span><br><span class="line">model = AutoModelForMaskedLM.from_pretrained(<span class="string">&quot;bert-base-chinese&quot;</span>) <span class="comment">#æŸ¥çœ‹æ¨¡å‹çš„åˆ†å±‚</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="å‡½æ•°è°ƒç”¨ï¼š"><a href="#å‡½æ•°è°ƒç”¨ï¼š" class="headerlink" title="å‡½æ•°è°ƒç”¨ï¼š"></a>å‡½æ•°è°ƒç”¨ï¼š</h3><h4 id="å­—å…¸å¤§å°ï¼ŒtokenåŒ–ï¼ŒidsåŒ–"><a href="#å­—å…¸å¤§å°ï¼ŒtokenåŒ–ï¼ŒidsåŒ–" class="headerlink" title="å­—å…¸å¤§å°ï¼ŒtokenåŒ–ï¼ŒidsåŒ–"></a>å­—å…¸å¤§å°ï¼ŒtokenåŒ–ï¼ŒidsåŒ–</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vocab = tokenizer.vocab</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;å­—å…¸å¤§å°ï¼š&quot;</span>, <span class="built_in">len</span>(vocab)) <span class="comment"># æŸ¥çœ‹å­—å…¸å¤§å°</span></span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;[CLS] ç­‰åˆ°æ½®æ°´ [MASK] äº†ï¼Œå°±çŸ¥é“è°æ²’ç©¿è£¤å­ã€‚&quot;</span></span><br><span class="line">tokens = tokenizer.tokenize(text)<span class="comment"># å°†æ–‡å­—åˆ†è¯</span></span><br><span class="line">ids = tokenizer.convert_tokens_to_ids(tokens)<span class="comment"># å°†æ–‡å­—è½¬åŒ–ä¸ºæ•°å­—ï¼Œè¿›è¡Œç¼–ç </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&#x27;[CLS]&#x27;, &#x27;ç­‰&#x27;, &#x27;åˆ°&#x27;, &#x27;æ½®&#x27;, &#x27;æ°´&#x27;, &#x27;[MASK]&#x27;, &#x27;äº†&#x27;, &#x27;ï¼Œ&#x27;, &#x27;å°±&#x27;, &#x27;çŸ¥&#x27;] ...</span></span><br><span class="line"><span class="string">[101, 5023, 1168, 4060, 3717, 103, 749, 8024, 2218, 4761] ... </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="Maskæ¨¡å‹çš„ä½¿ç”¨"><a href="#Maskæ¨¡å‹çš„ä½¿ç”¨" class="headerlink" title="Maskæ¨¡å‹çš„ä½¿ç”¨"></a>Maskæ¨¡å‹çš„ä½¿ç”¨</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertForMaskedLM</span><br><span class="line"><span class="comment"># é™¤äº† tokens ä»¥å¤–æˆ‘å€‘é‚„éœ€è¦è¾¨åˆ¥å¥å­çš„ segment ids</span></span><br><span class="line">tokens_tensor = torch.tensor([ids])  <span class="comment"># (1, seq_len)</span></span><br><span class="line">segments_tensors = torch.zeros_like(tokens_tensor)  <span class="comment"># (1, seq_len)</span></span><br><span class="line">maskedLM_model = BertForMaskedLM.from_pretrained(PRETRAINED_MODEL_NAME)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨ masked LM ä¼°è¨ˆ [MASK] ä½ç½®æ‰€ä»£è¡¨çš„å¯¦éš› token </span></span><br><span class="line">maskedLM_model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = maskedLM_model(tokens_tensor, segments_tensors)</span><br><span class="line">    predictions = outputs[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># (1, seq_len, num_hidden_units)</span></span><br><span class="line"><span class="keyword">del</span> maskedLM_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># å°‡ [MASK] ä½ç½®çš„æ©Ÿç‡åˆ†ä½ˆå– top k æœ€æœ‰å¯èƒ½çš„ tokens å‡ºä¾†</span></span><br><span class="line">masked_index = <span class="number">5</span></span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">probs, indices = torch.topk(torch.softmax(predictions[<span class="number">0</span>, masked_index], -<span class="number">1</span>), k)</span><br><span class="line">predicted_tokens = tokenizer.convert_ids_to_tokens(indices.tolist())</span><br><span class="line"></span><br><span class="line"><span class="comment"># é¡¯ç¤º top k å¯èƒ½çš„å­—ã€‚ä¸€èˆ¬æˆ‘å€‘å°±æ˜¯å– top 1 å½“åšé¢„æµ‹å€¼</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;è¼¸å…¥ tokens ï¼š&quot;</span>, tokens[:<span class="number">10</span>], <span class="string">&#x27;...&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="keyword">for</span> i, (t, p) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(predicted_tokens, probs), <span class="number">1</span>):</span><br><span class="line">    tokens[masked_index] = t</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Top &#123;&#125; (&#123;:2&#125;%)ï¼š&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, <span class="built_in">int</span>(p.item() * <span class="number">100</span>), tokens[:<span class="number">10</span>]), <span class="string">&#x27;...&#x27;</span>)</span><br></pre></td></tr></table></figure><p>â€‹è¼¸å…¥ tokens ï¼š [â€˜[CLS]â€™, â€˜ç­‰â€™, â€˜åˆ°â€™, â€˜æ½®â€™, â€˜æ°´â€™, â€˜[MASK]â€™, â€˜äº†â€™, â€˜ï¼Œâ€™, â€˜å°±â€™, â€˜çŸ¥â€™] â€¦<br>â€‹Top 1 (65%)ï¼š[â€˜[CLS]â€™, â€˜ç­‰â€™, â€˜åˆ°â€™, â€˜æ½®â€™, â€˜æ°´â€™, â€˜æ¥â€™, â€˜äº†â€™, â€˜ï¼Œâ€™, â€˜å°±â€™, â€˜çŸ¥â€™] â€¦<br>â€‹Top 2 ( 4%)ï¼š[â€˜[CLS]â€™, â€˜ç­‰â€™, â€˜åˆ°â€™, â€˜æ½®â€™, â€˜æ°´â€™, â€˜è¿‡â€™, â€˜äº†â€™, â€˜ï¼Œâ€™, â€˜å°±â€™, â€˜çŸ¥â€™] â€¦<br>â€‹Top 3 ( 4%)ï¼š[â€˜[CLS]â€™, â€˜ç­‰â€™, â€˜åˆ°â€™, â€˜æ½®â€™, â€˜æ°´â€™, â€˜å¹²â€™, â€˜äº†â€™, â€˜ï¼Œâ€™, â€˜å°±â€™, â€˜çŸ¥â€™] â€¦</p><h4 id="å¯è§†åŒ–æ¨¡å‹-bertviz"><a href="#å¯è§†åŒ–æ¨¡å‹-bertviz" class="headerlink" title="å¯è§†åŒ–æ¨¡å‹: bertviz"></a>å¯è§†åŒ–æ¨¡å‹: bertviz</h4><h2 id="Pandasé¢„å¤„ç†æ–‡æœ¬"><a href="#Pandasé¢„å¤„ç†æ–‡æœ¬" class="headerlink" title="Pandasé¢„å¤„ç†æ–‡æœ¬"></a>Pandasé¢„å¤„ç†æ–‡æœ¬</h2><ol><li>å¤šä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°</li><li>nltkåº“çš„stopwords</li><li>textblobåº“çš„æ‹¼å†™æ£€æŸ¥ã€è¯å¹²æŠ½å–ã€è¯æ€§è¿˜åŸç­‰</li></ol><h3 id="æ–‡æœ¬æ•°æ®çš„åŸºæœ¬ä½“å¾æå–"><a href="#æ–‡æœ¬æ•°æ®çš„åŸºæœ¬ä½“å¾æå–" class="headerlink" title="æ–‡æœ¬æ•°æ®çš„åŸºæœ¬ä½“å¾æå–"></a>æ–‡æœ¬æ•°æ®çš„åŸºæœ¬ä½“å¾æå–</h3><ul><li><p>è¯æ±‡æ•°é‡</p></li><li><p>å­—ç¬¦æ•°é‡</p></li><li><p>å¹³å‡å­—é•¿</p></li><li><p>åœç”¨è¯æ•°é‡</p></li><li><p>ç‰¹æ®Šå­—ç¬¦æ•°é‡</p></li><li><p>æ•°å­—æ•°é‡</p></li><li><p>å¤§å†™å­—æ¯æ•°é‡</p></li></ul><h3 id="æ–‡æœ¬æ•°æ®çš„åŸºæœ¬é¢„å¤„ç†"><a href="#æ–‡æœ¬æ•°æ®çš„åŸºæœ¬é¢„å¤„ç†" class="headerlink" title="æ–‡æœ¬æ•°æ®çš„åŸºæœ¬é¢„å¤„ç†"></a>æ–‡æœ¬æ•°æ®çš„åŸºæœ¬é¢„å¤„ç†</h3><ul><li>å°å†™è½¬æ¢</li><li>å»é™¤æ ‡ç‚¹ç¬¦å·</li><li>å»é™¤åœç”¨è¯</li><li>å»é™¤é¢‘ç°è¯</li><li>å»é™¤ç¨€ç–è¯</li><li>æ‹¼å†™æ ¡æ­£</li><li>åˆ†è¯(tokenization)</li><li>è¯å¹²æå–(stemming)</li><li>è¯å½¢è¿˜åŸ(lemmatization)</li></ul>]]></content>
      
      
      <categories>
          
          <category> Universe </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HuggingFace </tag>
            
            <tag> Bert </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title></title>
      <link href="/archives/index.html"/>
      <url>/archives/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/light.js"/>
      <url>/js/light.js</url>
      
        <content type="html"><![CDATA[// éœ“è™¹ç¯æ•ˆæœ// é¢œè‰²æ•°ç»„var arr = ["#f14747", "#f1a247", "#f1ee47", "#b347f1", "#1edbff", "#ed709b", "#5636ed"];// é¢œè‰²ç´¢å¼•var idx = 0;// åˆ‡æ¢é¢œè‰²function changeColor() {    // ä»…å¤œé—´æ¨¡å¼æ‰å¯ç”¨    if (document.getElementsByTagName('html')[0].getAttribute('data-theme') == 'dark') {        if (document.getElementById("site-name"))            document.getElementById("site-name").style.textShadow = arr[idx] + " 0 0 15px";        if (document.getElementById("site-title"))            document.getElementById("site-title").style.textShadow = arr[idx] + " 0 0 15px";        if (document.getElementById("site-subtitle"))            document.getElementById("site-subtitle").style.textShadow = arr[idx] + " 0 0 10px";        if (document.getElementById("post-info"))            document.getElementById("post-info").style.textShadow = arr[idx] + " 0 0 5px";        try {            document.getElementsByClassName("author-info__name")[0].style.textShadow = arr[idx] + " 0 0 12px";            document.getElementsByClassName("author-info__description")[0].style.textShadow = arr[idx] + " 0 0 12px";        } catch {                    }        idx++;        if (idx == 8) {            idx = 0;        }    } else {        // ç™½å¤©æ¨¡å¼æ¢å¤é»˜è®¤        if (document.getElementById("site-name"))            document.getElementById("site-name").style.textShadow = "#1e1e1ee0 1px 1px 1px";        if (document.getElementById("site-title"))            document.getElementById("site-title").style.textShadow = "#1e1e1ee0 1px 1px 1px";        if (document.getElementById("site-subtitle"))            document.getElementById("site-subtitle").style.textShadow = "#1e1e1ee0 1px 1px 1px";        if (document.getElementById("post-info"))            document.getElementById("post-info").style.textShadow = "#1e1e1ee0 1px 1px 1px";        try {            document.getElementsByClassName("author-info__name")[0].style.textShadow = "";            document.getElementsByClassName("author-info__description")[0].style.textShadow = "";        } catch {                    }    }}// å¼€å¯è®¡æ—¶å™¨window.onload = setInterval(changeColor, 9900);]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/categorybar.css"/>
      <url>/css/categorybar.css</url>
      
        <content type="html"><![CDATA[#categoryBar {  width: 100% !important;}ul.categoryBar-list {  margin: 5px 5px 0 5px !important;  padding: 0 !important;}li.categoryBar-list-item {  font-weight: bold;  display: inline-block;  height: 180px !important;  margin: 5px 0.5% 0 0.5% !important;  background-image: linear-gradient(rgba(0,0,0,0.4) 25%, rgba(16,16,16,0) 100%);  border-radius: 10px;  padding: 25px 0 25px 25px !important;  box-shadow: rgba(50,50,50,0.3) 50px 50px 50px 50px inset;  overflow: hidden;  background-size: 100% !important;  background-position: center !important;}li.categoryBar-list-item:hover {  background-size: 110% !important;  box-shadow: inset 500px 50px 50px 50px rgba(50,50,50,0.6);}li.categoryBar-list-item:hover span.categoryBar-list-descr {  transition: all 0.5s;  transform: translate(-100%, 0);}a.categoryBar-list-link {  color: #fff !important;  font-size: 20px !important;}a.categoryBar-list-link::before {  content: '|' !important;  color: #fff !important;  font-size: 20px !important;}a.categoryBar-list-link:after {  content: '';  position: relative;  width: 0;  bottom: 0;  display: block;  height: 3px;  border-radius: 3px;  background-color: #fff;}a.categoryBar-list-link:hover:after {  width: 90%;  left: 1%;  transition: all 0.5s;}span.categoryBar-list-count {  /* display: block !important; */  color: #fff !important;  font-size: 20px !important;}span.categoryBar-list-count::before {  content: '\f02d' !important;  padding-right: 15px !important;  display: inline-block;  font-weight: 600;  font-style: normal;  font-variant: normal;  font-family: 'Font Awesome 6 Free';  text-rendering: auto;  -webkit-font-smoothing: antialiased;}span.categoryBar-list-descr {  padding: 5px;  display: block !important;  color: #fff !important;  font-size: 20px !important;  position: relative;  right: -100%;}@media screen and (max-width: 650px) {  li.categoryBar-list-item {    width: 48% !important;    height: 150px !important;    margin: 5px 1% 0 1% !important;  }}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>çŸ¥è¯†æ ‡ç­¾</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/custom.css"/>
      <url>/css/custom.css</url>
      
        <content type="html"><![CDATA[/* é¡µè„šä¸å¤´å›¾é€æ˜ */#footer {    background: transparent !important;  }  #page-header {    background: transparent !important;  }    /* ç™½å¤©æ¨¡å¼é®ç½©é€æ˜ */  #footer::before {    background: transparent !important;  }  /* #page-header::before {    background: transparent !important;  } */    /* å¤œé—´æ¨¡å¼é®ç½©é€æ˜ */  [data-theme="dark"] #footer::before {    background: transparent !important;  }  [data-theme="dark"] #page-header::before {    background: transparent !important;  }/* ä¸€çº§èœå•å±…ä¸­ *//* #nav .menus_items {    position: absolute !important;    width: fit-content !important;    left: 50% !important;    transform: translateX(-50%) !important;  }  å­èœå•æ¨ªå‘å±•ç¤º */  /* #nav .menus_items .menus_item:hover .menus_item_child {    display: flex !important;  }  /* è¿™é‡Œçš„2æ˜¯ä»£è¡¨å¯¼èˆªæ çš„ç¬¬2ä¸ªå…ƒç´ ï¼Œå³æœ‰å­èœå•çš„å…ƒç´ ï¼Œå¯ä»¥æŒ‰è‡ªå·±éœ€æ±‚ä¿®æ”¹ */  /* .menus_items .menus_item:nth-child(2) .menus_item_child {    left: -125px;  } */ *//* å¤œé—´æ¨¡å¼èœå•æ å‘å…‰å­— */[data-theme="dark"] #nav .site-page,[data-theme="dark"] #nav .menus_items .menus_item .menus_item_child li a {  text-shadow: 0 0 2px var(--theme-color) !important;}/* æ‰‹æœºç«¯é€‚é… */[data-theme="dark"] #sidebar #sidebar-menus .menus_items .site-page {  text-shadow: 0 0 2px var(--theme-color) !important;}/* ä¾§è¾¹æ ä¸ªäººä¿¡æ¯å¡ç‰‡åŠ¨æ€æ¸å˜è‰² *//* #aside-content > .card-widget.card-info {   background-image: linear-gradient(  to right,   #ff8177 0%,  #ff867a 0%,  #ff8c7f 21%,  #f99185 52%,  #cf556c 78%,  #b12a5b 100%);;    box-shadow: 0 0 5px rgb(66, 68, 68);    position: relative;    background-size: 400% 400%;    -webkit-animation: Gradient 10s ease infinite;    -moz-animation: Gradient 10s ease infinite;    animation: Gradient 10s ease infinite !important;  }  @-webkit-keyframes Gradient {    0% {      background-position: 0% 50%;    }    50% {      background-position: 100% 50%;    }    100% {      background-position: 0% 50%;    }  }  @-moz-keyframes Gradient {    0% {      background-position: 0% 50%;    }    50% {      background-position: 100% 50%;    }    100% {      background-position: 0% 50%;    }  }  @keyframes Gradient {    0% {      background-position: 0% 50%;    }    50% {      background-position: 100% 50%;    }    100% {      background-position: 0% 50%;    }  }      /* é»‘å¤œæ¨¡å¼é€‚é… */  [data-theme="dark"] #aside-content > .card-widget.card-info {    background: #191919dd;  }    /* ä¸ªäººä¿¡æ¯Follow meæŒ‰é’® */  #aside-content > .card-widget.card-info > #card-info-btn {    background-color: #3eb8be;    border-radius: 8px;  }/* ç¿»é¡µæŒ‰é’®å±…ä¸­ */#pagination {  width: 100%;  margin: auto;}/* é¦–é¡µ å¡ç‰‡æ–‡ç« èƒŒæ™¯é€æ˜ */#recent-posts>.recent-post-item {  background: #ffffffee;  /* backdrop-filter: var(--backdrop-filter); */  border-radius: 25px;  border: 1px solid rgb(169, 169, 169) }#aside-content .card-widget {  background: #ffffffee;   /* backdrop-filter: var(--backdrop-filter); */  border-radius: 18px;  transition: .3s;  border: 1px solid rgb(169, 169, 169) }div#post {  background: #ffffffee;  /* backdrop-filter: var(--backdrop-filter); */  border: 1px solid rgb(169, 169, 169) ;  border-radius: 20px}div#page {  background: #ffffffee;  /* backdrop-filter: var(--backdrop-filter); */  border: 1px solid rgb(169, 169, 169) ;  border-radius: 20px}div#archive {  background: #ffffffee;  /* backdrop-filter: var(--backdrop-filter); */  border: 1px solid rgb(169, 169, 169) ;  border-radius: 20px}div#tag {  background: #ffffffee;  /* backdrop-filter: var(--backdrop-filter); */  border: 1px solid rgb(169, 169, 169) ;  border-radius: 20px}div#category {  background: #ffffffee;  /* backdrop-filter: var(--backdrop-filter); */  border: 1px solid rgb(169, 169, 169) ;  border-radius: 20px}#page-header.nav-fixed #nav {  background: rgba(255,255,255,.75);  /* backdrop-filter: var(--backdrop-filter) */}[data-theme=dark] #page-header.nav-fixed #nav {  background: rgba(0,0,0,.7)!important}[data-theme=dark] #recent-posts>.recent-post-item {  background: #191919dd  }[data-theme=dark] #aside-content .card-widget {  background: #191919dd}[data-theme=dark] div#post {  background: #191919dd}[data-theme=dark] div#tag {  background: #191919dd}[data-theme=dark] div#archive {  background: #191919dd}[data-theme=dark] div#page {  background: #191919dd}[data-theme=dark] div#category {  background: #191919dd}[data-theme=dark] #footer::before {  background: 0 0!important}[data-theme=dark] #page-header::before {  background: 0 0!important}.read-mode #aside-content .card-widget {  background: rgba(158,204,171,.5)!important}.read-mode div#post {  background: rgba(158,204,171,.5)!important}[data-theme=dark] .read-mode #aside-content .card-widget {  background: rgba(25,25,25,.9)!important;  color: #fff}[data-theme=dark] .read-mode div#post {  background: rgba(25,25,25,.9)!important;  color: #fff}/* éšè—åˆ†ç±»ç£è´´æ•°å­— */span.categoryBar-list-count {  display: none !important;}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>æ–‡ç« åˆ†ç±»</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>èµ„æºåˆ†äº«</title>
      <link href="/something/index.html"/>
      <url>/something/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
