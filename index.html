<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Attention Is A Talent</title><meta name="author" content="Poy One"><meta name="copyright" content="Poy One"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Attention Is A Talent">
<meta property="og:url" content="https://poyone.github.io/index.html">
<meta property="og:site_name" content="Attention Is A Talent">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.imagehub.cc/images/2022/11/20/375c6e3994a1f2472da5b34c26e48f18ab750e42.jpg942w_1332h_progressive.webp">
<meta property="article:author" content="Poy One">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.imagehub.cc/images/2022/11/20/375c6e3994a1f2472da5b34c26e48f18ab750e42.jpg942w_1332h_progressive.webp"><link rel="shortcut icon" href="https://s1.imagehub.cc/images/2022/11/20/375c6e3994a1f2472da5b34c26e48f18ab750e42.jpg942w_1332h_progressive.webp"><link rel="canonical" href="https://poyone.github.io/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"ä½ å·²åˆ‡æ¢ä¸ºç¹ä½“","cht_to_chs":"ä½ å·²åˆ‡æ¢ä¸ºç®€ä½“","day_to_night":"ä½ å·²åˆ‡æ¢ä¸ºæ·±è‰²æ¨¡å¼","night_to_day":"ä½ å·²åˆ‡æ¢ä¸ºæµ…è‰²æ¨¡å¼","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Attention Is A Talent',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-11-22 13:01:05'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card@1.0.0/lib/categorybar.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/20/375c6e3994a1f2472da5b34c26e48f18ab750e42.jpg942w_1332h_progressive.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">4</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> å…³äº</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Attention Is A Talent</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> å…³äº</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Attention Is A Talent</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2022/11/21/NLP%E7%AC%94%E8%AE%B0/Transformer%20Self-Attention/" title="Transformer &amp; Self-Attention"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/22/Mushoku.Tensei_.Isekai.Ittara.Honki.Dasu.full.3542652.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformer &amp; Self-Attention"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/NLP%E7%AC%94%E8%AE%B0/Transformer%20Self-Attention/" title="Transformer &amp; Self-Attention">Transformer &amp; Self-Attention</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-21T09:00:10.398Z" title="å‘è¡¨äº 2022-11-21 17:00:10">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-11-22T04:59:49.364Z" title="æ›´æ–°äº 2022-11-22 12:59:49">2022-11-22</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a></span></div><div class="content">é˜¿ä¸‰åšå®¢åœ°å€
ææ²è€å¸ˆ 48åˆ†é’Ÿè®²è§£ encoder-decoderä¸­(KVâ€“Q)çš„è¿ç®—: 
KQç›¸ä¹˜å°±æ˜¯å•ä¸ªqå¯¹æ‰€æœ‰kçš„ç›¸ä¼¼åº¦ä½œä¸ºattention score(ç»™è¿™ä¸ªKå€¼å¤šå°‘æ³¨æ„åŠ›)ï¼Œä¸å•ä¸ªvåšåŠ æƒå’Œ(æƒå€¼æ¥è‡ªKQ)
å†é€šè¿‡æ³¨æ„åŠ›åˆ†æ•°ä¸Vå‘é‡ç›¸ä¹˜ï¼Œå¾—åˆ°æ¯ä¸ªVåº”è¯¥å¤šå¤§çš„ç¼©æ”¾ï¼Œ è¿›è¡Œç›¸åŠ åå°±å¾—åˆ°äº†æœ€ç»ˆVåº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­äº†
ææ²è€å¸ˆ 56åˆ† å¯¹multi-headè¾“å‡ºå’Œlinearå±‚ç›¸è¾ƒäºRNNçš„è®²è§£ï¼š
è¯å‘é‡ç»è¿‡Attentionå±‚æŠ“å–å…¨å±€ä¿¡æ¯ï¼Œæ±‡èšä¹‹åï¼Œåœ¨æ¯ä¸ªç‚¹ä¸Šéƒ½æœ‰äº†æ‰€éœ€è¦çš„ä¿¡æ¯
(æƒé‡ä¸åŒï¼Œæ¯ä¸ªè¾“å‡ºçš„å‘é‡çš„é‡ç‚¹åœ¨ä¸åŒçš„positionç¼–ç ä½ç½®ä¸Š)ï¼Œå› æ­¤åªéœ€è¦åšlinear transformationã€‚
bertä¸­transformerå‚æ•°è®¡ç®—:
embedding: vocab_size&#x3D;30522, max_position_embeddings&#x3D;512, token_type_embeddings&#x3D;2(å°±è¿›è¡Œä¸¤å¥åˆ†åˆ«æ ‡è®°ï¼Œå¤šäº†æˆªæ–­)
â€‹					ï¼ˆ30522+512+2ï¼‰*768 &#x3D; 23835648 (23M)
self-attention: 768&#x2F;12 &#x3D; 64 (å¤šå¤´æ¯å¤´åˆ†64ç»´åº¦çš„å‘é‡) ï¼Œ64*768(æ¯ä¸ª64æ˜ å°„å›768)ï¼ŒQKVä¸‰ä¸ªçŸ©é˜µ, 
â€‹						  æœ€åä¸€å±‚ 786(64 *12çš„æ‹¼æ¥)-&gt;768çš„çº¿æ€§å˜æ¢
â€‹						(768&#x2F;12 * 768 3 ) * 12 + (768768) &#x3D; 2359296
â€‹						ç»è¿‡12ä¸ªtransformer
â€‹						2359296*12 &#x3D; 28311552 (28M)
feedfoward: è‡ªæ³¨æ„åŠ›å±‚ä¹‹å åˆ†åˆ«åœ¨ encoder å’Œ decoder ä¸­æœ‰ä¸ªä¸€ä¸ªå…¨è¿æ¥å±‚
â€‹						ç»´åº¦ä» 768-&gt;4*768_768-&gt;768
â€‹						(768*4 * 768 )*2 &#x3D; 4718592
â€‹						(768*4 * 768 )*2  * 12 &#x3D; 56623104 (56M)
layernorm: æœ‰ä¼½é©¬å’Œè´å¡”ä¸¤ä¸ªå‚æ•°ï¼Œembeddingå±‚ï¼ˆ768 * 2ï¼‰ï¼Œ12å±‚çš„self-attentionï¼Œ
â€‹						768 * 2 + 768 * 2 * 2 * 12 &#x3D; 38400
æ€»è®¡: 23835648+28311552+56623104+38400 &#x3D; 108808704      				(108M)
æ¯ä¸€å±‚çš„å‚æ•°ä¸º:  å¤šå¤´æ³¨æ„åŠ›çš„å‚æ•° + æ‹¼æ¥çº¿æ€§å˜æ¢çš„å‚æ•° + feed-forwardçš„å‚æ•° + layer-normçš„å‚æ•°
768 * 768 &#x2F; 12 * 3 * 12 + 768 * 768 + 768 * 3072 * 2 + 768 * 2 * 2 &#x3D; 7080960  (7M)
Encoder ç¼–ç é˜¶æ®µMulti-head Attentionå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å°†ä¸€ä¸ªè¯å‘é‡ç•™è¿‡å…«ä¸ª self-attention å¤´ç”Ÿæˆå…«ä¸ªè¯å‘é‡ vectorï¼Œ
å°†å…«ä¸ªè¯å‘é‡æ‹¼æ¥ï¼Œé€šè¿‡ fc å±‚è¿›è¡Œ softmax è¾“å‡ºã€‚
ä¾‹å¦‚ï¼š
è¯å‘é‡ä¸º (1,4) â€“&gt; 
ç»è¿‡ QKV çŸ©é˜µ(ç³»æ•°) å¾—åˆ° (1,3) å…«ä¸ª (1,3)*8 â€“&gt;
å°†è¾“å‡ºæ‹¼æ¥æˆ (8,3) çŸ©é˜µä¸å…¨è¿æ¥å±‚çš„ç³»æ•°çŸ©é˜µè¿›è¡Œç›¸ä¹˜å† softmax ç¡®å®šæœ€åè¾“å‡ºçš„ è¯å‘é‡ â€“&gt;
(1,4)
æ³¨æ„ QKVçŸ©é˜µæ€ä¹ˆæ¥çš„(attentionåˆ†æ•°)ï¼Œæœ€åä¸ºä»€ä¹ˆè¦æ‹¼æ¥ï¼Œä»¥åŠFCå±‚çš„ç³»æ•°
qkç›¸ä¹˜å¾—åˆ°ï¼Œè¯å‘é‡ä¸å…¶ä»–è¯çš„attentionåˆ†æ•°( q1*(k1,k2,k3) )

å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶è®©ä¸€ä»½è¯å‘é‡äº§ç”Ÿäº†å¤šä»½ç­”æ¡ˆï¼Œå°†æ¯ä¸€ä»½æ³¨æ„åŠ›æœºåˆ¶çš„äº§ç‰©æ‹¼æ¥ï¼Œ
è·å¾—äº†è¯å‘é‡åœ¨ä¸åŒæ³¨æ„åŠ›çŸ©é˜µè¿ç®—åçš„åˆ†æ•°ï¼Œè¿›è¡Œæ‹¼æ¥åï¼Œsoftmaxè¾“å‡ºæœ€æ³¨æ„çš„è¯ï¼Œå³æ˜¯æ³¨æ„åŠ›æœºåˆ¶ã€‚

å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†å‘é‡å¤åˆ¶nä»½(nä¸ºå¤šå¤´å¤´æ•°)ï¼ŒæŠ•å½±åˆ°å¦‚512&#x2F;8 &#x3D; 64çš„64ç»´çš„ä½ç»´ç©ºé—´ï¼Œæœ€åå°†æ¯ä¸€å±‚çš„è¾“å‡ºç»“æœ
æ­¤å¤„ä¸ºå…«å±‚ï¼Œ8*64&#x3D;512 æ‹¼å›512ç»´çš„è¾“å‡ºæ•°æ®
ç”±äºScale Dot Product åªæ˜¯åšä¹˜æ³•ç‚¹ç§¯(å‘é‡å˜æˆqvkä¹‹åçš„attentionè¿ç®—)ï¼Œæ²¡ä»€ä¹ˆå‚æ•°ï¼Œå› æ­¤é‡ç‚¹å­¦ä¹ çš„å‚æ•°åœ¨Multi-Headçš„çº¿æ€§å˜æ¢ä¸­ï¼Œ
å³å°† 64*8çš„å…«ä»½æ•°æ®çº¿æ€§å˜æ¢çš„ä¸‹æ–‡ä¸­çš„W0ï¼Œç»™æ¨¡å‹å…«æ¬¡æœºä¼šå¸Œæœ›èƒ½å¤Ÿå­¦åˆ°ä»€ä¹ˆï¼Œæœ€ååœ¨æ‹¼æ¥å›æ¥ã€‚&#x3D;&#x3D;


æ³¨æ„åŠ›æœºåˆ¶æµç¨‹ï¼š
q â€“&gt; æŸ¥è¯¢å‘é‡
set( kï¼Œv)    		k â€“&gt;å…³é”®å­— vâ€”-&gt; å€¼
å¦‚æœ qå¯¹kçš„ç›¸ä¼¼åº¦å¾ˆé«˜ï¼Œåˆ™è¾“å‡ºvçš„æ¦‚ç‡ä¹Ÿå˜é«˜


â€™å¤šå¤´â€™æ³¨æ„åŠ›æœºåˆ¶ 
è¯·æ³¨æ„å¹¶æ¨æ¼”å…¶è¯å‘é‡ç»´åº¦ä¸ç³»æ•°çŸ©é˜µå¸¦çš„è¡Œæ•°

Scale Dot Product
step1
QKåšç‚¹ç§¯ï¼Œåˆ™è¾“å‡ºæ¯ä¸€è¡Œï¼Œæ˜¯qä¸æ‰€æœ‰kçš„ç›¸ä¹˜ç›¸åŠ ç»“æœï¼Œ
Î±1 &#x3D; ï¼ˆq11k11+q12k21+q13k31 ,  q11k12+q12k22+q13k32 )
Î±2åŒç†ã€‚
step2
æ‰€ä»¥å¾—åˆ°äº†query1å¯¹æ‰€æœ‰keyçš„ç›¸ä¼¼åº¦ï¼Œæœ€åæ¯ä¸€è¡Œåšä¸ªsoftmaxè¿›è¡Œæ¦‚ç‡åˆ†å¸ƒã€‚
é™¤ä»¥æ ¹å·dkæ˜¯ä¸ºäº†å¹³æ»‘æ¢¯åº¦ï¼Œå…·ä½“æ¥è¯´ï¼šå½“æ¦‚ç‡è¶‹è¿‘äº1çš„æ—¶å€™softmaxå‡½æ•°çš„æ¢¯åº¦å¾ˆå°ï¼Œé™¤ä»¥dkè®©æ•°å€¼æ¥è¿‘å‡½æ•°ä¸­éƒ¨ï¼Œæ¢¯åº¦ä¼šæ¯”è¾ƒé™¡å³­
step3
å°†ç¬¬äºŒæ­¥çš„ç»“æœä¸Vç›¸ä¹˜å¾—åˆ°æœ€åçš„è¾“å‡º
Position Embeddingä½ç½®ç¼–ç æ˜¯ å°†embeddingå¥½çš„è¯å‘é‡åŠ ä¸Š position embedding vector å°†ä¿¡æ¯èåˆï¼Œåœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­è¿›è¡Œè®¡ç®—ã€‚
(åŸæ–‡æ˜¯ä½¿ç”¨sin coså°†è¯å‘é‡ä»½ä¸¤éƒ¨åˆ†è¿›è¡Œç¼–ç ï¼Œ æœ¬æ–‡ä¸­å°†äº¤æ›¿ä½¿ç”¨sin cosï¼Œå³å•æ•°sin åŒæ•°cos)
ä½ç½®åµŒå…¥ç¼–ç ï¼Œä¸»è¦æ˜¯ä¸ºäº†ç¼–è¾‘å®šä½è¯å‘é‡çš„ä½ç½®ä»¥åŠè¯å‘é‡é—´çš„ç›¸å¯¹è·ç¦»

posä¸º è¯çš„ç§ç±»æ•°ï¼Œä¸ºè¡Œæ ‡å·
i ä¸ºç‰¹å¾ç»´åº¦
len(pos) * len(i)  è¡¨ç¤ºä¸ºä¸€position embedding çŸ©é˜µï¼Œ æ¯ä¸€è¡Œä¸ºè¯çš„ä½ç½®ä¿¡æ¯ï¼Œæ¯ä¸€åˆ—è¡¨ç¤ºåœ¨ç‰¹å¾ä¸Šåç½®ï¼Œ
å°†ä½ç½®ä¿¡æ¯ èå…¥ è¯å‘é‡ä¿¡æ¯ ä½¿è¯è·å¾— æ—¶é—´ä¸Šçš„ç›¸å¯¹ä¿¡æ¯





Residual ç»†èŠ‚
Decoder è§£ç é˜¶æ®µMask Multi-headä¸encoderä¸åŒçš„æ˜¯ï¼Œè§£ç å™¨åœ¨å·¥ä½œæ—¶ä¼šå¼•å…¥ Mask Multi-head æœºåˆ¶ï¼Œå°†å³ä¾§çš„è¯ç›–ä½(è®¾ä¸ºè´Ÿæ— ç©·æˆ–è€…åˆ«çš„)ã€‚
å…·ä½“æ¥è¯´:

encoder å°†ç”Ÿæˆçš„Kå’ŒVçŸ©é˜µä¼ å…¥ decoder çš„ self-attention æ¨¡å—ä¸­ï¼Œè€Œ decoder å°†äº§ç”Ÿ mask åçš„QçŸ©é˜µä¸å…¶åšattentionã€‚

maskåšçš„äº‹æƒ…




æ²¡å¤ªæ‡‚ï¼Œè¿™å¼ å›¾ï¼Œè¿™é‡Œå¯ä»¥å®ç°å¹¶è¡ŒåŒ–å˜›ï¼Ÿ&#x3D;&#x3D;è§£é‡Šåœ¨Maskç»†èŠ‚&#x3D;&#x3D;
æŒ‰ç…§å°è›®çš„çŸ©é˜µï¼Œå³ä¾§çš„æ˜¯å¯ä»¥å±è”½çš„ï¼Œä½†æ˜¯æ‰©å±•æˆnä¸ºçš„è¯å‘é‡æ€ä¹ˆå±è”½å‘¢ï¼Ÿ
åœ¨ç”ŸæˆzçŸ©é˜µå±è”½ï¼Ÿ ä¸å¯èƒ½ï¼Œå·²ç»å‚åŠ è®¡ç®—äº†ã€‚
æ‰€ä»¥ä¸èƒ½å¹¶è¡Œè¾“å‡ºï¼Ÿ åªèƒ½ä¸€ä¸ªä¸€ä¸ªåï¼Ÿç­‰ä¸‹çœ‹ä¸‹å°è›®è§†é¢‘ã€huggingfaceæ•™ç¨‹ä¹Ÿè¡Œ
æ—¶é—´ç»´åº¦ 
åœ¨æ—¶é—´åºåˆ—çš„æƒ…å†µä¸‹ï¼Œè¯å‘é‡è¡¨ç¤ºä¸ºï¼Œt1æ—¶åˆ»çš„vectorï¼Œt2æ—¶åˆ»çš„vectorâ€¦.
maskåšçš„äº‹æƒ…å°±æ˜¯å°†åé¢(å³è¾¹)çš„ tnä¸ªæ—¶åˆ»éƒ½å±è”½æ‰ï¼Œ
è€ŒQmatrixçš„å½¢æˆ å°†vectorå«æœ‰äº†å…¶ä¹‹åè¯çš„ä¿¡æ¯(å…±äº«äº†ç³»æ•°çŸ©é˜µ)ï¼Œæ‰€ä»¥å°†å…¶å³è¾¹å±è”½ã€‚
åˆ™å‰”é™¤äº†åé¢è¯çš„ä¿¡æ¯ï¼Œä»è€Œä¸è¿›è¡Œè€ƒè™‘ã€‚
Mask ç»†èŠ‚maskå°±æ˜¯ä¸ºäº†é˜»æ­¢è¯çŸ¥é“åé¢çš„ä¿¡æ¯ï¼Œå…·ä½“æ¥è¯´å°±æ˜¯QKVçŸ©é˜µè¿˜ç›¸ä¹˜ï¼Œä½†æ˜¯å¼•å…¥-infæ¥é˜»æ­¢å³è¾¹(åé¢çš„ä¿¡æ¯æ±‡èš)

åŒå°è›®çš„æµç¨‹ï¼Œç¬¬ä¸€æ¬¡ç‚¹ç§¯ï¼šå°†Qå’ŒKçŸ©é˜µç›¸ä¹˜å¾—åˆ°attentionåˆ†æ•°ï¼Œ
å°†å³ä¸Šè§’ç½®é›¶å°±ä¼šå¾—åˆ°åªå«æœ‰æœ¬èº«ä¿¡æ¯å’Œç›¸å¯¹ä½ç½®ä¹‹å‰(å·¦è¾¹)çš„ä¿¡æ¯ï¼Œ
ä¸”ç¬¬äºŒæ¬¡ç‚¹ç§¯: Mask(QK)ä¸Vç›¸ä¹˜ç”±ä¸‹ä¸‰è§’çŸ©é˜µçš„æ€§è´¨ï¼Œ

ç¬¬ä¸€è¡Œ(t1æ—¶åˆ»)åªè€ƒè™‘ç¬¬ä¸€ä¸ªå€¼çš„è¾“å‡º
ç¬¬ä¸€è¡Œ(t2æ—¶åˆ»)è€ƒè™‘ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªå€¼çš„è¾“å‡º
â€¦.
è¿™æ ·å°±å¯ä»¥å®ç° tnæ—¶åˆ»åªè€ƒè™‘ t1 åˆ° tn-1çš„è¾“å‡º
å¦‚æ­¤ä¾¿å¯å®ç°å¹¶è¡ŒåŒ–ã€‚ (encodeåˆ°decodeè¿˜æ˜¯ä¸²è¡Œçš„)


æ³¨: maskå»è´Ÿæ— ç©·æ˜¯å› ä¸º SoftMaxä¸­ eçš„æŒ‡æ•°å½¢å¼åªæœ‰åœ¨è´Ÿæ— ç©·æ‰ä¸ºé›¶ï¼Œ
è¿™æ ·ç›¸ä¹˜æ•°æ®ä¸ä¼šæœ‰ä¸€ç‚¹å½±å“ï¼Œå–å…¶ä»–å€¼ï¼Œéƒ½ä¼šå½±å“softmax



æ€»ç»“
ç‰¹åˆ«æ³¨æ„ç†è§£ attentionæœºåˆ¶å°†è¯å‘é‡ä¹‹é—´çš„è”ç³»ï¼Œ attentionåˆ†æ•°
embeddingæ–¹å¼ä¸º è¯å‘é‡+ä½ç½®ç¼–ç å‘é‡
å¼•å…¥äº† Residual
encoder-decoderå±‚çš„ä¼ å…¥ä¸ºKVçŸ©é˜µï¼Œdecoderç”ŸæˆQçŸ©é˜µ
Maskæ–¹å¼

å°šæœªæ˜æ™°:
multi-head å°†è¾“å…¥çš„å‘é‡å‡åˆ†å…«ç­‰åˆ†ï¼Ÿåˆ†åˆ«åš self-attentionï¼Ÿ å‡å°‘å‚æ•°åŠ å¿«è¿ç®—ï¼Œç»“æœè¿˜å·®ä¸å¤šï¼Ÿ
multi-head å¤„ç†çš„å‘é‡æ˜¯åœ¨ä¸åŒç»´åº¦å¤„ç†ï¼Ÿ æ¯”å¦‚ head1æ˜¯è¯ä¹‰ï¼Œhead2æ˜¯ä½ç½®ç­‰ç­‰ã€‚

(æ¥è‡ªå°è›®è§†é¢‘)
</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/11/21/NLP%E7%AC%94%E8%AE%B0/Attention%E6%9C%BA%E5%88%B6/" title="Attentionæœºåˆ¶"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/22/Mushoku.Tensei_.Isekai.Ittara.Honki.Dasu.full.3542652.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Attentionæœºåˆ¶"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/NLP%E7%AC%94%E8%AE%B0/Attention%E6%9C%BA%E5%88%B6/" title="Attentionæœºåˆ¶">Attentionæœºåˆ¶</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-21T09:00:10.386Z" title="å‘è¡¨äº 2022-11-21 17:00:10">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-11-22T05:00:03.361Z" title="æ›´æ–°äº 2022-11-22 13:00:03">2022-11-22</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Attention/">Attention</a></span></div><div class="content">åšå®¢åœ°å€
ä¼ ç»ŸSeq2Seqâ€‹	
åŠ¨ç”»è¿æ¥
å·¦ä¾§ä¸º input å°†å¥å­ä¸€ä¸ªä¸€ä¸ªæŠ•å…¥åˆ° encoder ä¸­ï¼Œ
encoderæ•´ä¸ªå¤„ç†å…¶ç›¸å…³æ€§å¾—åˆ° contextï¼Œåç»™ decoderï¼Œ
decoder è¿›è¡Œä¸€ä¸ªä¸€ä¸ªè§£ç è¾“å‡ºï¼Œå¾—åˆ°æ•´ä¸ªç¿»è¯‘åçš„å¥å­ã€‚
AttentionAn attention model differs from a classic sequence-to-sequence model in two main ways:

First, the encoder passes a lot more data to the decoder. Instead of passing the last hidden state of the encoding stage, the encoder passes all the hidden states to the decoder:

â€‹		æ³¨æ„åŠ›æœºåˆ¶å°†äº§ç”Ÿçš„éšè—å±‚ä¿¡æ¯(æ—¶é—´æ­¥éª¤ä¿¡æ¯)ï¼Œå…¨éƒ¨ä¿ç•™ï¼Œä¸€æ¬¡æ€§ä¼ ç»™ Decoderã€‚



Second, an attention decoder does an extra step before producing its output. In order to focus on the parts of the input that are relevant to this decoding time step, the decoder does the following:

Look at the set of encoder hidden states it received â€“ each encoder hidden state is most associated with a certain word in the input sentence

Give each hidden state a score (letâ€™s ignore how the scoring is done for now)

Multiply each hidden state by its softmaxed score, thus amplifying hidden states with high scores, and drowning out hidden states with low scores




â€‹		decoder å°† encoder è¾“å…¥çš„éšè—å±‚çš„ vector è¿›è¡Œæ‰“åˆ†å¾—åˆ°ä¸€ä¸ªåˆ†æ•°vectorï¼Œ
â€‹		å°†åˆ†æ•° vector åš softmaxï¼Œå¾—åˆ°ä¸€ä¸ªæƒé‡ vectorï¼Œ
â€‹		å°†æƒé‡ vector ä¸éšè—å±‚ vector ç›¸ä¹˜å¾—åˆ° æ³¨æ„åŠ› vectorï¼Œ
â€‹		æœ€åæŠŠæ³¨æ„åŠ› vector è¿›è¡Œç›¸åŠ å°±å®Œæˆäº†ã€‚


æ³¨æ„: å°† encoder çš„éšè—å±‚ä¿¡æ¯ä¼ å…¥ decoderä¹‹åï¼Œdecoder æ¯ä¸€æ­¥éƒ½å°†ä½¿ç”¨å…¶ä¼ å…¥çš„éšè—å±‚ä¿¡æ¯åš attentionã€‚


â€‹			ç”±ä¸Šå›¾å¯ä»¥çœ‹åˆ°ï¼Œè¾“å‡ºæ—¶ Attention æœºåˆ¶å°±æ˜¯å°†æ³¨æ„åŠ›æ”¾åœ¨åˆ†æ•°æœ€é«˜çš„å‘é‡ä¸Šï¼Œæ‰€ä»¥ï¼Œç§°ä¹‹ä¸ºâ€™æ³¨æ„åŠ›æœºåˆ¶â€™
</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/11/21/NLP%E7%AC%94%E8%AE%B0/HuggingFace/02%20Bert%20API%20/" title="02 HuggingFaceåŸºç¡€"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/20/d3962fe070511210156b8db2f4a5ecf6de45843a.jpg942w_926h_progressive.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="02 HuggingFaceåŸºç¡€"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/NLP%E7%AC%94%E8%AE%B0/HuggingFace/02%20Bert%20API%20/" title="02 HuggingFaceåŸºç¡€">02 HuggingFaceåŸºç¡€</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-21T08:59:54.815Z" title="å‘è¡¨äº 2022-11-21 16:59:54">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-11-21T09:01:35.614Z" title="æ›´æ–°äº 2022-11-21 17:01:35">2022-11-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/HuggingFace/">HuggingFace</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Bert/">Bert</a><span class="article-meta-link">â€¢</span><a class="article-meta__tags" href="/tags/Preprocessing/">Preprocessing</a></span></div><div class="content">Transformeråˆ†ä¸¤å—BERT&amp;GPTéƒ½å¾ˆèƒ½æ‰“
BERTç”¨çš„æ˜¯transformerçš„encoder

BERTæ˜¯ç”¨äº†Transformerçš„encoderä¾§çš„ç½‘ç»œï¼Œencoderä¸­çš„Self-attentionæœºåˆ¶åœ¨ç¼–ç ä¸€ä¸ªtokençš„æ—¶å€™åŒæ—¶åˆ©ç”¨äº†å…¶ä¸Šä¸‹æ–‡çš„tokenï¼Œå…¶ä¸­â€˜åŒæ—¶åˆ©ç”¨ä¸Šä¸‹æ–‡â€™å³ä¸ºåŒå‘çš„ä½“ç°ï¼Œè€Œå¹¶éæƒ³Bi-LSTMé‚£æ ·æŠŠå¥å­å€’åºè¾“å…¥ä¸€éã€‚


GPTç”¨çš„æ˜¯transformerçš„decoder

åœ¨å®ƒä¹‹å‰æ˜¯GPTï¼ŒGPTä½¿ç”¨çš„æ˜¯Transformerçš„decoderä¾§çš„ç½‘ç»œï¼ŒGPTæ˜¯ä¸€ä¸ªå•å‘è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒè¿‡ç¨‹ï¼Œæ›´é€‚ç”¨äºæ–‡æœ¬ç”Ÿæˆï¼Œé€šè¿‡å‰æ–‡å»é¢„æµ‹å½“å‰çš„å­—ã€‚



Bertçš„embeddingEmbeddingç”±ä¸‰ç§Embeddingæ±‚å’Œè€Œæˆï¼š

Token Embeddingsæ˜¯è¯å‘é‡ï¼Œç¬¬ä¸€ä¸ªå•è¯æ˜¯CLSæ ‡å¿—ï¼Œå¯ä»¥ç”¨äºä¹‹åçš„åˆ†ç±»ä»»åŠ¡

BERTåœ¨ç¬¬ä¸€å¥å‰ä¼šåŠ ä¸€ä¸ª[CLS]æ ‡å¿—ï¼Œæœ€åä¸€å±‚è¯¥ä½å¯¹åº”å‘é‡å¯ä»¥ä½œä¸ºæ•´å¥è¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œä»è€Œç”¨äºä¸‹æ¸¸çš„åˆ†ç±»ä»»åŠ¡ç­‰ã€‚å› ä¸ºä¸æ–‡æœ¬ä¸­å·²æœ‰çš„å…¶å®ƒè¯ç›¸æ¯”ï¼Œè¿™ä¸ªæ— æ˜æ˜¾è¯­ä¹‰ä¿¡æ¯çš„ç¬¦å·ä¼šæ›´â€œå…¬å¹³â€åœ°èåˆæ–‡æœ¬ä¸­å„ä¸ªè¯çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä»è€Œæ›´å¥½çš„è¡¨ç¤ºæ•´å¥è¯çš„è¯­ä¹‰ã€‚ å…·ä½“æ¥è¯´ï¼Œself-attentionæ˜¯ç”¨æ–‡æœ¬ä¸­çš„å…¶å®ƒè¯æ¥å¢å¼ºç›®æ ‡è¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œä½†æ˜¯ç›®æ ‡è¯æœ¬èº«çš„è¯­ä¹‰è¿˜æ˜¯ä¼šå ä¸»è¦éƒ¨åˆ†çš„ï¼Œå› æ­¤ï¼Œç»è¿‡BERTçš„12å±‚ï¼ˆBERT-baseä¸ºä¾‹ï¼‰ï¼Œæ¯æ¬¡è¯çš„embeddingèåˆäº†æ‰€æœ‰è¯çš„ä¿¡æ¯ï¼Œå¯ä»¥å»æ›´å¥½çš„è¡¨ç¤ºè‡ªå·±çš„è¯­ä¹‰ã€‚è€Œ[CLS]ä½æœ¬èº«æ²¡æœ‰è¯­ä¹‰ï¼Œç»è¿‡12å±‚ï¼Œå¥å­çº§åˆ«çš„å‘é‡ï¼Œç›¸æ¯”å…¶ä»–æ­£å¸¸è¯ï¼Œå¯ä»¥æ›´å¥½çš„è¡¨å¾å¥å­è¯­ä¹‰ã€‚


Segment Embeddingsç”¨æ¥åŒºåˆ«ä¸¤ç§å¥å­ï¼Œå› ä¸ºé¢„è®­ç»ƒä¸å…‰åšLMè¿˜è¦åšä»¥ä¸¤ä¸ªå¥å­ä¸ºè¾“å…¥çš„åˆ†ç±»ä»»åŠ¡

Position Embeddingså’Œä¹‹å‰æ–‡ç« ä¸­çš„Transformerä¸ä¸€æ ·ï¼Œä¸æ˜¯ä¸‰è§’å‡½æ•°è€Œæ˜¯å­¦ä¹ å‡ºæ¥çš„


APItokenizer12345678910111213141516171819202122232425262728293031323334from transformers import AutoConfig,AutoModel,AutoTokenizer,AdamW,get_linear_schedule_with_warmup,logging# configæ¨¡å—MODEL_NAME=&quot;bert-base-chinese&quot;config = AutoConfig.from_pretrained(MODEL_NAME) #c onfigå¯ä»¥é…ç½®æ¨¡å‹ä¿¡æ¯# tokenizeræ¨¡å—tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)tokenizer.all_special_ids # æŸ¥çœ‹ç‰¹æ®Šç¬¦å·çš„id [100, 102, 0, 101, 103]tokenizer.all_special_tokens # æŸ¥çœ‹token  [&#x27;[UNK]&#x27;, &#x27;[SEP]&#x27;, &#x27;[PAD]&#x27;, &#x27;[CLS]&#x27;, &#x27;[MASK]&#x27;]tokenizer.vocab_size # è¯æ±‡è¡¨å¤§å°tokenizer.vocab # è¯æ±‡å¯¹åº”çš„dictå½¢å¼## tokeningtext=&quot;æˆ‘åœ¨åŒ—äº¬å·¥ä½œ&quot;token_ids=tokenizer.encode(text)token_ids # [101, 2769, 1762, 1266, 776, 2339, 868, 102]tokenizer.convert_ids_to_tokens(token_ids) # [&#x27;[CLS]&#x27;, &#x27;æˆ‘&#x27;, &#x27;åœ¨&#x27;, &#x27;åŒ—&#x27;, &#x27;äº¬&#x27;, &#x27;å·¥&#x27;, &#x27;ä½œ&#x27;, &#x27;[SEP]&#x27;]		  # convert_tokens_to_ids(tokens) ä¸ºå¯¹åº”æ–¹æ³•    ## padding åšå‘é‡å¡«å……token_ids=tokenizer.encode(text,padding=True,max_length=30,add_special_tokens=True)## encode_plustoken_ids=tokenizer.encode_plus(    text,padding=&quot;max_length&quot;,    max_length=30,    add_special_tokens=True,    return_tensors=&#x27;pt&#x27;,    return_token_type_ids=True,    return_attention_mask=True)



ä½¿ç”¨pre_trainæ¨¡å‹è½½å…¥æ•°æ®12model=AutoModel.from_pretrained(MODEL_NAME)outputs=model(token_ids[&#x27;input_ids&#x27;],token_ids[&#x27;attention_mask&#x27;])



æ•°æ®é›†datasetå®šä¹‰12345678910111213141516171819202122232425262728293031323334class EnterpriseDataset(Dataset):    def __init__(self,texts,labels,tokenizer,max_len):        self.texts=texts        self.labels=labels        self.tokenizer=tokenizer        self.max_len=max_len    def __len__(self):        return len(self.texts)        def __getitem__(self,item):        &quot;&quot;&quot;        item ä¸ºæ•°æ®ç´¢å¼•ï¼Œè¿­ä»£å–ç¬¬itemæ¡æ•°æ®        &quot;&quot;&quot;        text=str(self.texts[item])        label=self.labels[item]                encoding=self.tokenizer.encode_plus(            text,            add_special_tokens=True,            max_length=self.max_len,            return_token_type_ids=True,            pad_to_max_length=True,            return_attention_mask=True,            return_tensors=&#x27;pt&#x27;,  #è½¬ä¸ºtensor        )        #print(encoding[&#x27;input_ids&#x27;])        return &#123;            &#x27;texts&#x27;:text,            &#x27;input_ids&#x27;:encoding[&#x27;input_ids&#x27;].flatten(),            &#x27;attention_mask&#x27;:encoding[&#x27;attention_mask&#x27;].flatten(),            # toeken_type_ids:0            &#x27;labels&#x27;:torch.tensor(label,dtype=torch.long)        &#125;

</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/11/21/NLP%E7%AC%94%E8%AE%B0/HuggingFace/01%20Attention%E4%BB%A5%E5%8F%8AAPI%20/" title="02 HuggingFaceåŸºç¡€"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/22/Souryuu.Asuka.Langley.full.3259249.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="02 HuggingFaceåŸºç¡€"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/NLP%E7%AC%94%E8%AE%B0/HuggingFace/01%20Attention%E4%BB%A5%E5%8F%8AAPI%20/" title="02 HuggingFaceåŸºç¡€">02 HuggingFaceåŸºç¡€</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-21T08:59:54.804Z" title="å‘è¡¨äº 2022-11-21 16:59:54">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-11-21T09:01:29.567Z" title="æ›´æ–°äº 2022-11-21 17:01:29">2022-11-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/HuggingFace/">HuggingFace</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Bert/">Bert</a><span class="article-meta-link">â€¢</span><a class="article-meta__tags" href="/tags/Preprocessing/">Preprocessing</a></span></div><div class="content">Attention åŸæ–‡
Why
å…¨é¢æ‹¥æŠ±Transformerï¼šNLPä¸‰å¤§ç‰¹å¾æŠ½å–å™¨(CNN&#x2F;RNN&#x2F;TF)ä¸­ï¼Œè¿‘ä¸¤å¹´æ–°æ¬¢Transformeræ˜æ˜¾ä¼šå¾ˆå¿«æˆä¸ºNLPé‡Œæ‹…å½“å¤§ä»»çš„æœ€ä¸»æµçš„ç‰¹å¾æŠ½å–å™¨ã€‚

åƒWordvecå‡ºç°ä¹‹åä¸€æ ·ï¼Œåœ¨äººå·¥æ™ºèƒ½é¢†åŸŸç§å„ç§ç›®æ ‡çš†å¯å‘é‡åŒ–ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬ç»å¸¸å¬åˆ°çš„â€œä¸‡ç‰©çš†å¯Embeddingâ€ã€‚è€ŒTransformeræ¨¡å‹å’ŒBertæ¨¡å‹çš„å‡ºç°ï¼Œæ›´æ˜¯NLPé¢†åŸŸåˆ’æ—¶ä»£çš„äº§ç‰©ï¼šå°†transformerå’ŒåŒå‘è¯­è¨€æ¨¡å‹è¿›è¡Œèåˆï¼Œä¾¿å¾—åˆ°NLPåˆ’æ—¶ä»£çš„ï¼Œä¹Ÿæ˜¯å½“ä¸‹åœ¨å„è‡ªNLPä¸‹æµä»»åŠ¡ä¸­è·å¾—state-of-the-artçš„æ¨¡å‹-BERT

BERTèµ·æºäºé¢„è®­ç»ƒçš„ä¸Šä¸‹æ–‡è¡¨ç¤ºå­¦ä¹ ï¼Œä¸ä¹‹å‰çš„æ¨¡å‹ä¸åŒï¼ŒBERTæ˜¯ä¸€ç§æ·±åº¦åŒå‘çš„ã€æ— ç›‘ç£çš„è¯­è¨€è¡¨ç¤ºï¼Œä¸”ä»…ä½¿ç”¨çº¯æ–‡æœ¬è¯­æ–™åº“è¿›è¡Œé¢„è®­ç»ƒçš„æ¨¡å‹ã€‚ä¸Šä¸‹æ–‡æ— å…³æ¨¡å‹ï¼ˆå¦‚word2vecæˆ–GloVeï¼‰ä¸ºè¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªå•è¯ç”Ÿæˆä¸€ä¸ªè¯å‘é‡è¡¨ç¤ºï¼Œå› æ­¤å®¹æ˜“å‡ºç°å•è¯çš„æ­§ä¹‰é—®é¢˜ã€‚BERTè€ƒè™‘åˆ°å•è¯å‡ºç°æ—¶çš„ä¸Šä¸‹æ–‡ã€‚ä¾‹å¦‚ï¼Œè¯â€œæ°´åˆ†â€çš„word2vecè¯å‘é‡åœ¨â€œæ¤ç‰©éœ€è¦å¸æ”¶æ°´åˆ†â€å’Œâ€œè´¢åŠ¡æŠ¥è¡¨é‡Œæœ‰æ°´åˆ†â€æ˜¯ç›¸åŒçš„ï¼Œä½†BERTæ ¹æ®ä¸Šä¸‹æ–‡çš„ä¸åŒæä¾›ä¸åŒçš„è¯å‘é‡ï¼Œè¯å‘é‡ä¸å¥å­è¡¨è¾¾çš„å¥æ„æœ‰å…³ã€‚


Embeddingï¼š

é¦–å…ˆç±»ä¼¼ word2vec çš„ tokenåŒ–ï¼Œå†è¿›è¡Œç‰‡æ®µæ ‡è®°( segment )ï¼Œæœ€å ids çš„ä½ç½®ç¼–ç (  position )
ç¼–ç åä¸€ä¸ª â€™è¯â€˜ æœ‰ä¸‰ä¸ªä¿¡æ¯ï¼Œtokenã€æ®µè½ä½ç½®ä¿¡æ¯ã€ç»å¯¹ä½ç½®ä¿¡æ¯( id: 1ã€2ã€3â€¦)

Embeddingè§£å†³çš„é—®é¢˜:
é¦–å…ˆæ˜¯ä¹‹å‰ç”¨çš„ One-Hot Keyï¼Œé«˜ç»´åº¦ï¼Œç¦»æ•£çš„ï¼Œä½ä¿¡æ¯å¯†åº¦çš„å‚¨å­˜å½¢å¼
å…¶æ¬¡æ˜¯æ›´å¥½çš„ Contextual Similarityï¼Œä¸Šä¸‹æ–‡ç›¸å…³ç›¸ä¼¼æ€§ã€‚

Preview Apiå‰ç½®æŸ¥çœ‹ï¼š123456from transformers import BertTokenizertokenizer = BertTokenizer.from_pretrained(&quot;bert-base-chinese&quot;) # è·å–ç›¸åº”æ¨¡å‹çš„tokenizerfrom transformers import AutoTokenizer, AutoModelForMaskedLMmodel = AutoModelForMaskedLM.from_pretrained(&quot;bert-base-chinese&quot;) #æŸ¥çœ‹æ¨¡å‹çš„åˆ†å±‚



å‡½æ•°è°ƒç”¨ï¼šå­—å…¸å¤§å°ï¼ŒtokenåŒ–ï¼ŒidsåŒ–12345678910vocab = tokenizer.vocabprint(&quot;å­—å…¸å¤§å°ï¼š&quot;, len(vocab)) 	# æŸ¥çœ‹å­—å…¸å¤§å°text = &quot;[CLS] ç­‰åˆ°æ½®æ°´ [MASK] äº†ï¼Œå°±çŸ¥é“è°æ²’ç©¿è£¤å­ã€‚&quot;tokens = tokenizer.tokenize(text)				# å°†æ–‡å­—åˆ†è¯ids = tokenizer.convert_tokens_to_ids(tokens)	# å°†æ–‡å­—è½¬åŒ–ä¸ºæ•°å­—ï¼Œè¿›è¡Œç¼–ç &#x27;&#x27;&#x27;[&#x27;[CLS]&#x27;, &#x27;ç­‰&#x27;, &#x27;åˆ°&#x27;, &#x27;æ½®&#x27;, &#x27;æ°´&#x27;, &#x27;[MASK]&#x27;, &#x27;äº†&#x27;, &#x27;ï¼Œ&#x27;, &#x27;å°±&#x27;, &#x27;çŸ¥&#x27;] ...[101, 5023, 1168, 4060, 3717, 103, 749, 8024, 2218, 4761] ... &#x27;&#x27;&#x27;

Maskæ¨¡å‹çš„ä½¿ç”¨1234567891011121314151617181920212223242526from transformers import BertForMaskedLM# é™¤äº† tokens ä»¥å¤–æˆ‘å€‘é‚„éœ€è¦è¾¨åˆ¥å¥å­çš„ segment idstokens_tensor = torch.tensor([ids])  # (1, seq_len)segments_tensors = torch.zeros_like(tokens_tensor)  # (1, seq_len)maskedLM_model = BertForMaskedLM.from_pretrained(PRETRAINED_MODEL_NAME)# ä½¿ç”¨ masked LM ä¼°è¨ˆ [MASK] ä½ç½®æ‰€ä»£è¡¨çš„å¯¦éš› token maskedLM_model.eval()with torch.no_grad():    outputs = maskedLM_model(tokens_tensor, segments_tensors)    predictions = outputs[0]    # (1, seq_len, num_hidden_units)del maskedLM_model# å°‡ [MASK] ä½ç½®çš„æ©Ÿç‡åˆ†ä½ˆå– top k æœ€æœ‰å¯èƒ½çš„ tokens å‡ºä¾†masked_index = 5k = 3probs, indices = torch.topk(torch.softmax(predictions[0, masked_index], -1), k)predicted_tokens = tokenizer.convert_ids_to_tokens(indices.tolist())# é¡¯ç¤º top k å¯èƒ½çš„å­—ã€‚ä¸€èˆ¬æˆ‘å€‘å°±æ˜¯å– top 1 å½“åšé¢„æµ‹å€¼print(&quot;è¼¸å…¥ tokens ï¼š&quot;, tokens[:10], &#x27;...&#x27;)print(&#x27;-&#x27; * 50)for i, (t, p) in enumerate(zip(predicted_tokens, probs), 1):    tokens[masked_index] = t    print(&quot;Top &#123;&#125; (&#123;:2&#125;%)ï¼š&#123;&#125;&quot;.format(i, int(p.item() * 100), tokens[:10]), &#x27;...&#x27;)

â€‹	è¼¸å…¥ tokens ï¼š [â€˜[CLS]â€™, â€˜ç­‰â€™, â€˜åˆ°â€™, â€˜æ½®â€™, â€˜æ°´â€™, â€˜[MASK]â€™, â€˜äº†â€™, â€˜ï¼Œâ€™, â€˜å°±â€™, â€˜çŸ¥â€™] â€¦â€‹	Top 1 (65%)ï¼š[â€˜[CLS]â€™, â€˜ç­‰â€™, â€˜åˆ°â€™, â€˜æ½®â€™, â€˜æ°´â€™, â€˜æ¥â€™, â€˜äº†â€™, â€˜ï¼Œâ€™, â€˜å°±â€™, â€˜çŸ¥â€™] â€¦â€‹	Top 2 ( 4%)ï¼š[â€˜[CLS]â€™, â€˜ç­‰â€™, â€˜åˆ°â€™, â€˜æ½®â€™, â€˜æ°´â€™, â€˜è¿‡â€™, â€˜äº†â€™, â€˜ï¼Œâ€™, â€˜å°±â€™, â€˜çŸ¥â€™] â€¦â€‹	Top 3 ( 4%)ï¼š[â€˜[CLS]â€™, â€˜ç­‰â€™, â€˜åˆ°â€™, â€˜æ½®â€™, â€˜æ°´â€™, â€˜å¹²â€™, â€˜äº†â€™, â€˜ï¼Œâ€™, â€˜å°±â€™, â€˜çŸ¥â€™] â€¦
å¯è§†åŒ–æ¨¡å‹: bertvizPandasé¢„å¤„ç†æ–‡æœ¬
å¤šä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°
nltkåº“çš„stopwords
textblobåº“çš„æ‹¼å†™æ£€æŸ¥ã€è¯å¹²æŠ½å–ã€è¯æ€§è¿˜åŸç­‰

æ–‡æœ¬æ•°æ®çš„åŸºæœ¬ä½“å¾æå–
è¯æ±‡æ•°é‡

å­—ç¬¦æ•°é‡

å¹³å‡å­—é•¿

åœç”¨è¯æ•°é‡

ç‰¹æ®Šå­—ç¬¦æ•°é‡

æ•°å­—æ•°é‡

å¤§å†™å­—æ¯æ•°é‡


æ–‡æœ¬æ•°æ®çš„åŸºæœ¬é¢„å¤„ç†
å°å†™è½¬æ¢
å»é™¤æ ‡ç‚¹ç¬¦å·
å»é™¤åœç”¨è¯
å»é™¤é¢‘ç°è¯
å»é™¤ç¨€ç–è¯
æ‹¼å†™æ ¡æ­£
åˆ†è¯(tokenization)
è¯å¹²æå–(stemming)
è¯å½¢è¿˜åŸ(lemmatization)

</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/11.17%E5%8F%B7%20%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/" title="05 é—®é¢˜æ€»ç»“"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/20/43c14d8ae5420e27e58c63a658a886d1c5c45bcc.jpg942w_1155h_progressive.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="05 é—®é¢˜æ€»ç»“"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/11.17%E5%8F%B7%20%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/" title="05 é—®é¢˜æ€»ç»“">05 é—®é¢˜æ€»ç»“</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:15.091Z" title="å‘è¡¨äº 2022-11-21 10:16:15">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-11-21T08:22:01.527Z" title="æ›´æ–°äº 2022-11-21 16:22:01">2022-11-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Trick/">Trick</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/">å¯è§†åŒ–</a></span></div><div class="content">typingåº“ä¸»è¦æ˜¯è¿›è¡Œæ³¨è§£ List Tuple Optional 
def aa( input0: str)  å†’å·åé¢ä¸ºæ¨èçš„æ•°æ®ç±»å‹ï¼Œä½¿ç”¨Union è¿›è¡Œç»„åˆç±»å‹æ¨è 
å¦‚ input1 ï¼šList(str)  æ¨èä¼ å…¥ä¸€ä¸ªåˆ—è¡¨ï¼Œåˆ—è¡¨å†…å®¹ä¸ºå­—ç¬¦ä¸²
TensorBoardä½¿ç”¨ 
1234567891011import numpy as npfrom torch.utils.tensorboard import SummaryWriter  # ä¹Ÿå¯ä»¥ä½¿ç”¨ tensorboardX# from tensorboardX import SummaryWriter  # ä¹Ÿå¯ä»¥ä½¿ç”¨ pytorch é›†æˆçš„ tensorboardwriter = SummaryWriter()for epoch in range(100):    writer.add_scalar(&#x27;add_scalar/squared&#x27;, np.square(epoch), epoch)    writer.add_scalars(&quot;add_scalars/trigonometric&quot;, &#123;&#x27;xsinx&#x27;: epoch * np.sin(epoch/5), &#x27;xcosx&#x27;: epoch* np.cos(epoch/5), &#x27;xtanx&#x27;: np.tan(epoch/5)&#125;, epoch)writer.close()

&#x3D;&#x3D;writer.add_scalar&#x3D;&#x3D;
PyTorch ä¿®æ”¹ä¿å­˜æ¨¡å‹ ä¿®æ”¹ï¼š
1vgg.classifer[layer_num] = nn.linear(dim1,dim2)

 ä¿å­˜ï¼š
1vgg.save(vagg.state_dict(), &#x27;model_parameters.pth&#x27;)

åŠ è½½ï¼š
1vgg.load_state_dict(torch.load(&#x27;model_parameters.pth&#x27;))

</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/08%20QA_v3/" title="04 QA_v3"><img class="post_bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/20/43c14d8ae5420e27e58c63a658a886d1c5c45bcc.jpg942w_1155h_progressive.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="04 QA_v3"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/21/Kaggle%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/08%20QA_v3/" title="04 QA_v3">04 QA_v3</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-11-21T02:16:15.068Z" title="å‘è¡¨äº 2022-11-21 10:16:15">2022-11-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-11-21T08:21:41.370Z" title="æ›´æ–°äº 2022-11-21 16:21:41">2022-11-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/QA/">QA</a></span></div><div class="content">Pipeline1234567891011121314151617import copyimport jsonimport osimport randomimport numpy as npimport pandas as pdimport torchimport torch.nn as nnimport torch.optim as optimfrom datasets import load_datasetfrom fastprogress.fastprogress import master_bar, progress_barfrom torch.cuda.amp import autocastfrom torch.utils.data import DataLoader, Datasetfrom tqdm.auto import tqdmfrom transformers import (AdamW, AutoModel, AutoModelForQuestionAnswering,                          AutoTokenizer, get_scheduler)
preprocesing1234567891011121314def open_json(file_path):    with open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as f:        data = json.load(f)        return datadef txt_json(file_path):    dt = open_json(file_path)    for i in range(len(dt[&#x27;questions&#x27;])):        pg_id = dt[&#x27;questions&#x27;][i][&#x27;paragraph_id&#x27;]        dt[&#x27;questions&#x27;][i][&#x27;context&#x27;] = dt[&#x27;paragraphs&#x27;][pg_id]    return dtdef save_json(file_path, save_name):    info = txt_json(file_path)    with open(save_name, &#x27;w&#x27;) as f:        json.dump(info, f)

123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def preprocess_function(examples):    questions = [q.strip() for q in examples[&quot;question_text&quot;]]    inputs = tokenizer(        questions,        examples[&quot;context&quot;],        max_length=384,        truncation=&quot;only_second&quot;,        return_offsets_mapping=True,        padding=&quot;max_length&quot;,        stride = 128,        return_overflowing_tokens=True,    )    offset_mapping = inputs.pop(&quot;offset_mapping&quot;)    sample_map = inputs.pop(&#x27;overflow_to_sample_mapping&#x27;)    start_positions = []    end_positions = []    for i, offset in enumerate(offset_mapping):        sample_idx = sample_map[i]        start_char = examples[&quot;answer_start&quot;][sample_idx]        end_char = examples[&quot;answer_start&quot;][sample_idx]+ len(examples[&quot;answer_text&quot;][sample_idx])+1        sequence_ids = inputs.sequence_ids(i)        idx = 0        while sequence_ids[idx] != 1:            idx += 1        context_start = idx        while sequence_ids[idx] == 1:            idx += 1        context_end = idx - 1        if offset[context_start][0] &gt; end_char or offset[context_end][1] &lt; start_char:            start_positions.append(0)            end_positions.append(0)        else:            idx = context_start            while idx &lt;= context_end and offset[idx][0] &lt;= start_char:                idx += 1            start_positions.append(idx - 1)            idx = context_end            while idx &gt;= context_start and offset[idx][1] &gt;= end_char:                idx -= 1            end_positions.append(idx + 1)    inputs[&quot;start_positions&quot;] = start_positions    inputs[&quot;end_positions&quot;] = end_positions    return inputsdef deal_dataset(file_path):    data_type = load_dataset(&quot;json&quot;, data_files=file_path, field=&#x27;questions&#x27;)    dataset = data_type.map(preprocess_function, batched=True, remove_columns=data_type[&quot;train&quot;].column_names)    return dataset

1234567891011121314151617class mydataset(Dataset):    def __init__(self, data):        self.data = data[&#x27;train&#x27;]    def __len__(self):        return len(self.data)    def __getitem__(self, idx):        input_ids = torch.tensor(self.data[idx][&#x27;input_ids&#x27;])        token_type_ids = torch.tensor(self.data[idx][&#x27;token_type_ids&#x27;])        attention_mask = torch.tensor(self.data[idx][&#x27;attention_mask&#x27;])        start_positions = torch.tensor(self.data[idx][&#x27;start_positions&#x27;])        end_positions = torch.tensor(self.data[idx][&#x27;end_positions&#x27;])                return &#123;&#x27;input_ids&#x27;:input_ids, &#x27;token_type_ids&#x27;:token_type_ids,                &#x27;attention_mask&#x27;:attention_mask, &#x27;start_positions&#x27;:start_positions,                &#x27;end_positions&#x27;:end_positions&#125;

train123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def train_bert(net, device, opti, lr, lr_scheduler, batch_size, train_loader, val_loader, epochs, model_name):        best_ep = 1    best_loss = 4.20051    train_loss, valid_loss = [], []    mb = master_bar(range(1, epochs+1))    for epoch in mb:        train_ls, valid_ls = 0, 0        # train_part        net.train()        with autocast():            for batch_data in progress_bar(train_loader, parent=mb):                                batch_data = &#123;k: v.to(device) for k, v in batch_data.items()&#125;                outputs = net(**batch_data)                loss = outputs.loss                train_ls += loss.item()                                opti.zero_grad()                loss.backward()                lr_scheduler.step()                opti.step()                            train_loss.append(train_ls/(len(train_loader)))                                    # valid_part        net.eval()        with torch.no_grad():            for batch in progress_bar(val_loader, parent=mb):                            batch_data = &#123;k: v.to(device) for k, v in batch_data.items()&#125;                outputs = net(**batch_data)                                loss = outputs.loss                valid_ls += loss.item()                            valid_loss.append(valid_ls/(len(val_loader)))                    # plot#         print(train_loss, &#x27;\n&#x27;, valid_loss) # ç»å¸¸å‡ºé”™ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆ        plot_loss_update(epoch, mb, train_loss, valid_loss)                # save        valid_loss_now = valid_loss[-1]        print(f&quot;Epoch &#123;epoch+1&#125; complete! Validation Loss : &#123;valid_loss_now:.5f&#125;&quot;, &#x27;\n&#x27;)        if valid_loss_now &lt; best_loss:            print(f&quot;Best validation loss improved from &#123;best_loss:.5f&#125; to &#123;valid_loss_now:.5f&#125;&quot;)            net_copy = copy.deepcopy(net)            best_loss = valid_loss_now            best_ep = epoch + 1            path_to_model = f&#x27;caofei_model/&#123;model_name&#125;_lr_&#123;lr&#125;_val_loss_&#123;best_loss:.5f&#125;_epoch_&#123;best_ep&#125;.pt&#x27;            torch.save(net_copy.state_dict(), path_to_model)            print(f&quot;The model has been saved in &#123;path_to_model&#125;&quot;)

1234567891011def plot_loss_update(epoch, mb, train_loss, valid_loss):    x = range(1, epoch+1)    y = np.concatenate((train_loss, valid_loss))    graphs = [[x,train_loss], [x,valid_loss]]    x_margin = 0.2    y_margin = 0.05    x_bounds = [1-x_margin, epochs+x_margin]    y_bounds = [np.min(y)-y_margin, np.max(y)+y_margin]    mb.update_graph(graphs, x_bounds, y_bounds)

è°ƒç”¨12345678910111213141516171819# è·¯å¾„è®¾ç½®!mkdir caofei_model  # !mkdir resultstrain_path = &#x27;../input/ml2022spring-hw7/hw7_train.json&#x27;dev_path = &#x27;../input/ml2022spring-hw7/hw7_dev.json&#x27;test_path = &#x27;../input/ml2022spring-hw7/hw7_test.json&#x27;model_name = &#x27;hfl/chinese-bert-wwm-ext&#x27;json_train_path = &#x27;./qa_dataset.json&#x27;json_dev_path = &#x27;./dev_dataset.json&#x27;# è®­ç»ƒè¶…å‚æ•°seed = 1222bs = 64lr = 2e-5epochs = 20

1234567tokenizer = AutoTokenizer.from_pretrained(model_name)save_json(train_path, json_train_path)save_json(dev_path, json_dev_path)train_json_dataset = deal_dataset(json_train_path)dev_json_dataset = deal_dataset(json_dev_path)

12345678import osos.environ[&quot;TOKENIZERS_PARALLELISM&quot;] = &quot;false&quot;train_dataset = mydataset(train_json_dataset)train_dataloader = DataLoader(train_dataset, batch_size=bs, num_workers=2)dev_dataset = mydataset(dev_json_dataset)dev_dataloader = DataLoader(dev_dataset, batch_size=bs, num_workers=2)

12345678910111213141516171819set_seed(seed)model = AutoModelForQuestionAnswering.from_pretrained(model_name)# model.load_state_dict(torch.load(&#x27;final_model/chineseQA_model_lr_2e-05_val_loss_4.20051_epoch_21.pt&#x27;))# len(list(model.parameters()))for idx, para in enumerate(model.parameters()):    para.requires_grad = False    if idx == 195:        break        device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)opti = torch.optim.Adam(model.parameters(), lr=lr)lr_scheduler = get_scheduler(    &quot;linear&quot;,    optimizer=opti,    num_warmup_steps=0,    num_training_steps=epochs*len(train_dataloader),)

1234model.to(device)train_bert(net=model, device=device, opti=opti, lr=lr, l           r_scheduler=lr_scheduler, batch_size=bs, train_loader=dev_dataloader,            val_loader=dev_dataloader, epochs=epochs, model_name=&#x27;chineseQA_model&#x27;)

</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.imagehub.cc/images/2022/11/20/375c6e3994a1f2472da5b34c26e48f18ab750e42.jpg942w_1332h_progressive.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Poy One</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/poyone"><i></i><span>ğŸ›´å‰å¾€github...</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">æ¬¢è¿æ¥åˆ°æˆ‘çš„åšå®¢</div></div><div class="sticky_layout"><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>ç½‘ç«™èµ„è®¯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">æ–‡ç« æ•°ç›® :</div><div class="item-count">11</div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™æ€»å­—æ•° :</div><div class="item-count">16.1k</div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™è®¿å®¢æ•° :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">æœ¬ç«™æ€»è®¿é—®é‡ :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">æœ€åæ›´æ–°æ—¶é—´ :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-11-22T05:01:05.320Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Poy One</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script defer src="/js/light.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 380px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 320px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(https://s1.imagehub.cc/images/2022/11/21/Souryuu.Asuka.Langley.full.3306081.jpg);"> <a class="categoryBar-list-link" href="categories/CV/">CV</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">Computer Vision</span></li><li class="categoryBar-list-item" style="background:url(https://s1.imagehub.cc/images/2022/11/21/Souryuu.Asuka.Langley.600.3414217.jpg);"> <a class="categoryBar-list-link" href="categories/NLP/">NLP</a><span class="categoryBar-list-count">7</span><span class="categoryBar-list-descr">Natural Language Processing</span></li><li class="categoryBar-list-item" style="background:url(https://s1.imagehub.cc/images/2022/11/22/Souryuu.Asuka.Langley.full.3684208.jpg);"> <a class="categoryBar-list-link" href="categories/Trick/">Trick</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">Processing Trikcs</span></li><li class="categoryBar-list-item" style="background:url(https://s1.imagehub.cc/images/2022/11/21/Souryuu.Asuka.Langley.full.3198846.png);"> <a class="categoryBar-list-link" href="categories/HuggingFace/">HuggingFace</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">HuggingFace Summary</span></li></ul></div></div>';
      console.log('å·²æŒ‚è½½butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><!-- hexo injector body_end end --></body></html>