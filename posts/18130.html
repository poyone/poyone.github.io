<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>HF Course 03 微调范式 | Attention Is A Talent</title><meta name="author" content="Poy One"><meta name="copyright" content="Poy One"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="dataIn this section we will use as an example the MRPC (Microsoft Research Paraphrase Corpus) dataset, introduced in a paper by William B. Dolan and Chris Brockett. The dataset consists of 5,801 pairs">
<meta property="og:type" content="article">
<meta property="og:title" content="HF Course 03 微调范式">
<meta property="og:url" content="https://poyone.github.io/posts/18130.html">
<meta property="og:site_name" content="Attention Is A Talent">
<meta property="og:description" content="dataIn this section we will use as an example the MRPC (Microsoft Research Paraphrase Corpus) dataset, introduced in a paper by William B. Dolan and Chris Brockett. The dataset consists of 5,801 pairs">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://npm.elemecdn.com/poyone1222/eris/Eris40.webp">
<meta property="article:published_time" content="2022-12-06T10:52:16.506Z">
<meta property="article:modified_time" content="2022-12-12T04:03:12.006Z">
<meta property="article:author" content="Poy One">
<meta property="article:tag" content="Huggingface">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://npm.elemecdn.com/poyone1222/eris/Eris40.webp"><link rel="shortcut icon" href="https://npm.elemecdn.com/poyone1222/eris/eris11.webp"><link rel="canonical" href="https://poyone.github.io/posts/18130"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'HF Course 03 微调范式',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-12-12 12:03:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card@1.0.0/lib/categorybar.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/eris11.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://npm.elemecdn.com/poyone1222/eris/Eris40.webp')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Attention Is A Talent</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">HF Course 03 微调范式</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-12-06T10:52:16.506Z" title="发表于 2022-12-06 18:52:16">2022-12-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-12-12T04:03:12.006Z" title="更新于 2022-12-12 12:03:12">2022-12-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Universe/">Universe</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="HF Course 03 微调范式"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="data"><a href="#data" class="headerlink" title="data"></a>data</h1><p>In this section we will use as an example the <strong>MRPC</strong> (Microsoft Research Paraphrase Corpus) dataset, introduced in a <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/I05-5002.pdf">paper</a> by William B. Dolan and Chris Brockett. <strong>The dataset consists of 5,801 pairs of sentences, with a label indicating if they are paraphrases</strong> or not (i.e., if both sentences mean the same thing). We’ve selected it for this chapter <strong>because it’s a small dataset,</strong> so it’s easy to experiment with training on it.</p>
<p> let’s focus on the MRPC dataset! This is one of the 10 datasets composing the <a target="_blank" rel="noopener" href="https://gluebenchmark.com/">GLUE benchmark</a></p>
<ul>
<li><p>使用的是MRPC，很小很好实验</p>
</li>
<li><p>它属于 GLUE</p>
</li>
</ul>
<p>接下来查看下数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">raw_datasets = load_dataset(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">raw_datasets</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">DatasetDict(&#123;</span></span><br><span class="line"><span class="string">    train: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;label&#x27;, &#x27;idx&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 3668</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">    validation: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;label&#x27;, &#x27;idx&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 408</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">    test: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;label&#x27;, &#x27;idx&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 1725</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">&#125;)&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">raw_train_dataset = raw_datasets[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">raw_train_dataset[<span class="number">0</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;idx&#x27;: 0,</span></span><br><span class="line"><span class="string"> &#x27;label&#x27;: 1,</span></span><br><span class="line"><span class="string"> &#x27;sentence1&#x27;: &#x27;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .&#x27;,</span></span><br><span class="line"><span class="string"> &#x27;sentence2&#x27;: &#x27;Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#x27;&#125;&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">raw_train_dataset.features</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;sentence1&#x27;: Value(dtype=&#x27;string&#x27;, id=None),</span></span><br><span class="line"><span class="string"> &#x27;sentence2&#x27;: Value(dtype=&#x27;string&#x27;, id=None),</span></span><br><span class="line"><span class="string"> &#x27;label&#x27;: ClassLabel(num_classes=2, names=[&#x27;not_equivalent&#x27;, &#x27;equivalent&#x27;], names_file=None, id=None),</span></span><br><span class="line"><span class="string"> &#x27;idx&#x27;: Value(dtype=&#x27;int32&#x27;, id=None)&#125;&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<h1 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h1><p>tokenizer方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tokenized_dataset = tokenizer(</span><br><span class="line">    raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;sentence1&quot;</span>],</span><br><span class="line">    raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;sentence2&quot;</span>],</span><br><span class="line">    padding=<span class="literal">True</span>,</span><br><span class="line">    truncation=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>This works well, but it has the disadvantage of returning a dictionary (with our keys, <code>input_ids</code>, <code>attention_mask</code>, and <code>token_type_ids</code>, and values that are lists of lists). It will also only work if you have enough RAM to store your whole dataset during the tokenization (whereas the datasets from the 🤗 Datasets library are <a target="_blank" rel="noopener" href="https://arrow.apache.org/">Apache Arrow</a> files stored on the disk, so you only keep the samples you ask for loaded in memory).</p>
<ul>
<li>占内存</li>
</ul>
<p>dataset.map 方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_function</span>(<span class="params">example</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(example[<span class="string">&quot;sentence1&quot;</span>], example[<span class="string">&quot;sentence2&quot;</span>], truncation=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">tokenized_datasets = raw_datasets.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>)</span><br><span class="line">tokenized_datasets</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">DatasetDict(&#123;</span></span><br><span class="line"><span class="string">    train: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;attention_mask&#x27;, &#x27;idx&#x27;, &#x27;input_ids&#x27;, &#x27;label&#x27;, &#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;token_type_ids&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 3668</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">    validation: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;attention_mask&#x27;, &#x27;idx&#x27;, &#x27;input_ids&#x27;, &#x27;label&#x27;, &#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;token_type_ids&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 408</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">    test: Dataset(&#123;</span></span><br><span class="line"><span class="string">        features: [&#x27;attention_mask&#x27;, &#x27;idx&#x27;, &#x27;input_ids&#x27;, &#x27;label&#x27;, &#x27;sentence1&#x27;, &#x27;sentence2&#x27;, &#x27;token_type_ids&#x27;],</span></span><br><span class="line"><span class="string">        num_rows: 1725</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">&#125;)&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<p>since the <code>tokenizer</code> works on lists of pairs of sentences, as seen before. This will allow us to use the option <code>batched=True</code> in our call to <code>map()</code>, which will greatly speed up the tokenization. The <code>tokenizer</code> is backed by a tokenizer written in Rust from the <a target="_blank" rel="noopener" href="https://github.com/huggingface/tokenizers">🤗 Tokenizers</a> library. This tokenizer can be very fast, but only if we give it lots of inputs at once.</p>
<ul>
<li>batch</li>
</ul>
<p>This is because padding all the samples to the maximum length is not efficient: it’s better to pad the samples when we’re building a batch, <strong>as then we only need to pad to the maximum length in that batch</strong>, and not the maximum length in the entire dataset. This can save a lot of time and processing power when the inputs have very variable lengths!</p>
<ul>
<li>batch内最长padding，将在下一小节介绍<code>DataCollatorWithPadding</code></li>
</ul>
<p>You can even use multiprocessing when applying your preprocessing function with <code>map()</code> by passing along a <code>num_proc</code> argument. We didn’t do this here because the 🤗 Tokenizers library already uses multiple threads to tokenize our samples faster, but if you are not using a fast tokenizer backed by this library, this could speed up your preprocessing.</p>
<ul>
<li>多线程</li>
</ul>
<blockquote>
<p>but note that if you’re training on a TPU it can cause problems — TPUs prefer fixed shapes, even when that requires extra padding.</p>
<ul>
<li>tpu更喜欢恒定形状，所以你很少数据with large pad 也没事</li>
</ul>
</blockquote>
<h2 id="Dynamic-padding"><a href="#Dynamic-padding" class="headerlink" title="Dynamic padding"></a>Dynamic padding</h2><p>The function that is responsible for putting together samples inside a batch is called a <em>collate function</em>. It’s an argument you can pass when you build a <code>DataLoader</code>, the default being a function that will just convert your samples to PyTorch tensors and concatenate them (recursively if your elements are lists, tuples, or dictionaries). This won’t be possible in our case since the inputs we have won’t all be of the same size.</p>
<ul>
<li>DataCollator可以看成是一个函数，可以传入pytorch的dataloader的<code>collate_fn</code>参数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorWithPadding</span><br><span class="line"></span><br><span class="line">data_collator = DataCollatorWithPadding(tokenizer=tokenizer) <span class="comment"># 有model参数，可以把model也让collator知道</span></span><br></pre></td></tr></table></figure>



<p>军火展示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">samples = tokenized_datasets[<span class="string">&quot;train&quot;</span>][:<span class="number">8</span>]</span><br><span class="line">samples = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> samples.items() <span class="keyword">if</span> k <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;idx&quot;</span>, <span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>]&#125;</span><br><span class="line">[<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> samples[<span class="string">&quot;input_ids&quot;</span>]]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[50, 59, 47, 67, 59, 50, 62, 32]&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">batch = data_collator(samples)</span><br><span class="line">&#123;k: v.shape <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;attention_mask&#x27;: torch.Size([8, 67]),</span></span><br><span class="line"><span class="string"> &#x27;input_ids&#x27;: torch.Size([8, 67]),</span></span><br><span class="line"><span class="string"> &#x27;token_type_ids&#x27;: torch.Size([8, 67]),</span></span><br><span class="line"><span class="string"> &#x27;labels&#x27;: torch.Size([8])&#125;&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<h1 id="Fine-tune"><a href="#Fine-tune" class="headerlink" title="Fine-tune"></a>Fine-tune</h1><h2 id="Trainer"><a href="#Trainer" class="headerlink" title="Trainer"></a>Trainer</h2><p>首先是TrainingArguments的定义</p>
<p>The first step before we can define our <code>Trainer</code> is to define a <code>TrainingArguments</code> class that will contain all the hyperparameters the <code>Trainer</code> will use for training and evaluation. The only argument you have to provide is a directory where the trained model will be saved, as well as the checkpoints along the way. For all the rest, you can leave the defaults, which should work pretty well for a basic fine-tuning.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(<span class="string">&quot;test-trainer&quot;</span>)</span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>



<p>You will notice that unlike in <a target="_blank" rel="noopener" href="https://huggingface.co/course/chapter2">Chapter 2</a>, you get a warning after instantiating this pretrained model. This is because BERT has not been pretrained on classifying pairs of sentences, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead. The warnings indicate that some weights were not used (the ones corresponding to the dropped pretraining head) and that some others were randomly initialized (the ones for the new head). It concludes by encouraging you to train the model, which is exactly what we are going to do now.</p>
<ul>
<li>使用细分模型 (automode后带任务名称的)不会得到警告，是因为他会加载 最后面那个多分类的权重给你，这样预训练就又快了些，上面写的head 应该是指classifier的那几层吧。</li>
</ul>
<p>接下来可以train了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    training_args,</span><br><span class="line">    train_dataset=tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=tokenized_datasets[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train() <span class="comment"># 调用训练</span></span><br></pre></td></tr></table></figure>

<p>Note that when you pass the <code>tokenizer</code> as we did here, the default <code>data_collator</code> used by the <code>Trainer</code> will be a <code>DataCollatorWithPadding</code> as defined previously, so you can skip the line <code>data_collator=data_collator</code> in this call.</p>
<p>This will start the fine-tuning (which should take a couple of minutes on a GPU) and report the training loss every 500 steps.</p>
<ul>
<li>不写collate的话默认就是DataCollatorWithPadding，不过声明一下，比较好，为了可读性</li>
<li>每500步给你一个loss返回，<del>看看need loss有多大</del></li>
</ul>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predictions = trainer.predict(tokenized_datasets[<span class="string">&quot;validation&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(predictions.predictions.shape, predictions.label_ids.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># (408, 2) (408,)</span></span><br></pre></td></tr></table></figure>

<ul>
<li>predict的结果就是二分类的logits 接下来做个argmax 取位置信息即可</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">preds = np.argmax(predictions.predictions, axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">metric.compute(predictions=preds, references=predictions.label_ids)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;accuracy&#x27;: 0.8578431372549019, &#x27;f1&#x27;: 0.8996539792387542&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>The table in the <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1810.04805.pdf">BERT paper</a> reported an F1 score of 88.9 for the base model. That was the <code>uncased</code> model while we are currently using the <code>cased</code> model, which explains the better result.</p>
<ul>
<li>上面说 微调的power！</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">eval_preds</span>):</span><br><span class="line">    metric = evaluate.load(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">    logits, labels = eval_preds</span><br><span class="line">    predictions = np.argmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br></pre></td></tr></table></figure>

<p>封装代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">training_args = TrainingArguments(<span class="string">&quot;test-trainer&quot;</span>, evaluation_strategy=<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    training_args,</span><br><span class="line">    train_dataset=tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=tokenized_datasets[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train() <span class="comment"># 狠狠的训练</span></span><br></pre></td></tr></table></figure>

<ul>
<li>这里我们设置每个epoch进行一次evaluation，评测方法用上面封装的函数</li>
</ul>
<p>The <code>Trainer</code> will work out of the box on multiple GPUs or TPUs and provides lots of options, like mixed-precision training (use <code>fp16 = True</code> in your training arguments)</p>
<ul>
<li>如果你的机器支持float 16训练速度会更快</li>
</ul>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>以上是通过trainer定义的训练，可以作为我们正式工作前的训练测试，接下来我们使用pytorch来正式工作。</p>
<h1 id="full-training"><a href="#full-training" class="headerlink" title="full training"></a>full training</h1><h2 id="preprocessing"><a href="#preprocessing" class="headerlink" title="preprocessing"></a>preprocessing</h2><p>we need to apply a bit of postprocessing to our <code>tokenized_datasets</code>, to take care of some things that the <code>Trainer</code> did for us automatically. </p>
<ul>
<li><p>Remove the columns corresponding to values the model does not expect (like the <code>sentence1</code> and <code>sentence2</code> columns).</p>
</li>
<li><p>Rename the column <code>label</code> to <code>labels</code> (because the model expects the argument to be named <code>labels</code>).</p>
</li>
<li><p><strong>Set the format of the datasets</strong> so they return PyTorch tensors instead of lists.</p>
</li>
<li><p>做点后处理，删除、改名、return PyTorch tensors</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tokenized_datasets = tokenized_datasets.remove_columns([<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>, <span class="string">&quot;idx&quot;</span>])</span><br><span class="line">tokenized_datasets = tokenized_datasets.rename_column(<span class="string">&quot;label&quot;</span>, <span class="string">&quot;labels&quot;</span>)</span><br><span class="line">tokenized_datasets.set_format(<span class="string">&quot;torch&quot;</span>)</span><br><span class="line">tokenized_datasets[<span class="string">&quot;train&quot;</span>].column_names</span><br></pre></td></tr></table></figure>

<p>remove的操作可以在<code>dataset.map</code>里面设置<code>remove_columns=split_datasets[&quot;train&quot;].column_names</code>, 记得查看一下name别删除了不该删除的东西</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">    tokenized_datasets[<span class="string">&quot;train&quot;</span>], shuffle=<span class="literal">True</span>, batch_size=<span class="number">8</span>, collate_fn=data_collator</span><br><span class="line">)</span><br><span class="line">eval_dataloader = DataLoader(</span><br><span class="line">    tokenized_datasets[<span class="string">&quot;validation&quot;</span>], batch_size=<span class="number">8</span>, collate_fn=data_collator</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">&#123;k: v.shape <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;attention_mask&#x27;: torch.Size([8, 65]),</span></span><br><span class="line"><span class="string"> &#x27;input_ids&#x27;: torch.Size([8, 65]),</span></span><br><span class="line"><span class="string"> &#x27;labels&#x27;: torch.Size([8]),</span></span><br><span class="line"><span class="string"> &#x27;token_type_ids&#x27;: torch.Size([8, 65])&#125;&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>加载数据并check一下形状</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">outputs = model(**batch)</span><br><span class="line"><span class="built_in">print</span>(outputs.loss, outputs.logits.shape)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor(0.5441, grad_fn=&lt;NllLossBackward&gt;) torch.Size([8, 2])&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<h2 id="optimizer"><a href="#optimizer" class="headerlink" title="optimizer"></a>optimizer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW</span><br><span class="line"></span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">5e-5</span>)</span><br></pre></td></tr></table></figure>

<p>Finally, the learning rate scheduler used by default is just a linear decay from the <strong>maximum value (5e-5) to 0</strong>. To properly define it, we need to know the number of training steps we will take, which is the number of epochs we want to run multiplied by the number of training batches (which is the length of our training dataloader). </p>
<ul>
<li>我推荐 3e-4 cosine的组合</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> get_scheduler</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line">num_training_steps = num_epochs * <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">lr_scheduler = get_scheduler(</span><br><span class="line">    <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">    num_training_steps=num_training_steps,</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(num_training_steps)</span><br><span class="line"><span class="comment"># 1377</span></span><br></pre></td></tr></table></figure>



<h2 id="loop-amp-evaluation"><a href="#loop-amp-evaluation" class="headerlink" title="loop &amp; evaluation"></a>loop &amp; evaluation</h2><p>train 阶段就是pytorch那几样，eval换成了HF的api</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line">progress_bar = tqdm(<span class="built_in">range</span>(num_training_steps))</span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        progress_bar.update(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> eval_dataloader:</span><br><span class="line">    batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line"></span><br><span class="line">    logits = outputs.logits</span><br><span class="line">    predictions = torch.argmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line">    metric.add_batch(predictions=predictions, references=batch[<span class="string">&quot;labels&quot;</span>])</span><br><span class="line"></span><br><span class="line">metric.compute()</span><br><span class="line"><span class="comment"># &#123;&#x27;accuracy&#x27;: 0.8431372549019608, &#x27;f1&#x27;: 0.8907849829351535&#125;</span></span><br></pre></td></tr></table></figure>



<h2 id="Accelerate"><a href="#Accelerate" class="headerlink" title="Accelerate"></a>Accelerate</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">+ <span class="keyword">from</span> accelerate <span class="keyword">import</span> Accelerator</span><br><span class="line">  <span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW, AutoModelForSequenceClassification, get_scheduler</span><br><span class="line"></span><br><span class="line">+ accelerator = Accelerator()</span><br><span class="line"></span><br><span class="line">  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br><span class="line">  optimizer = AdamW(model.parameters(), lr=<span class="number">3e-5</span>)</span><br><span class="line"></span><br><span class="line">- device = torch.device(<span class="string">&quot;cuda&quot;</span>) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">- model.to(device)</span><br><span class="line"></span><br><span class="line">+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(</span><br><span class="line">+     train_dataloader, eval_dataloader, model, optimizer</span><br><span class="line">+ )</span><br><span class="line"></span><br><span class="line">  num_epochs = <span class="number">3</span></span><br><span class="line">  num_training_steps = num_epochs * <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">  lr_scheduler = get_scheduler(</span><br><span class="line">      <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">      optimizer=optimizer,</span><br><span class="line">      num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">      num_training_steps=num_training_steps</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  progress_bar = tqdm(<span class="built_in">range</span>(num_training_steps))</span><br><span class="line"></span><br><span class="line">  model.train()</span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">      <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">-         batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">          outputs = model(**batch)</span><br><span class="line">          loss = outputs.loss</span><br><span class="line">-         loss.backward()</span><br><span class="line">+         accelerator.backward(loss)</span><br><span class="line"></span><br><span class="line">          optimizer.step()</span><br><span class="line">          lr_scheduler.step()</span><br><span class="line">          optimizer.zero_grad()</span><br><span class="line">          progress_bar.update(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>进行以上代码的修改，减号就是在原先的代码上删减的，加号反之</p>
<p>The first line to add is the import line. The second line instantiates an <code>Accelerator</code> object that will look at the environment and initialize the proper distributed setup. 🤗 Accelerate handles the device placement for you, so you can remove the lines that put the model on the device (or, if you prefer, change them to use <code>accelerator.device</code> instead of <code>device</code>).</p>
<p>Then the main bulk of the work is done in the line that <strong>sends the dataloaders, the model, and the optimizer to</strong> <code>accelerator.prepare()</code>. This will wrap those objects in the proper container to make sure your distributed training works as intended. The remaining changes to make are removing the line that puts the batch on the <code>device</code> (again, if you want to keep this you can just change it to use <code>accelerator.device</code>) and replacing <code>loss.backward()</code> with <code>accelerator.backward(loss)</code>.</p>
<ul>
<li>引入并实例化</li>
<li>将 the dataloaders, the model, and the optimizer送入accelerator</li>
<li>使用accelerator.backward(loss)</li>
</ul>
<blockquote>
<p>In order to benefit from the speed-up offered by Cloud TPUs, we recommend padding your samples to a fixed length with the <code>padding=&quot;max_length&quot;</code> and <code>max_length</code> arguments of the tokenizer.</p>
<ul>
<li>如果你使用tpu记得直接放最大长度就可以了</li>
</ul>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>HF Course 03 微调范式</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://poyone.github.io/posts/18130.html">https://poyone.github.io/posts/18130.html</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>Poy One</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2022-12-06</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2022-12-12</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Huggingface/">Huggingface</a></div><div class="post_share"><div class="social-share" data-image="https://npm.elemecdn.com/poyone1222/eris/Eris40.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/4498.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris32.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">HF Course 04 Dataset</div></div></a></div><div class="next-post pull-right"><a href="/posts/64185.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris40.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">HF Course 02 API概要</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/58033.html" title="NLP Baseline 01 翻译"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/Asuka/Asuka26.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-05</div><div class="title">NLP Baseline 01 翻译</div></div></a></div><div><a href="/posts/16149.html" title="HF Course 01 基础概念"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris40.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-06</div><div class="title">HF Course 01 基础概念</div></div></a></div><div><a href="/posts/64185.html" title="HF Course 02 API概要"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris40.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-06</div><div class="title">HF Course 02 API概要</div></div></a></div><div><a href="/posts/4498.html" title="HF Course 04 Dataset"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris32.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-11</div><div class="title">HF Course 04 Dataset</div></div></a></div><div><a href="/posts/5596.html" title="HF Course 05 faiss 搜索引擎"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris32.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-11</div><div class="title">HF Course 05 faiss 搜索引擎</div></div></a></div><div><a href="/posts/55913.html" title="HF Course 06 继承式的Tokenizer"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/Eris11.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-11</div><div class="title">HF Course 06 继承式的Tokenizer</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://npm.elemecdn.com/poyone1222/eris/eris11.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Poy One</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/poyone"><i></i><span>🛴前往github...</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/poyone" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:poyone1222@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客 <br> QQ 914987163</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#data"><span class="toc-text">data</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-text">预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Dynamic-padding"><span class="toc-text">Dynamic padding</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Fine-tune"><span class="toc-text">Fine-tune</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Trainer"><span class="toc-text">Trainer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluation"><span class="toc-text">Evaluation</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-text">小结</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#full-training"><span class="toc-text">full training</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#preprocessing"><span class="toc-text">preprocessing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#optimizer"><span class="toc-text">optimizer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#loop-amp-evaluation"><span class="toc-text">loop &amp; evaluation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Accelerate"><span class="toc-text">Accelerate</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By Poy One</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script defer src="/js/light.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#web_bg",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 380px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 320px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka15.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/CV/&quot;);" href="javascript:void(0);">CV</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">计算机视觉</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka22.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/NLP/&quot;);" href="javascript:void(0);">NLP</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">自然语言处理</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka10.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Trick/&quot;);" href="javascript:void(0);">Trick</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">import torch as tf</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka29.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Dive-Into-Paper/&quot;);" href="javascript:void(0);">Dive Into Paper</a><span class="categoryBar-list-count">4</span><span class="categoryBar-list-descr">论文精读</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka16.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Python/&quot;);" href="javascript:void(0);">Python</a><span class="categoryBar-list-count">3</span><span class="categoryBar-list-descr">流畅的Python</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/poyone1222/Asuka/Asuka32.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/Universe/&quot;);" href="javascript:void(0);">Universe</a><span class="categoryBar-list-count">13</span><span class="categoryBar-list-descr">拥有一切 却变成太空</span></li></ul></div></div>';
      console.log('已挂载butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><!-- hexo injector body_end end --></body></html>